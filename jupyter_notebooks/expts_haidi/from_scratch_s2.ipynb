{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T16:30:42.086423Z",
     "start_time": "2023-07-30T16:30:41.946073Z"
    }
   },
   "outputs": [],
   "source": [
    "import mlagents\n",
    "from mlagents_envs.environment import UnityEnvironment as UE\n",
    "import numpy as np\n",
    "from mlagents_envs.environment import ActionTuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T16:30:54.097647Z",
     "start_time": "2023-07-30T16:30:42.087425Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialise envs\n",
    "\n",
    "# env =  UE(file_name=\"stage0_160523\\stage0_copy\",seed=1,side_channels=[])\n",
    "file_name_train = \"C:\\\\Users\\\\Palaash.HPZ\\\\Desktop\\\\RL-concept-learning_large_build_envs\\\\build_envs\\\\windows\\\\S2 180723\\\\build\"\n",
    "file_name_test = \"C:\\\\Users\\\\Palaash.HPZ\\\\Desktop\\\\RL-concept-learning_large_build_envs\\\\build_envs\\\\windows\\\\S2_test 180723\\\\build\"\n",
    "env_train =  UE(file_name=file_name_train,seed=1,side_channels=[],worker_id=5,no_graphics = False)\n",
    "env_train.reset()\n",
    "env_test =  UE(file_name=file_name_test,seed=1,side_channels=[],worker_id=6,no_graphics = False)\n",
    "env_test.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T16:30:54.113648Z",
     "start_time": "2023-07-30T16:30:54.098647Z"
    }
   },
   "outputs": [],
   "source": [
    "# env_train.close()\n",
    "# env_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T16:30:54.619856Z",
     "start_time": "2023-07-30T16:30:54.114649Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Palaash.HPZ\\anaconda3\\envs\\transformers_mlagents\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "vision_output_dim = 3136\n",
    "num_words = 35  # Number of unique words in the vocabulary\n",
    "language_output_dim = 128\n",
    "embedding_dim = 128\n",
    "mixing_dim = 256\n",
    "lstm_hidden_dim = 256\n",
    "num_actions = 4\n",
    "\n",
    "# (3,128,128) --> (64,7,7) = 3136 (3-layer CNN)\n",
    "class VisualModule(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(VisualModule, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=3, padding=0),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # self.conv = nn.Sequential(\n",
    "        #     nn.Conv2d(3, 32, kernel_size=5, stride=2, padding=2),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=2),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Conv2d(128, 64, kernel_size=5, stride=2, padding=1),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.ReLU(),\n",
    "        # )\n",
    "\n",
    "    def forward(self, vt):\n",
    "        encoded_vt = self.conv(vt)\n",
    "        return encoded_vt.view(vt.size(0), -1).squeeze()\n",
    "\n",
    "# one-hot encoding [0 0 1 0 0] --> 128 dimensional embedding (FF)\n",
    "# S1:5 S2:5 S3:11 S4:9 --> 30 + 5 (noun) = 35 in total\n",
    "class LanguageModule(nn.Module): \n",
    "    def __init__(self, num_words, embedding_dim):\n",
    "        super(LanguageModule, self).__init__()\n",
    "        self.embedding = nn.Linear(num_words, embedding_dim)\n",
    "\n",
    "    def forward(self, lt):\n",
    "        embedded_lt = self.embedding(lt)\n",
    "        return embedded_lt\n",
    "\n",
    "# 3136(vision) + 128 (language) --> 256 dimensional embedding (FF)\n",
    "class MixingModule(nn.Module):\n",
    "    def __init__(self, vision_output_dim, language_output_dim, mixing_dim):\n",
    "        super(MixingModule, self).__init__()\n",
    "        self.linear = nn.Linear(vision_output_dim + language_output_dim, mixing_dim)\n",
    "\n",
    "    def forward(self, vision_output, language_output):\n",
    "        combined_output = torch.cat((vision_output, language_output), dim=0)\n",
    "        mixed_output = self.linear(combined_output)\n",
    "        return mixed_output\n",
    "\n",
    "class LSTMModule(nn.Module):\n",
    "    def __init__(self,mixing_dim,lstm_hidden_dim):\n",
    "        super(LSTMModule, self).__init__()\n",
    "        self.lstm = nn.LSTMCell(mixing_dim, lstm_hidden_dim)\n",
    "    \n",
    "    def forward(self,mixed_output,lstm_hidden_state):\n",
    "        lstm_hidden_state = self.lstm(mixed_output, lstm_hidden_state) \n",
    "        # lstm_output = lstm_hidden_state[0] # output is (hidden_state,cell_state), we need hidden state, shape (1,256)\n",
    "        return lstm_hidden_state\n",
    "\n",
    "class Agent(nn.Module):\n",
    "    def __init__(self, num_words, embedding_dim, vision_output_dim, language_output_dim, mixing_dim, lstm_hidden_dim,num_actions):\n",
    "        super(Agent, self).__init__()\n",
    "        self.language_module = LanguageModule(num_words, embedding_dim)\n",
    "        self.visual_module = VisualModule()\n",
    "        self.mixing_module = MixingModule(vision_output_dim, language_output_dim, mixing_dim)\n",
    "        self.lstm_module = LSTMModule(mixing_dim, lstm_hidden_dim)\n",
    "        self.action_predictor = nn.Linear(lstm_hidden_dim, num_actions)\n",
    "        self.value_estimator = nn.Linear(lstm_hidden_dim, 1)\n",
    "\n",
    "    def forward(self, vt, lt, lstm_hidden_state):\n",
    "        vision_output = self.visual_module(vt)\n",
    "        language_output = self.language_module(lt)\n",
    "        mixed_output = self.mixing_module(vision_output, language_output).unsqueeze(0)\n",
    "        lstm_output = self.lstm_module(mixed_output,lstm_hidden_state)\n",
    "        action_probs = self.action_predictor(lstm_output[0]) \n",
    "        value_estimate = self.value_estimator(lstm_output[0])\n",
    "        return action_probs,value_estimate,lstm_output\n",
    "        \n",
    "        \n",
    "    def save(self, episode, ALG_NAME, ENV_ID):\n",
    "        path = os.path.join('model', '_'.join([ALG_NAME, ENV_ID]))\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        torch.save(self.state_dict(), os.path.join(path, f'agent_{episode}.pt'))\n",
    "\n",
    "    def load(self, episode, ALG_NAME, ENV_ID):\n",
    "        path = os.path.join('model', '_'.join([ALG_NAME, ENV_ID]))\n",
    "        self.load_state_dict(torch.load(os.path.join(path, f'agent_{episode}.pt')))    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T16:30:54.635862Z",
     "start_time": "2023-07-30T16:30:54.620841Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# function to test model on test env\n",
    "def test(agent,test_episode,test_episode_reward,test_average_reward,test_steps,test_actor_loss,test_critic_loss,test_entropy_loss,test_total_loss):\n",
    "    env = env_test\n",
    "    TEST_EPISODES = 100\n",
    "    tracked_agent = -1\n",
    "    entropy_term = 0\n",
    "    for episode in range(TEST_EPISODES):\n",
    "        test_episode += 1\n",
    "        t0 = time.time()\n",
    "        episode_reward = 0\n",
    "        # env.reset()\n",
    "        behavior_name=list(env.behavior_specs)[0]\n",
    "        spec=env.behavior_specs[behavior_name]\n",
    "        # state = env.reset().astype(np.float32)\n",
    "        STEPS = 0\n",
    "        decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "        # state -- vt, lt, lstm\n",
    "        vt = torch.tensor(decision_steps.obs[0]).reshape(1,3,128,128).to(device)\n",
    "        index1 = int(decision_steps.obs[1][0][0])\n",
    "        index2 = int(decision_steps.obs[1][0][1])+5\n",
    "        print(f'TEST: ---{hashmap[index2]} {hashmap[index1]}---')\n",
    "        # 0-capsule,1-cube,2-cylinder,3-prism,4-sphere \n",
    "        lt = torch.zeros(35).to(device)\n",
    "        lt[index1],lt[index2] = 1,1\n",
    "        lstm_hidden_state = (torch.zeros(1, lstm_hidden_dim).to(device), torch.zeros(1, lstm_hidden_dim).to(device))\n",
    "        done = False\n",
    "        while True:\n",
    "\n",
    "            # Need to use when calculating the loss\n",
    "            log_probs = []\n",
    "            # values = []\n",
    "            values = torch.empty(0).to(device)\n",
    "            rewards = []\n",
    "\n",
    "            \n",
    "            lstm_hidden_state = tuple(tensor.detach() for tensor in lstm_hidden_state)\n",
    "            STEPS += 1\n",
    "            policy_dist, value, lstm_hidden_state = agent(vt,lt,lstm_hidden_state)\n",
    "            # value = value.detach()\n",
    "            dist = F.softmax(policy_dist.detach(),dim=1).cpu().numpy()\n",
    "            \n",
    "\n",
    "            action_dist = Categorical(F.softmax(policy_dist.detach(),dim=1))\n",
    "            # action_dist = Categorical(F.softmax(policy_dist,dim=1))\n",
    "            action = action_dist.sample() # sample an action from action_dist\n",
    "            action_onehot = F.one_hot(torch.tensor(action),num_actions).cpu()\n",
    "            \n",
    "            log_prob = torch.log(F.softmax(policy_dist,dim=1)[0][action])\n",
    "            # log_prob = torch.log(F.softmax(policy_dist,dim=1)[0][action])\n",
    "            # entropy = -np.sum(np.mean(dist)* np.log(dist))\n",
    "            entropy = F.cross_entropy(policy_dist.detach(), action)\n",
    "\n",
    "            discrete_actions = np.array(action_onehot).reshape(1,4)*speed\n",
    "            action_tuple = ActionTuple()\n",
    "            action_tuple.add_discrete(discrete_actions)\n",
    "            env.set_actions(behavior_name,action_tuple)\n",
    "            env.step()\n",
    "            decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "\n",
    "            if tracked_agent == -1 and len(decision_steps) >= 1:\n",
    "                tracked_agent = decision_steps.agent_id[0]\n",
    "                # print(tracked_agent)\n",
    "\n",
    "            if tracked_agent in terminal_steps: # roll over or hit the target\n",
    "                print('TEST: Agent in terminal steps')\n",
    "                done = True\n",
    "                reward = terminal_steps[tracked_agent].reward\n",
    "                if reward > 0:\n",
    "                    pass\n",
    "                else: reward = -1 # roll over or other unseen conditions\n",
    "\n",
    "                print(f'TEST: Terminal Step reward: {reward}')\n",
    "\n",
    "            elif tracked_agent in decision_steps: # the agent which requires action\n",
    "                reward = decision_steps[tracked_agent].reward\n",
    "                # print(f'Decision Step reward: {reward}')\n",
    "                if reward<0:\n",
    "                    print(f'TEST: Decision Step reward: {reward}')\n",
    "            if STEPS >= MAX_STEPS:\n",
    "                reward = -10\n",
    "                print(f'TEST: Max Step Reward: {reward}')\n",
    "                env.reset()\n",
    "                done = True\n",
    "            if STEPS % 100 == 0:\n",
    "                print (f'TEST: Step: {STEPS}')\n",
    "\n",
    "            episode_reward = episode_reward + reward\n",
    "\n",
    "            rewards.append(reward)\n",
    "            # values.append(value)\n",
    "            values = torch.cat((values, value), dim=0)\n",
    "            log_probs.append(log_prob)\n",
    "            entropy_term = entropy_term + entropy\n",
    "            vt_new = torch.tensor(decision_steps.obs[0]).reshape(1,3,128,128).to(device)\n",
    "            vt = vt_new\n",
    "\n",
    "            if done:\n",
    "                # _, Qval,_ = agent(vt_new,lt,lstm_hidden_state)\n",
    "                # Qval = Qval.detach()\n",
    "                break\n",
    "            \n",
    "            \n",
    "        discounted_rewards = np.zeros_like(values.cpu().detach().numpy())\n",
    "        cumulative = 0\n",
    "        for t in reversed(range(len(rewards))):\n",
    "            cumulative = rewards[t] + LAM * cumulative # Monte Carlo\n",
    "            discounted_rewards[t] = cumulative\n",
    "        # print(f'rewards:{rewards}, discounted_rewards:{discounted_rewards}')\n",
    "        # Advantage Actor Critic\n",
    "\n",
    "        # Qvals[-1] = rewards[t] + LAM * Qval      or       Qvals[-1] = rewards[t]                   \n",
    "        # for t in range(len(rewards)-1):\n",
    "        #         Qvals[t] = rewards[t] + LAM * values[t+1]\n",
    "        \n",
    "        # r_(t+1) = R(s_t|a_t)--> reward[t]        a_t, V_t = agent(s_t)\n",
    "        # A_t = r_(t+1) + LAM * V_(t+1) - V_t \n",
    "        #     = Q_t - V_t\n",
    "        \n",
    "        # Monte Carlo Advantage = reward + LAM * cumulative_reward\n",
    "        # Actor_loss = -log(pai(s_t|a_t))*A_t\n",
    "        # Critic_loss = A_t.pow(2) *0.5\n",
    "        # Entropy_loss = -F.entropy(pai(St),index) * 0.001\n",
    "\n",
    "        # entropy = -np.sum(np.mean(dist) * np.log(dist))\n",
    "        \n",
    "        #update actor critic\n",
    "        \n",
    "        # values = torch.FloatTensor(values).requires_grad_(True).to(device)\n",
    "        discounted_rewards = torch.FloatTensor(discounted_rewards.astype(np.float32)).to(device)\n",
    "        log_probs = torch.stack(log_probs)\n",
    "        advantage = discounted_rewards - values\n",
    "        actor_loss = (-log_probs * advantage).mean()\n",
    "        critic_loss = 0.5 * torch.square(advantage).mean()\n",
    "        entropy_term /= STEPS\n",
    "        entropy_loss = -0.1 * entropy_term\n",
    "        ac_loss = actor_loss + critic_loss + entropy_loss\n",
    "        test_episode_reward.append(float(episode_reward))\n",
    "        test_steps.append(STEPS)\n",
    "        test_actor_loss.append(float(actor_loss))\n",
    "        test_critic_loss.append(float(critic_loss))\n",
    "        test_entropy_loss.append(float(entropy_loss))\n",
    "        test_total_loss.append(float(ac_loss))\n",
    "\n",
    "        if test_episode >= 100:\n",
    "            avg_score = np.mean(test_episode_reward[-100:])\n",
    "            test_average_reward.append(avg_score)\n",
    "            print('Testing  | Episode: {}/{}  | Episode Reward: {:.0f}  | Average Reward {:.2f}  | Actor loss: {:.2f} | Critic loss: {:.2f} | Entropy loss: {:.4f}  | Total Loss: {:.2f} | Total Steps: {}' \\\n",
    "                .format(episode + 1, TEST_EPISODES, episode_reward, avg_score, actor_loss, critic_loss,entropy_loss,  ac_loss, STEPS))\n",
    "        else:  print('Testing  | Episode: {}/{}  | Episode Reward: {:.0f}  | Actor loss: {:.2f} | Critic loss: {:.2f} | Entropy loss: {:.4f}  | Total Loss: {:.2f} | Total Steps: {}' \\\n",
    "                .format(episode + 1, TEST_EPISODES, episode_reward, actor_loss, critic_loss, entropy_loss,  ac_loss, STEPS))\n",
    "    return test_episode,test_episode_reward,test_average_reward,test_steps,test_actor_loss,test_critic_loss,test_entropy_loss,test_total_loss\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-30T16:48:48.313Z"
    },
    "code_folding": [
     0,
     35
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "\n",
      "---blue prism---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Palaash.HPZ\\anaconda3\\envs\\transformers_mlagents\\lib\\site-packages\\ipykernel_launcher.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1/94000  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "Model has been saved\n",
      "TEST: ---black sphere---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Palaash.HPZ\\anaconda3\\envs\\transformers_mlagents\\lib\\site-packages\\ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0004  | Total Loss: 0.02 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 2  | Actor loss: 0.00 | Critic loss: 0.34 | Entropy loss: -0.0110  | Total Loss: 0.33 | Total Steps: 53\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 3/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.22 | Entropy loss: -0.0004  | Total Loss: 0.22 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 8  | Actor loss: 0.00 | Critic loss: 0.81 | Entropy loss: -0.0207  | Total Loss: 0.80 | Total Steps: 55\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 10  | Actor loss: 0.02 | Critic loss: 1.97 | Entropy loss: -0.0481  | Total Loss: 1.95 | Total Steps: 8\n",
      "TEST: ---yellow prism---\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 10  | Actor loss: 11.51 | Critic loss: 13.55 | Entropy loss: -0.0525  | Total Loss: 25.01 | Total Steps: 172\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0228  | Total Loss: 0.14 | Total Steps: 10\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 8  | Actor loss: 0.00 | Critic loss: 0.76 | Entropy loss: -0.0281  | Total Loss: 0.73 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 5  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0111  | Total Loss: -0.00 | Total Steps: 53\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.48 | Entropy loss: -0.0232  | Total Loss: 0.46 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 10  | Actor loss: 0.06 | Critic loss: 4.01 | Entropy loss: -0.0076  | Total Loss: 4.06 | Total Steps: 43\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.25 | Entropy loss: -0.0003  | Total Loss: 0.25 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 8  | Actor loss: 0.00 | Critic loss: 0.33 | Entropy loss: -0.0017  | Total Loss: 0.33 | Total Steps: 29\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: 9  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0502  | Total Loss: 0.08 | Total Steps: 110\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: -2  | Actor loss: 0.01 | Critic loss: 1.91 | Entropy loss: -0.0191  | Total Loss: 1.90 | Total Steps: 105\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 8  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0009  | Total Loss: 0.03 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 10  | Actor loss: 0.19 | Critic loss: 5.75 | Entropy loss: -0.0507  | Total Loss: 5.89 | Total Steps: 40\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 8  | Actor loss: 0.00 | Critic loss: 0.49 | Entropy loss: -0.0019  | Total Loss: 0.49 | Total Steps: 36\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.26 | Entropy loss: -0.0001  | Total Loss: 0.26 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: 8  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0177  | Total Loss: -0.02 | Total Steps: 56\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 10  | Actor loss: 0.15 | Critic loss: 2.78 | Entropy loss: -0.0816  | Total Loss: 2.85 | Total Steps: 30\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 22/100  | Episode Reward: -82  | Actor loss: -18.52 | Critic loss: 75.47 | Entropy loss: -0.0547  | Total Loss: 56.90 | Total Steps: 500\n",
      "TEST: ---green cube---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 5  | Actor loss: 0.00 | Critic loss: 0.85 | Entropy loss: -0.0019  | Total Loss: 0.85 | Total Steps: 42\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.45 | Entropy loss: -0.0006  | Total Loss: 0.45 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 5  | Actor loss: 0.02 | Critic loss: 1.38 | Entropy loss: -0.0004  | Total Loss: 1.40 | Total Steps: 47\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.93 | Entropy loss: -0.0005  | Total Loss: 0.93 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 8  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0147  | Total Loss: 0.02 | Total Steps: 30\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 10  | Actor loss: 0.01 | Critic loss: 2.36 | Entropy loss: -0.0116  | Total Loss: 2.35 | Total Steps: 55\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 10  | Actor loss: 1.09 | Critic loss: 9.49 | Entropy loss: -0.0530  | Total Loss: 10.53 | Total Steps: 57\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 8  | Actor loss: 0.00 | Critic loss: 0.52 | Entropy loss: -0.0034  | Total Loss: 0.51 | Total Steps: 186\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 9  | Actor loss: 0.02 | Critic loss: 3.50 | Entropy loss: -0.0203  | Total Loss: 3.50 | Total Steps: 26\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 32/100  | Episode Reward: 8  | Actor loss: 0.52 | Critic loss: 8.40 | Entropy loss: -0.0174  | Total Loss: 8.90 | Total Steps: 26\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 33/100  | Episode Reward: -10  | Actor loss: -0.00 | Critic loss: 61.79 | Entropy loss: -0.0001  | Total Loss: 61.79 | Total Steps: 500\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 34/100  | Episode Reward: 8  | Actor loss: 0.01 | Critic loss: 3.19 | Entropy loss: -0.0299  | Total Loss: 3.17 | Total Steps: 39\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 35/100  | Episode Reward: 8  | Actor loss: 0.01 | Critic loss: 2.37 | Entropy loss: -0.0357  | Total Loss: 2.35 | Total Steps: 58\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 36/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0586  | Total Loss: -0.01 | Total Steps: 81\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 37/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0101  | Total Loss: 0.06 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: 5  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0020  | Total Loss: 0.16 | Total Steps: 46\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0007  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 8  | Actor loss: 0.00 | Critic loss: 0.53 | Entropy loss: -0.0003  | Total Loss: 0.53 | Total Steps: 34\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0006  | Total Loss: 0.20 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0163  | Total Loss: 0.12 | Total Steps: 9\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 43/100  | Episode Reward: -10  | Actor loss: -0.00 | Critic loss: 64.68 | Entropy loss: -0.0001  | Total Loss: 64.68 | Total Steps: 500\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 5  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0043  | Total Loss: 0.02 | Total Steps: 47\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: 8  | Actor loss: 6.08 | Critic loss: 27.01 | Entropy loss: -0.0544  | Total Loss: 33.04 | Total Steps: 75\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.98 | Entropy loss: -0.0104  | Total Loss: 0.97 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 5  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0028  | Total Loss: 0.12 | Total Steps: 47\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 10  | Actor loss: 0.01 | Critic loss: 1.62 | Entropy loss: -0.0285  | Total Loss: 1.60 | Total Steps: 7\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 8  | Actor loss: 0.00 | Critic loss: 0.38 | Entropy loss: -0.0052  | Total Loss: 0.37 | Total Steps: 164\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0012  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 1.09 | Entropy loss: -0.0017  | Total Loss: 1.10 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.48 | Entropy loss: -0.0200  | Total Loss: 0.46 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 53/100  | Episode Reward: 8  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0064  | Total Loss: -0.01 | Total Steps: 39\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 54/100  | Episode Reward: 10  | Actor loss: 0.06 | Critic loss: 2.23 | Entropy loss: -0.0033  | Total Loss: 2.29 | Total Steps: 50\n",
      "TEST: ---red capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0147  | Total Loss: 0.16 | Total Steps: 12\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: 8  | Actor loss: 0.00 | Critic loss: 14.87 | Entropy loss: -0.0096  | Total Loss: 14.86 | Total Steps: 32\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.56 | Entropy loss: -0.0032  | Total Loss: 0.56 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0146  | Total Loss: 0.22 | Total Steps: 10\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 10  | Actor loss: 1.54 | Critic loss: 16.87 | Entropy loss: -0.0409  | Total Loss: 18.37 | Total Steps: 67\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 60/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0228  | Total Loss: 0.13 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 61/100  | Episode Reward: 10  | Actor loss: 0.12 | Critic loss: 2.57 | Entropy loss: -0.0154  | Total Loss: 2.68 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 8  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0008  | Total Loss: 0.02 | Total Steps: 38\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.44 | Entropy loss: -0.0036  | Total Loss: 0.44 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 64/100  | Episode Reward: 10  | Actor loss: 0.05 | Critic loss: 2.49 | Entropy loss: -0.0014  | Total Loss: 2.53 | Total Steps: 50\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 65/100  | Episode Reward: 10  | Actor loss: 0.02 | Critic loss: 1.65 | Entropy loss: -0.0265  | Total Loss: 1.65 | Total Steps: 7\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 10  | Actor loss: 11.09 | Critic loss: 22.92 | Entropy loss: -0.0577  | Total Loss: 33.96 | Total Steps: 69\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 5  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0023  | Total Loss: 0.09 | Total Steps: 467\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 68/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0435  | Total Loss: 0.10 | Total Steps: 7\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0076  | Total Loss: 0.07 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 70/100  | Episode Reward: 10  | Actor loss: 0.15 | Critic loss: 5.62 | Entropy loss: -0.0383  | Total Loss: 5.74 | Total Steps: 34\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 10  | Actor loss: 0.09 | Critic loss: 2.43 | Entropy loss: -0.0151  | Total Loss: 2.50 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 8  | Actor loss: 0.05 | Critic loss: 21.27 | Entropy loss: -0.0241  | Total Loss: 21.30 | Total Steps: 21\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 10  | Actor loss: 0.01 | Critic loss: 1.40 | Entropy loss: -0.0691  | Total Loss: 1.34 | Total Steps: 9\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: 5  | Actor loss: 0.00 | Critic loss: 0.84 | Entropy loss: -0.0024  | Total Loss: 0.84 | Total Steps: 42\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0002  | Total Loss: 0.13 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.46 | Entropy loss: -0.0029  | Total Loss: 0.46 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 77/100  | Episode Reward: -10  | Actor loss: -0.00 | Critic loss: 80.61 | Entropy loss: -0.0001  | Total Loss: 80.61 | Total Steps: 500\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.86 | Entropy loss: -0.0002  | Total Loss: 0.87 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 8  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0220  | Total Loss: 0.02 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 9  | Actor loss: 1.30 | Critic loss: 8.68 | Entropy loss: -0.0402  | Total Loss: 9.95 | Total Steps: 27\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 8  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0024  | Total Loss: 0.10 | Total Steps: 30\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0170  | Total Loss: 0.07 | Total Steps: 8\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 8  | Actor loss: 0.00 | Critic loss: 0.76 | Entropy loss: -0.0008  | Total Loss: 0.76 | Total Steps: 29\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 84/100  | Episode Reward: 10  | Actor loss: 1.00 | Critic loss: 3.73 | Entropy loss: -0.0362  | Total Loss: 4.69 | Total Steps: 7\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 85/100  | Episode Reward: -10  | Actor loss: -0.00 | Critic loss: 62.33 | Entropy loss: -0.0019  | Total Loss: 62.32 | Total Steps: 500\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: 5  | Actor loss: 0.44 | Critic loss: 5.79 | Entropy loss: -0.0020  | Total Loss: 6.23 | Total Steps: 46\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.54 | Entropy loss: -0.0015  | Total Loss: 0.54 | Total Steps: 6\n",
      "TEST: ---green cube---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 5  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0299  | Total Loss: -0.02 | Total Steps: 34\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 89/100  | Episode Reward: 8  | Actor loss: 0.01 | Critic loss: 1.29 | Entropy loss: -0.0096  | Total Loss: 1.30 | Total Steps: 55\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 90/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0140  | Total Loss: 0.15 | Total Steps: 10\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.45 | Entropy loss: -0.0026  | Total Loss: 0.45 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 10  | Actor loss: 0.07 | Critic loss: 0.87 | Entropy loss: -0.0038  | Total Loss: 0.94 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: 8  | Actor loss: 0.00 | Critic loss: 0.53 | Entropy loss: -0.0004  | Total Loss: 0.53 | Total Steps: 34\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0004  | Total Loss: 0.07 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.29 | Entropy loss: -0.0183  | Total Loss: 0.28 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 10  | Actor loss: 0.08 | Critic loss: 2.16 | Entropy loss: -0.0162  | Total Loss: 2.22 | Total Steps: 56\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 8  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0037  | Total Loss: -0.00 | Total Steps: 39\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: 5  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0263  | Total Loss: -0.01 | Total Steps: 62\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0089  | Total Loss: 0.11 | Total Steps: 9\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 10  | Average Reward 6.90  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0634  | Total Loss: 0.04 | Total Steps: 14\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2/94000  | Episode Reward: 5  | Actor loss: -1.34 | Critic loss: 11.05 | Entropy loss: -0.0024  | Total Loss: 9.71 | Total Steps: 31\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 3/94000  | Episode Reward: 10  | Actor loss: 0.22 | Critic loss: 0.87 | Entropy loss: -0.0005  | Total Loss: 1.08 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 4/94000  | Episode Reward: 10  | Actor loss: -0.06 | Critic loss: 2.81 | Entropy loss: -0.0008  | Total Loss: 2.75 | Total Steps: 44\n",
      "\n",
      "---black capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 5/94000  | Episode Reward: 8  | Actor loss: 0.07 | Critic loss: 1.27 | Entropy loss: -0.0021  | Total Loss: 1.34 | Total Steps: 67\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 6/94000  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0000  | Total Loss: 0.21 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 7/94000  | Episode Reward: 5  | Actor loss: -0.02 | Critic loss: 2.44 | Entropy loss: -0.0025  | Total Loss: 2.42 | Total Steps: 135\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 8/94000  | Episode Reward: 10  | Actor loss: -0.00 | Critic loss: 1.35 | Entropy loss: -0.0001  | Total Loss: 1.34 | Total Steps: 40\n",
      "\n",
      "---black cylinder---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 9/94000  | Episode Reward: -10  | Actor loss: -0.00 | Critic loss: 3.07 | Entropy loss: -0.0001  | Total Loss: 3.06 | Total Steps: 500\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 10/94000  | Episode Reward: 10  | Actor loss: -0.10 | Critic loss: 2.75 | Entropy loss: -0.0057  | Total Loss: 2.65 | Total Steps: 76\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 11/94000  | Episode Reward: 10  | Actor loss: 0.01 | Critic loss: 9.66 | Entropy loss: -0.0000  | Total Loss: 9.67 | Total Steps: 31\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 12/94000  | Episode Reward: 10  | Actor loss: 0.18 | Critic loss: 0.38 | Entropy loss: -0.0007  | Total Loss: 0.55 | Total Steps: 7\n",
      "\n",
      "---yellow cube---\n",
      "Decision Step reward: -2.5\n",
      "Step: 250\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 13/94000  | Episode Reward: 8  | Actor loss: -0.52 | Critic loss: 2.91 | Entropy loss: -0.0222  | Total Loss: 2.37 | Total Steps: 407\n",
      "\n",
      "---red sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 14/94000  | Episode Reward: 8  | Actor loss: -0.85 | Critic loss: 5.21 | Entropy loss: -0.0076  | Total Loss: 4.36 | Total Steps: 55\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 15/94000  | Episode Reward: 10  | Actor loss: -0.10 | Critic loss: 4.05 | Entropy loss: -0.0066  | Total Loss: 3.94 | Total Steps: 64\n",
      "\n",
      "---yellow cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 16/94000  | Episode Reward: 8  | Actor loss: -0.13 | Critic loss: 7.05 | Entropy loss: -0.0050  | Total Loss: 6.92 | Total Steps: 197\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 17/94000  | Episode Reward: 10  | Actor loss: 0.16 | Critic loss: 3.09 | Entropy loss: -0.0013  | Total Loss: 3.25 | Total Steps: 53\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 18/94000  | Episode Reward: 2  | Actor loss: -0.24 | Critic loss: 7.30 | Entropy loss: -0.0063  | Total Loss: 7.05 | Total Steps: 181\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 19/94000  | Episode Reward: 10  | Actor loss: 0.01 | Critic loss: 6.45 | Entropy loss: -0.0000  | Total Loss: 6.46 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Step: 250\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 20/94000  | Episode Reward: 10  | Actor loss: 0.02 | Critic loss: 1.04 | Entropy loss: -0.0020  | Total Loss: 1.06 | Total Steps: 486\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 21/94000  | Episode Reward: 10  | Actor loss: -0.35 | Critic loss: 3.66 | Entropy loss: -0.0045  | Total Loss: 3.31 | Total Steps: 78\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 22/94000  | Episode Reward: 10  | Actor loss: 0.02 | Critic loss: 3.74 | Entropy loss: -0.0037  | Total Loss: 3.76 | Total Steps: 39\n",
      "\n",
      "---yellow sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 23/94000  | Episode Reward: 10  | Actor loss: -0.21 | Critic loss: 2.87 | Entropy loss: -0.0138  | Total Loss: 2.65 | Total Steps: 88\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 24/94000  | Episode Reward: 10  | Actor loss: -0.56 | Critic loss: 4.82 | Entropy loss: -0.0090  | Total Loss: 4.25 | Total Steps: 83\n",
      "\n",
      "---black prism---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 25/94000  | Episode Reward: -10  | Actor loss: -0.00 | Critic loss: 2.20 | Entropy loss: -0.0003  | Total Loss: 2.19 | Total Steps: 500\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 26/94000  | Episode Reward: 10  | Actor loss: 0.27 | Critic loss: 0.64 | Entropy loss: -0.0014  | Total Loss: 0.91 | Total Steps: 10\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 27/94000  | Episode Reward: 10  | Actor loss: 0.74 | Critic loss: 2.19 | Entropy loss: -0.0016  | Total Loss: 2.92 | Total Steps: 10\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 28/94000  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 7.79 | Entropy loss: -0.0000  | Total Loss: 7.80 | Total Steps: 31\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 29/94000  | Episode Reward: 10  | Actor loss: 0.01 | Critic loss: 0.49 | Entropy loss: -0.0000  | Total Loss: 0.49 | Total Steps: 6\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 30/94000  | Episode Reward: 10  | Actor loss: 0.20 | Critic loss: 2.92 | Entropy loss: -0.0003  | Total Loss: 3.11 | Total Steps: 8\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 31/94000  | Episode Reward: 8  | Actor loss: 0.18 | Critic loss: 1.76 | Entropy loss: -0.0013  | Total Loss: 1.94 | Total Steps: 49\n",
      "\n",
      "---red cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 32/94000  | Episode Reward: 8  | Actor loss: -0.42 | Critic loss: 5.74 | Entropy loss: -0.0085  | Total Loss: 5.32 | Total Steps: 43\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 33/94000  | Episode Reward: 10  | Actor loss: 0.02 | Critic loss: 0.58 | Entropy loss: -0.0007  | Total Loss: 0.60 | Total Steps: 50\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 34/94000  | Episode Reward: 10  | Actor loss: 0.05 | Critic loss: 2.73 | Entropy loss: -0.0009  | Total Loss: 2.78 | Total Steps: 51\n",
      "\n",
      "---blue capsule---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 35/94000  | Episode Reward: -10  | Actor loss: -0.00 | Critic loss: 2.21 | Entropy loss: -0.0002  | Total Loss: 2.21 | Total Steps: 500\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 36/94000  | Episode Reward: 8  | Actor loss: -0.10 | Critic loss: 4.93 | Entropy loss: -0.0007  | Total Loss: 4.83 | Total Steps: 48\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 37/94000  | Episode Reward: 10  | Actor loss: -0.10 | Critic loss: 5.85 | Entropy loss: -0.0012  | Total Loss: 5.76 | Total Steps: 24\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 38/94000  | Episode Reward: 10  | Actor loss: -0.03 | Critic loss: 2.95 | Entropy loss: -0.0013  | Total Loss: 2.93 | Total Steps: 45\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 39/94000  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.25 | Entropy loss: -0.0000  | Total Loss: 0.26 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 40/94000  | Episode Reward: 10  | Actor loss: 0.45 | Critic loss: 4.26 | Entropy loss: -0.0018  | Total Loss: 4.71 | Total Steps: 38\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 41/94000  | Episode Reward: 10  | Actor loss: -0.31 | Critic loss: 4.25 | Entropy loss: -0.0057  | Total Loss: 3.93 | Total Steps: 66\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 42/94000  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.65 | Entropy loss: -0.0000  | Total Loss: 0.65 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 43/94000  | Episode Reward: 10  | Actor loss: 0.09 | Critic loss: 4.41 | Entropy loss: -0.0008  | Total Loss: 4.50 | Total Steps: 34\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 44/94000  | Episode Reward: 10  | Actor loss: 0.01 | Critic loss: 3.50 | Entropy loss: -0.0000  | Total Loss: 3.51 | Total Steps: 31\n",
      "\n",
      "---green capsule---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 45/94000  | Episode Reward: -10  | Actor loss: -0.00 | Critic loss: 2.68 | Entropy loss: -0.0001  | Total Loss: 2.68 | Total Steps: 500\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 46/94000  | Episode Reward: 10  | Actor loss: 0.19 | Critic loss: 0.69 | Entropy loss: -0.0012  | Total Loss: 0.87 | Total Steps: 14\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 47/94000  | Episode Reward: 8  | Actor loss: -0.07 | Critic loss: 2.04 | Entropy loss: -0.0014  | Total Loss: 1.97 | Total Steps: 67\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 48/94000  | Episode Reward: 10  | Actor loss: 0.24 | Critic loss: 0.86 | Entropy loss: -0.0029  | Total Loss: 1.09 | Total Steps: 11\n",
      "\n",
      "---yellow cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Step: 250\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 49/94000  | Episode Reward: -32  | Actor loss: -0.94 | Critic loss: 15.34 | Entropy loss: -0.0197  | Total Loss: 14.38 | Total Steps: 500\n",
      "\n",
      "---yellow cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 50/94000  | Episode Reward: 8  | Actor loss: -0.29 | Critic loss: 5.05 | Entropy loss: -0.0151  | Total Loss: 4.75 | Total Steps: 101\n",
      "\n",
      "---yellow sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 51/94000  | Episode Reward: 8  | Actor loss: -0.55 | Critic loss: 2.25 | Entropy loss: -0.0293  | Total Loss: 1.67 | Total Steps: 173\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 52/94000  | Episode Reward: 10  | Actor loss: -0.09 | Critic loss: 3.27 | Entropy loss: -0.0030  | Total Loss: 3.17 | Total Steps: 120\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 53/94000  | Episode Reward: 8  | Actor loss: 0.14 | Critic loss: 2.13 | Entropy loss: -0.0008  | Total Loss: 2.27 | Total Steps: 41\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 54/94000  | Episode Reward: 8  | Actor loss: -0.53 | Critic loss: 3.55 | Entropy loss: -0.0036  | Total Loss: 3.02 | Total Steps: 54\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 55/94000  | Episode Reward: 10  | Actor loss: -0.13 | Critic loss: 3.10 | Entropy loss: -0.0048  | Total Loss: 2.97 | Total Steps: 74\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 56/94000  | Episode Reward: 10  | Actor loss: 0.04 | Critic loss: 1.37 | Entropy loss: -0.0001  | Total Loss: 1.40 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 57/94000  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0000  | Total Loss: 0.17 | Total Steps: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 58/94000  | Episode Reward: 8  | Actor loss: -0.25 | Critic loss: 2.77 | Entropy loss: -0.0032  | Total Loss: 2.51 | Total Steps: 63\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 59/94000  | Episode Reward: 10  | Actor loss: 0.20 | Critic loss: 1.77 | Entropy loss: -0.0015  | Total Loss: 1.97 | Total Steps: 44\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 60/94000  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 4.69 | Entropy loss: -0.0001  | Total Loss: 4.69 | Total Steps: 29\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 61/94000  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.31 | Entropy loss: -0.0000  | Total Loss: 0.31 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 62/94000  | Episode Reward: 8  | Actor loss: 0.05 | Critic loss: 0.57 | Entropy loss: -0.0006  | Total Loss: 0.62 | Total Steps: 43\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 63/94000  | Episode Reward: 10  | Actor loss: 0.01 | Critic loss: 0.81 | Entropy loss: -0.0000  | Total Loss: 0.82 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 64/94000  | Episode Reward: 10  | Actor loss: -0.42 | Critic loss: 2.70 | Entropy loss: -0.0039  | Total Loss: 2.27 | Total Steps: 50\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 65/94000  | Episode Reward: 10  | Actor loss: 0.22 | Critic loss: 3.41 | Entropy loss: -0.0028  | Total Loss: 3.62 | Total Steps: 26\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 66/94000  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 4.15 | Entropy loss: -0.0000  | Total Loss: 4.15 | Total Steps: 31\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 67/94000  | Episode Reward: 8  | Actor loss: -0.46 | Critic loss: 6.87 | Entropy loss: -0.0011  | Total Loss: 6.41 | Total Steps: 29\n",
      "\n",
      "---yellow capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 68/94000  | Episode Reward: 5  | Actor loss: -0.41 | Critic loss: 6.41 | Entropy loss: -0.0042  | Total Loss: 6.00 | Total Steps: 64\n",
      "\n",
      "---yellow cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Step: 250\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 69/94000  | Episode Reward: -25  | Actor loss: -1.68 | Critic loss: 7.53 | Entropy loss: -0.0521  | Total Loss: 5.79 | Total Steps: 500\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 70/94000  | Episode Reward: 10  | Actor loss: 0.03 | Critic loss: 3.67 | Entropy loss: -0.0004  | Total Loss: 3.70 | Total Steps: 31\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 71/94000  | Episode Reward: 10  | Actor loss: 0.06 | Critic loss: 1.56 | Entropy loss: -0.0007  | Total Loss: 1.62 | Total Steps: 66\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 72/94000  | Episode Reward: 10  | Actor loss: -0.66 | Critic loss: 0.12 | Entropy loss: -0.0051  | Total Loss: -0.55 | Total Steps: 8\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 73/94000  | Episode Reward: 8  | Actor loss: 0.09 | Critic loss: 0.62 | Entropy loss: -0.0009  | Total Loss: 0.71 | Total Steps: 38\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 74/94000  | Episode Reward: 10  | Actor loss: 0.13 | Critic loss: 0.93 | Entropy loss: -0.0003  | Total Loss: 1.06 | Total Steps: 8\n",
      "\n",
      "---black cube---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 75/94000  | Episode Reward: -10  | Actor loss: -0.00 | Critic loss: 3.08 | Entropy loss: -0.0001  | Total Loss: 3.08 | Total Steps: 500\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 76/94000  | Episode Reward: 10  | Actor loss: -0.00 | Critic loss: 3.75 | Entropy loss: -0.0008  | Total Loss: 3.75 | Total Steps: 36\n",
      "\n",
      "---green sphere---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 77/94000  | Episode Reward: -10  | Actor loss: -0.00 | Critic loss: 3.44 | Entropy loss: -0.0001  | Total Loss: 3.44 | Total Steps: 500\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 78/94000  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 3.73 | Entropy loss: -0.0000  | Total Loss: 3.73 | Total Steps: 31\n",
      "\n",
      "---yellow cube---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 79/94000  | Episode Reward: 5  | Actor loss: -0.85 | Critic loss: 4.33 | Entropy loss: -0.0077  | Total Loss: 3.47 | Total Steps: 60\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 80/94000  | Episode Reward: 10  | Actor loss: -0.00 | Critic loss: 4.25 | Entropy loss: -0.0001  | Total Loss: 4.25 | Total Steps: 34\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 81/94000  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 4.04 | Entropy loss: -0.0000  | Total Loss: 4.04 | Total Steps: 31\n",
      "\n",
      "---black capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 82/94000  | Episode Reward: 8  | Actor loss: 0.25 | Critic loss: 0.70 | Entropy loss: -0.0021  | Total Loss: 0.95 | Total Steps: 37\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 83/94000  | Episode Reward: 10  | Actor loss: -0.30 | Critic loss: 4.00 | Entropy loss: -0.0106  | Total Loss: 3.69 | Total Steps: 117\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 84/94000  | Episode Reward: 10  | Actor loss: 0.11 | Critic loss: 1.24 | Entropy loss: -0.0010  | Total Loss: 1.35 | Total Steps: 40\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 85/94000  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 86/94000  | Episode Reward: 10  | Actor loss: 1.40 | Critic loss: 2.90 | Entropy loss: -0.0033  | Total Loss: 4.29 | Total Steps: 13\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 87/94000  | Episode Reward: 10  | Actor loss: 0.31 | Critic loss: 1.06 | Entropy loss: -0.0011  | Total Loss: 1.37 | Total Steps: 12\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 88/94000  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 1.79 | Entropy loss: -0.0000  | Total Loss: 1.79 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 89/94000  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 90/94000  | Episode Reward: 10  | Actor loss: 0.01 | Critic loss: 0.52 | Entropy loss: -0.0000  | Total Loss: 0.53 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 91/94000  | Episode Reward: 10  | Actor loss: 0.01 | Critic loss: 0.75 | Entropy loss: -0.0000  | Total Loss: 0.76 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 92/94000  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0000  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---red cube---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 93/94000  | Episode Reward: 10  | Actor loss: 0.15 | Critic loss: 4.82 | Entropy loss: -0.0051  | Total Loss: 4.97 | Total Steps: 52\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 94/94000  | Episode Reward: 8  | Actor loss: -0.23 | Critic loss: 5.01 | Entropy loss: -0.0009  | Total Loss: 4.78 | Total Steps: 31\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 95/94000  | Episode Reward: 5  | Actor loss: -0.39 | Critic loss: 7.62 | Entropy loss: -0.0018  | Total Loss: 7.24 | Total Steps: 48\n",
      "\n",
      "---black capsule---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 96/94000  | Episode Reward: -10  | Actor loss: -0.00 | Critic loss: 2.75 | Entropy loss: -0.0001  | Total Loss: 2.74 | Total Steps: 500\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 97/94000  | Episode Reward: 10  | Actor loss: 0.00 | Critic loss: 0.49 | Entropy loss: -0.0000  | Total Loss: 0.49 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 98/94000  | Episode Reward: 10  | Actor loss: 0.02 | Critic loss: 1.00 | Entropy loss: -0.0005  | Total Loss: 1.01 | Total Steps: 44\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 99/94000  | Episode Reward: 10  | Actor loss: -0.02 | Critic loss: 3.55 | Entropy loss: -0.0016  | Total Loss: 3.53 | Total Steps: 61\n",
      "\n",
      "---red cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 100/94000  | Episode Reward: 8  | Actor loss: -0.56 | Critic loss: 5.03 | Entropy loss: -0.0055  | Total Loss: 4.46 | Total Steps: 67\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 7.025. Model has been saved-----\n",
      "Training  | Episode: 101/94000  | Episode Reward: 10  | Average Reward 7.03  | Actor loss: 0.29 | Critic loss: 0.82 | Entropy loss: -0.0051  | Total Loss: 1.10 | Total Steps: 47\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 10  | Average Reward 6.90  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0002  | Total Loss: 0.10 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 10  | Average Reward 6.97  | Actor loss: 0.00 | Critic loss: 4.06 | Entropy loss: -0.0126  | Total Loss: 4.05 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 3/100  | Episode Reward: 10  | Average Reward 6.97  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0025  | Total Loss: 0.12 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 10  | Average Reward 7.00  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0004  | Total Loss: 0.23 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 8  | Average Reward 6.97  | Actor loss: 0.02 | Critic loss: 0.07 | Entropy loss: -0.0030  | Total Loss: 0.08 | Total Steps: 49\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 8  | Average Reward 6.95  | Actor loss: 0.01 | Critic loss: 0.05 | Entropy loss: -0.0079  | Total Loss: 0.05 | Total Steps: 37\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: 2  | Average Reward 6.88  | Actor loss: 0.00 | Critic loss: 0.76 | Entropy loss: -0.0059  | Total Loss: 0.76 | Total Steps: 58\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 8  | Average Reward 6.88  | Actor loss: 0.01 | Critic loss: 3.34 | Entropy loss: -0.0175  | Total Loss: 3.34 | Total Steps: 48\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 10  | Average Reward 6.92  | Actor loss: 0.18 | Critic loss: 4.93 | Entropy loss: -0.0049  | Total Loss: 5.11 | Total Steps: 39\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 10  | Average Reward 6.92  | Actor loss: 0.00 | Critic loss: 0.95 | Entropy loss: -0.0064  | Total Loss: 0.95 | Total Steps: 36\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 10  | Average Reward 6.92  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0008  | Total Loss: 0.07 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 10  | Average Reward 6.92  | Actor loss: -0.00 | Critic loss: 0.30 | Entropy loss: -0.0008  | Total Loss: 0.30 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 10  | Average Reward 6.95  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0016  | Total Loss: 0.14 | Total Steps: 35\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: 10  | Average Reward 6.96  | Actor loss: 0.68 | Critic loss: 4.44 | Entropy loss: -0.0500  | Total Loss: 5.07 | Total Steps: 54\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 10  | Average Reward 7.08  | Actor loss: 0.00 | Critic loss: 0.93 | Entropy loss: -0.0225  | Total Loss: 0.91 | Total Steps: 14\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 10  | Average Reward 7.11  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0056  | Total Loss: 0.01 | Total Steps: 50\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 10  | Average Reward 7.11  | Actor loss: 0.03 | Critic loss: 1.21 | Entropy loss: -0.0549  | Total Loss: 1.19 | Total Steps: 58\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 10  | Average Reward 7.13  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0431  | Total Loss: -0.03 | Total Steps: 10\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 10  | Average Reward 7.13  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0247  | Total Loss: 0.21 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: 10  | Average Reward 7.16  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0043  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 10  | Average Reward 7.16  | Actor loss: -0.00 | Critic loss: 0.28 | Entropy loss: -0.0014  | Total Loss: 0.27 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 22/100  | Episode Reward: 10  | Average Reward 8.08  | Actor loss: 0.01 | Critic loss: 0.61 | Entropy loss: -0.0536  | Total Loss: 0.57 | Total Steps: 10\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 10  | Average Reward 8.13  | Actor loss: 0.00 | Critic loss: 0.28 | Entropy loss: -0.0095  | Total Loss: 0.27 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 10  | Average Reward 8.13  | Actor loss: 0.00 | Critic loss: 2.78 | Entropy loss: -0.0559  | Total Loss: 2.73 | Total Steps: 8\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0170  | Total Loss: 0.17 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0238  | Total Loss: -0.02 | Total Steps: 32\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 5  | Average Reward 8.15  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0140  | Total Loss: 0.18 | Total Steps: 96\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 8  | Average Reward 8.13  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0043  | Total Loss: -0.00 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 5  | Average Reward 8.08  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0156  | Total Loss: 0.02 | Total Steps: 47\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 10  | Average Reward 8.11  | Actor loss: 0.00 | Critic loss: 0.98 | Entropy loss: -0.0209  | Total Loss: 0.96 | Total Steps: 14\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 10  | Average Reward 8.12  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0038  | Total Loss: 0.20 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 32/100  | Episode Reward: 10  | Average Reward 8.14  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0019  | Total Loss: 0.05 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 33/100  | Episode Reward: 8  | Average Reward 8.31  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0003  | Total Loss: 0.12 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 34/100  | Episode Reward: 10  | Average Reward 8.34  | Actor loss: 0.00 | Critic loss: 0.32 | Entropy loss: -0.0327  | Total Loss: 0.28 | Total Steps: 48\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 35/100  | Episode Reward: 10  | Average Reward 8.37  | Actor loss: 0.01 | Critic loss: 4.65 | Entropy loss: -0.0209  | Total Loss: 4.64 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 36/100  | Episode Reward: 10  | Average Reward 8.37  | Actor loss: 0.00 | Critic loss: 0.60 | Entropy loss: -0.0048  | Total Loss: 0.60 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 37/100  | Episode Reward: 10  | Average Reward 8.37  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0857  | Total Loss: -0.05 | Total Steps: 7\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: 10  | Average Reward 8.41  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0153  | Total Loss: 0.01 | Total Steps: 48\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 8  | Average Reward 8.39  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0064  | Total Loss: -0.00 | Total Steps: 131\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 10  | Average Reward 8.41  | Actor loss: -0.00 | Critic loss: 0.04 | Entropy loss: -0.0004  | Total Loss: 0.04 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 10  | Average Reward 8.41  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0018  | Total Loss: 0.03 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 42/100  | Episode Reward: -10  | Average Reward 8.21  | Actor loss: -0.01 | Critic loss: 63.59 | Entropy loss: -0.0002  | Total Loss: 63.58 | Total Steps: 500\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 43/100  | Episode Reward: 5  | Average Reward 8.37  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0210  | Total Loss: 0.02 | Total Steps: 74\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 10  | Average Reward 8.41  | Actor loss: 0.02 | Critic loss: 1.69 | Entropy loss: -0.0376  | Total Loss: 1.68 | Total Steps: 64\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: 10  | Average Reward 8.44  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0024  | Total Loss: 0.01 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 10  | Average Reward 8.44  | Actor loss: 0.01 | Critic loss: 2.52 | Entropy loss: -0.0179  | Total Loss: 2.51 | Total Steps: 25\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 10  | Average Reward 8.49  | Actor loss: 0.08 | Critic loss: 5.67 | Entropy loss: -0.0368  | Total Loss: 5.72 | Total Steps: 48\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 10  | Average Reward 8.49  | Actor loss: 0.00 | Critic loss: 1.41 | Entropy loss: -0.0477  | Total Loss: 1.36 | Total Steps: 81\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 8  | Average Reward 8.49  | Actor loss: 0.00 | Critic loss: 1.59 | Entropy loss: -0.0032  | Total Loss: 1.59 | Total Steps: 29\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 10  | Average Reward 8.49  | Actor loss: 0.02 | Critic loss: 5.19 | Entropy loss: -0.0359  | Total Loss: 5.17 | Total Steps: 70\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 10  | Average Reward 8.49  | Actor loss: -0.00 | Critic loss: 0.05 | Entropy loss: -0.0024  | Total Loss: 0.05 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 8  | Average Reward 8.46  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0031  | Total Loss: 0.00 | Total Steps: 156\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 53/100  | Episode Reward: 5  | Average Reward 8.44  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0013  | Total Loss: -0.00 | Total Steps: 47\n",
      "TEST: ---green cube---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 54/100  | Episode Reward: 8  | Average Reward 8.41  | Actor loss: 2.27 | Critic loss: 25.01 | Entropy loss: -0.0032  | Total Loss: 27.28 | Total Steps: 170\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 10  | Average Reward 8.41  | Actor loss: 0.00 | Critic loss: 0.22 | Entropy loss: -0.0009  | Total Loss: 0.22 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: 10  | Average Reward 8.44  | Actor loss: 1.43 | Critic loss: 14.89 | Entropy loss: -0.0171  | Total Loss: 16.30 | Total Steps: 7\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 10  | Average Reward 8.44  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0032  | Total Loss: 0.20 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 10  | Average Reward 8.44  | Actor loss: 0.00 | Critic loss: 0.35 | Entropy loss: -0.0245  | Total Loss: 0.33 | Total Steps: 8\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 10  | Average Reward 8.44  | Actor loss: -0.00 | Critic loss: 0.09 | Entropy loss: -0.0046  | Total Loss: 0.08 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 60/100  | Episode Reward: 10  | Average Reward 8.44  | Actor loss: 0.01 | Critic loss: 1.18 | Entropy loss: -0.0175  | Total Loss: 1.18 | Total Steps: 73\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 61/100  | Episode Reward: -5  | Average Reward 8.29  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0301  | Total Loss: -0.03 | Total Steps: 84\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 10  | Average Reward 8.31  | Actor loss: 0.00 | Critic loss: 2.18 | Entropy loss: -0.0385  | Total Loss: 2.14 | Total Steps: 11\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: 5  | Average Reward 8.27  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0023  | Total Loss: 0.19 | Total Steps: 42\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 64/100  | Episode Reward: 10  | Average Reward 8.27  | Actor loss: 0.00 | Critic loss: 0.24 | Entropy loss: -0.0004  | Total Loss: 0.24 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 65/100  | Episode Reward: 10  | Average Reward 8.27  | Actor loss: 0.02 | Critic loss: 5.05 | Entropy loss: -0.0165  | Total Loss: 5.05 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 8  | Average Reward 8.24  | Actor loss: -0.00 | Critic loss: 0.06 | Entropy loss: -0.0104  | Total Loss: 0.05 | Total Steps: 68\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 10  | Average Reward 8.29  | Actor loss: 0.00 | Critic loss: 0.66 | Entropy loss: -0.0020  | Total Loss: 0.67 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 68/100  | Episode Reward: 10  | Average Reward 8.29  | Actor loss: 0.05 | Critic loss: 4.28 | Entropy loss: -0.0436  | Total Loss: 4.29 | Total Steps: 45\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 10  | Average Reward 8.29  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0213  | Total Loss: 0.01 | Total Steps: 66\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 70/100  | Episode Reward: 8  | Average Reward 8.27  | Actor loss: 0.26 | Critic loss: 10.69 | Entropy loss: -0.0152  | Total Loss: 10.93 | Total Steps: 37\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 10  | Average Reward 8.27  | Actor loss: 0.01 | Critic loss: 0.70 | Entropy loss: -0.0597  | Total Loss: 0.66 | Total Steps: 7\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 9  | Average Reward 8.28  | Actor loss: 0.00 | Critic loss: 0.27 | Entropy loss: -0.0470  | Total Loss: 0.22 | Total Steps: 34\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 10  | Average Reward 8.28  | Actor loss: -0.02 | Critic loss: 0.16 | Entropy loss: -0.0081  | Total Loss: 0.13 | Total Steps: 46\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: 10  | Average Reward 8.33  | Actor loss: 0.00 | Critic loss: 0.41 | Entropy loss: -0.0019  | Total Loss: 0.41 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 10  | Average Reward 8.33  | Actor loss: -0.00 | Critic loss: 0.35 | Entropy loss: -0.0009  | Total Loss: 0.34 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 10  | Average Reward 8.33  | Actor loss: 0.00 | Critic loss: 0.62 | Entropy loss: -0.0016  | Total Loss: 0.62 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 77/100  | Episode Reward: 8  | Average Reward 8.51  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0177  | Total Loss: 0.02 | Total Steps: 32\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 8  | Average Reward 8.48  | Actor loss: 0.00 | Critic loss: 0.31 | Entropy loss: -0.0065  | Total Loss: 0.30 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 10  | Average Reward 8.51  | Actor loss: 0.01 | Critic loss: 3.31 | Entropy loss: -0.0147  | Total Loss: 3.31 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 10  | Average Reward 8.52  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0195  | Total Loss: 0.12 | Total Steps: 37\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 10  | Average Reward 8.54  | Actor loss: -0.00 | Critic loss: 0.31 | Entropy loss: -0.0039  | Total Loss: 0.30 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: 10  | Average Reward 8.54  | Actor loss: 0.02 | Critic loss: 4.48 | Entropy loss: -0.0551  | Total Loss: 4.45 | Total Steps: 43\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 10  | Average Reward 8.56  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0045  | Total Loss: 0.01 | Total Steps: 35\n",
      "TEST: ---yellow prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 84/100  | Episode Reward: 10  | Average Reward 8.56  | Actor loss: 0.00 | Critic loss: 0.29 | Entropy loss: -0.0879  | Total Loss: 0.20 | Total Steps: 13\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 85/100  | Episode Reward: 5  | Average Reward 8.71  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0131  | Total Loss: 0.10 | Total Steps: 47\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: 8  | Average Reward 8.74  | Actor loss: 0.00 | Critic loss: 0.65 | Entropy loss: -0.0079  | Total Loss: 0.65 | Total Steps: 29\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 8  | Average Reward 8.71  | Actor loss: 0.00 | Critic loss: 0.25 | Entropy loss: -0.0166  | Total Loss: 0.24 | Total Steps: 64\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 10  | Average Reward 8.77  | Actor loss: 1.63 | Critic loss: 14.60 | Entropy loss: -0.0191  | Total Loss: 16.20 | Total Steps: 7\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 89/100  | Episode Reward: 8  | Average Reward 8.77  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0225  | Total Loss: -0.00 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 90/100  | Episode Reward: -10  | Average Reward 8.56  | Actor loss: -0.01 | Critic loss: 63.09 | Entropy loss: -0.0001  | Total Loss: 63.08 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 10  | Average Reward 8.56  | Actor loss: 0.00 | Critic loss: 0.43 | Entropy loss: -0.0137  | Total Loss: 0.42 | Total Steps: 22\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 10  | Average Reward 8.56  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0026  | Total Loss: 0.11 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: 10  | Average Reward 8.59  | Actor loss: 0.01 | Critic loss: 0.33 | Entropy loss: -0.0275  | Total Loss: 0.31 | Total Steps: 7\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 8  | Average Reward 8.56  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0014  | Total Loss: 0.08 | Total Steps: 38\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: 10  | Average Reward 8.56  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0080  | Total Loss: -0.01 | Total Steps: 52\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 10  | Average Reward 8.56  | Actor loss: 0.00 | Critic loss: 0.74 | Entropy loss: -0.0312  | Total Loss: 0.71 | Total Steps: 13\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 10  | Average Reward 8.59  | Actor loss: 0.04 | Critic loss: 5.24 | Entropy loss: -0.0541  | Total Loss: 5.23 | Total Steps: 53\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: 8  | Average Reward 8.62  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0018  | Total Loss: 0.09 | Total Steps: 38\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 8  | Average Reward 8.59  | Actor loss: 0.00 | Critic loss: 1.31 | Entropy loss: -0.0105  | Total Loss: 1.31 | Total Steps: 25\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 8  | Average Reward 8.56  | Actor loss: 0.00 | Critic loss: 0.48 | Entropy loss: -0.0006  | Total Loss: 0.48 | Total Steps: 29\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 7.075. Model has been saved-----\n",
      "Training  | Episode: 102/94000  | Episode Reward: 10  | Average Reward 7.08  | Actor loss: 0.05 | Critic loss: 1.06 | Entropy loss: -0.0013  | Total Loss: 1.11 | Total Steps: 41\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 103/94000  | Episode Reward: 10  | Average Reward 7.08  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 104/94000  | Episode Reward: 10  | Average Reward 7.08  | Actor loss: -0.03 | Critic loss: 1.31 | Entropy loss: -0.0002  | Total Loss: 1.28 | Total Steps: 49\n",
      "\n",
      "---yellow cube---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 105/94000  | Episode Reward: 5  | Average Reward 7.05  | Actor loss: -0.47 | Critic loss: 6.61 | Entropy loss: -0.0026  | Total Loss: 6.13 | Total Steps: 42\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 106/94000  | Episode Reward: 10  | Average Reward 7.05  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---red cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 107/94000  | Episode Reward: 8  | Average Reward 7.08  | Actor loss: 0.00 | Critic loss: 2.42 | Entropy loss: -0.0017  | Total Loss: 2.42 | Total Steps: 53\n",
      "\n",
      "---red sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 108/94000  | Episode Reward: 8  | Average Reward 7.05  | Actor loss: -0.43 | Critic loss: 5.82 | Entropy loss: -0.0014  | Total Loss: 5.39 | Total Steps: 28\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 7.225. Model has been saved-----\n",
      "Training  | Episode: 109/94000  | Episode Reward: 8  | Average Reward 7.22  | Actor loss: -0.48 | Critic loss: 7.97 | Entropy loss: -0.0013  | Total Loss: 7.49 | Total Steps: 42\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 110/94000  | Episode Reward: 10  | Average Reward 7.22  | Actor loss: -0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 111/94000  | Episode Reward: 10  | Average Reward 7.22  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0000  | Total Loss: 0.20 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 112/94000  | Episode Reward: 10  | Average Reward 7.22  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 113/94000  | Episode Reward: 8  | Average Reward 7.22  | Actor loss: 0.01 | Critic loss: 1.74 | Entropy loss: -0.0001  | Total Loss: 1.74 | Total Steps: 39\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 7.25. Model has been saved-----\n",
      "Training  | Episode: 114/94000  | Episode Reward: 10  | Average Reward 7.25  | Actor loss: -0.01 | Critic loss: 1.65 | Entropy loss: -0.0001  | Total Loss: 1.65 | Total Steps: 38\n",
      "\n",
      "---blue cube---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 115/94000  | Episode Reward: 8  | Average Reward 7.22  | Actor loss: 0.02 | Critic loss: 2.60 | Entropy loss: -0.0007  | Total Loss: 2.62 | Total Steps: 44\n",
      "\n",
      "---red sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 116/94000  | Episode Reward: 8  | Average Reward 7.22  | Actor loss: -0.47 | Critic loss: 5.42 | Entropy loss: -0.0023  | Total Loss: 4.95 | Total Steps: 55\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 117/94000  | Episode Reward: 10  | Average Reward 7.22  | Actor loss: 0.00 | Critic loss: 1.57 | Entropy loss: -0.0001  | Total Loss: 1.57 | Total Steps: 38\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 7.3. Model has been saved-----\n",
      "Training  | Episode: 118/94000  | Episode Reward: 10  | Average Reward 7.30  | Actor loss: -0.09 | Critic loss: 1.99 | Entropy loss: -0.0040  | Total Loss: 1.90 | Total Steps: 41\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 119/94000  | Episode Reward: 10  | Average Reward 7.30  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0000  | Total Loss: 0.08 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 120/94000  | Episode Reward: 8  | Average Reward 7.28  | Actor loss: -0.15 | Critic loss: 7.00 | Entropy loss: -0.0081  | Total Loss: 6.84 | Total Steps: 103\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 121/94000  | Episode Reward: 10  | Average Reward 7.28  | Actor loss: 0.04 | Critic loss: 3.98 | Entropy loss: -0.0005  | Total Loss: 4.02 | Total Steps: 31\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 122/94000  | Episode Reward: 10  | Average Reward 7.28  | Actor loss: 0.00 | Critic loss: 3.00 | Entropy loss: -0.0000  | Total Loss: 3.00 | Total Steps: 31\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 123/94000  | Episode Reward: 10  | Average Reward 7.28  | Actor loss: 0.00 | Critic loss: 2.44 | Entropy loss: -0.0000  | Total Loss: 2.44 | Total Steps: 31\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 124/94000  | Episode Reward: 10  | Average Reward 7.28  | Actor loss: 0.00 | Critic loss: 1.78 | Entropy loss: -0.0000  | Total Loss: 1.78 | Total Steps: 31\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 7.475. Model has been saved-----\n",
      "Training  | Episode: 125/94000  | Episode Reward: 10  | Average Reward 7.47  | Actor loss: 0.00 | Critic loss: 4.39 | Entropy loss: -0.0000  | Total Loss: 4.39 | Total Steps: 29\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 126/94000  | Episode Reward: 10  | Average Reward 7.47  | Actor loss: 0.02 | Critic loss: 0.94 | Entropy loss: -0.0000  | Total Loss: 0.96 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 127/94000  | Episode Reward: 10  | Average Reward 7.47  | Actor loss: -0.31 | Critic loss: 0.67 | Entropy loss: -0.0028  | Total Loss: 0.36 | Total Steps: 40\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 128/94000  | Episode Reward: 10  | Average Reward 7.47  | Actor loss: 0.11 | Critic loss: 5.50 | Entropy loss: -0.0006  | Total Loss: 5.61 | Total Steps: 29\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 129/94000  | Episode Reward: 10  | Average Reward 7.47  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 130/94000  | Episode Reward: 10  | Average Reward 7.47  | Actor loss: -0.00 | Critic loss: 1.76 | Entropy loss: -0.0001  | Total Loss: 1.76 | Total Steps: 31\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 7.5. Model has been saved-----\n",
      "Training  | Episode: 131/94000  | Episode Reward: 10  | Average Reward 7.50  | Actor loss: 0.41 | Critic loss: 7.12 | Entropy loss: -0.0006  | Total Loss: 7.53 | Total Steps: 12\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 7.525. Model has been saved-----\n",
      "Training  | Episode: 132/94000  | Episode Reward: 10  | Average Reward 7.53  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0000  | Total Loss: 0.16 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 133/94000  | Episode Reward: 10  | Average Reward 7.53  | Actor loss: 0.00 | Critic loss: 0.93 | Entropy loss: -0.0000  | Total Loss: 0.93 | Total Steps: 31\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 134/94000  | Episode Reward: 10  | Average Reward 7.53  | Actor loss: 0.05 | Critic loss: 1.11 | Entropy loss: -0.0001  | Total Loss: 1.16 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 7.725. Model has been saved-----\n",
      "Training  | Episode: 135/94000  | Episode Reward: 10  | Average Reward 7.72  | Actor loss: -0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 7.75. Model has been saved-----\n",
      "Training  | Episode: 136/94000  | Episode Reward: 10  | Average Reward 7.75  | Actor loss: -0.22 | Critic loss: 5.78 | Entropy loss: -0.0011  | Total Loss: 5.56 | Total Steps: 47\n",
      "\n",
      "---yellow cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 137/94000  | Episode Reward: 8  | Average Reward 7.72  | Actor loss: -0.94 | Critic loss: 5.57 | Entropy loss: -0.0022  | Total Loss: 4.63 | Total Steps: 15\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 138/94000  | Episode Reward: 10  | Average Reward 7.72  | Actor loss: 0.02 | Critic loss: 1.33 | Entropy loss: -0.0000  | Total Loss: 1.36 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 139/94000  | Episode Reward: 10  | Average Reward 7.72  | Actor loss: -0.38 | Critic loss: 3.61 | Entropy loss: -0.0073  | Total Loss: 3.22 | Total Steps: 61\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 140/94000  | Episode Reward: 10  | Average Reward 7.72  | Actor loss: -0.39 | Critic loss: 5.14 | Entropy loss: -0.0027  | Total Loss: 4.75 | Total Steps: 52\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 141/94000  | Episode Reward: 10  | Average Reward 7.72  | Actor loss: 0.06 | Critic loss: 1.42 | Entropy loss: -0.0013  | Total Loss: 1.48 | Total Steps: 30\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 142/94000  | Episode Reward: 10  | Average Reward 7.72  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0000  | Total Loss: 0.11 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 143/94000  | Episode Reward: 10  | Average Reward 7.72  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0000  | Total Loss: 0.12 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 144/94000  | Episode Reward: 10  | Average Reward 7.72  | Actor loss: -0.00 | Critic loss: 0.87 | Entropy loss: -0.0005  | Total Loss: 0.87 | Total Steps: 50\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 7.9. Model has been saved-----\n",
      "Training  | Episode: 145/94000  | Episode Reward: 8  | Average Reward 7.90  | Actor loss: -0.22 | Critic loss: 3.23 | Entropy loss: -0.0018  | Total Loss: 3.01 | Total Steps: 79\n",
      "\n",
      "---green sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 146/94000  | Episode Reward: 10  | Average Reward 7.90  | Actor loss: -0.08 | Critic loss: 2.97 | Entropy loss: -0.0008  | Total Loss: 2.90 | Total Steps: 48\n",
      "\n",
      "---black capsule---\n",
      "Step: 250\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 147/94000  | Episode Reward: 8  | Average Reward 7.90  | Actor loss: -0.04 | Critic loss: 3.43 | Entropy loss: -0.0013  | Total Loss: 3.39 | Total Steps: 349\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 148/94000  | Episode Reward: 10  | Average Reward 7.90  | Actor loss: 0.08 | Critic loss: 3.88 | Entropy loss: -0.0023  | Total Loss: 3.96 | Total Steps: 47\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 8.325. Model has been saved-----\n",
      "Training  | Episode: 149/94000  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0000  | Total Loss: 0.12 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 8.35. Model has been saved-----\n",
      "Training  | Episode: 150/94000  | Episode Reward: 10  | Average Reward 8.35  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0000  | Total Loss: 0.17 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 8.375. Model has been saved-----\n",
      "Training  | Episode: 151/94000  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 0.67 | Entropy loss: -0.0005  | Total Loss: 0.67 | Total Steps: 43\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 152/94000  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: 0.03 | Critic loss: 0.66 | Entropy loss: -0.0000  | Total Loss: 0.70 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 153/94000  | Episode Reward: 5  | Average Reward 8.35  | Actor loss: -0.71 | Critic loss: 8.17 | Entropy loss: -0.0023  | Total Loss: 7.46 | Total Steps: 49\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 154/94000  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 1.83 | Entropy loss: -0.0000  | Total Loss: 1.83 | Total Steps: 31\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 155/94000  | Episode Reward: 8  | Average Reward 8.35  | Actor loss: -0.13 | Critic loss: 0.36 | Entropy loss: -0.0025  | Total Loss: 0.23 | Total Steps: 40\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 156/94000  | Episode Reward: 10  | Average Reward 8.35  | Actor loss: -0.02 | Critic loss: 0.40 | Entropy loss: -0.0014  | Total Loss: 0.38 | Total Steps: 51\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 157/94000  | Episode Reward: 10  | Average Reward 8.35  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 158/94000  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 1.73 | Entropy loss: -0.0000  | Total Loss: 1.73 | Total Steps: 31\n",
      "\n",
      "---red cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 159/94000  | Episode Reward: 8  | Average Reward 8.35  | Actor loss: -0.14 | Critic loss: 1.94 | Entropy loss: -0.0015  | Total Loss: 1.79 | Total Steps: 49\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 160/94000  | Episode Reward: 10  | Average Reward 8.35  | Actor loss: 0.00 | Critic loss: 1.61 | Entropy loss: -0.0000  | Total Loss: 1.61 | Total Steps: 31\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 161/94000  | Episode Reward: 8  | Average Reward 8.32  | Actor loss: -0.49 | Critic loss: 2.14 | Entropy loss: -0.0021  | Total Loss: 1.65 | Total Steps: 39\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 162/94000  | Episode Reward: 10  | Average Reward 8.35  | Actor loss: 0.00 | Critic loss: 1.33 | Entropy loss: -0.0001  | Total Loss: 1.33 | Total Steps: 31\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 163/94000  | Episode Reward: 8  | Average Reward 8.32  | Actor loss: -0.47 | Critic loss: 1.91 | Entropy loss: -0.0034  | Total Loss: 1.44 | Total Steps: 37\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 164/94000  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: -0.14 | Critic loss: 3.37 | Entropy loss: -0.0058  | Total Loss: 3.23 | Total Steps: 61\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 165/94000  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: 0.00 | Critic loss: 1.23 | Entropy loss: -0.0001  | Total Loss: 1.24 | Total Steps: 31\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 166/94000  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0000  | Total Loss: 0.10 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 167/94000  | Episode Reward: 10  | Average Reward 8.35  | Actor loss: 0.30 | Critic loss: 1.06 | Entropy loss: -0.0011  | Total Loss: 1.36 | Total Steps: 13\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 8.4. Model has been saved-----\n",
      "Training  | Episode: 168/94000  | Episode Reward: 10  | Average Reward 8.40  | Actor loss: 0.58 | Critic loss: 1.44 | Entropy loss: -0.0021  | Total Loss: 2.02 | Total Steps: 10\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 8.75. Model has been saved-----\n",
      "Training  | Episode: 169/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.09 | Critic loss: 4.14 | Entropy loss: -0.0007  | Total Loss: 4.23 | Total Steps: 39\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 170/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.43 | Critic loss: 1.00 | Entropy loss: -0.0062  | Total Loss: 1.43 | Total Steps: 33\n",
      "\n",
      "---yellow cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 171/94000  | Episode Reward: 8  | Average Reward 8.72  | Actor loss: -0.82 | Critic loss: 6.39 | Entropy loss: -0.0150  | Total Loss: 5.55 | Total Steps: 147\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 172/94000  | Episode Reward: 8  | Average Reward 8.70  | Actor loss: -0.00 | Critic loss: 1.47 | Entropy loss: -0.0001  | Total Loss: 1.47 | Total Steps: 38\n",
      "\n",
      "---yellow sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 173/94000  | Episode Reward: 8  | Average Reward 8.70  | Actor loss: -0.21 | Critic loss: 3.69 | Entropy loss: -0.0004  | Total Loss: 3.48 | Total Steps: 12\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 174/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: -0.19 | Critic loss: 4.06 | Entropy loss: -0.0013  | Total Loss: 3.87 | Total Steps: 24\n",
      "\n",
      "---black capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 8.875. Model has been saved-----\n",
      "Training  | Episode: 175/94000  | Episode Reward: 8  | Average Reward 8.88  | Actor loss: -0.01 | Critic loss: 3.48 | Entropy loss: -0.0001  | Total Loss: 3.47 | Total Steps: 49\n",
      "\n",
      "---blue capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 176/94000  | Episode Reward: 8  | Average Reward 8.85  | Actor loss: 0.02 | Critic loss: 1.35 | Entropy loss: -0.0032  | Total Loss: 1.36 | Total Steps: 104\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 9.05. Model has been saved-----\n",
      "Training  | Episode: 177/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.04 | Critic loss: 1.45 | Entropy loss: -0.0024  | Total Loss: 1.49 | Total Steps: 216\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 178/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0000  | Total Loss: 0.21 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 9.1. Model has been saved-----\n",
      "Training  | Episode: 179/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: -0.01 | Critic loss: 2.93 | Entropy loss: -0.0003  | Total Loss: 2.92 | Total Steps: 29\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 180/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: -0.60 | Critic loss: 4.08 | Entropy loss: -0.0055  | Total Loss: 3.48 | Total Steps: 53\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 181/94000  | Episode Reward: 8  | Average Reward 9.07  | Actor loss: -0.05 | Critic loss: 3.73 | Entropy loss: -0.0006  | Total Loss: 3.69 | Total Steps: 44\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 182/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: -0.42 | Critic loss: 1.61 | Entropy loss: -0.0036  | Total Loss: 1.19 | Total Steps: 53\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 183/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 184/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 185/94000  | Episode Reward: 5  | Average Reward 9.05  | Actor loss: -0.64 | Critic loss: 5.51 | Entropy loss: -0.0056  | Total Loss: 4.87 | Total Steps: 80\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 186/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.01 | Critic loss: 0.27 | Entropy loss: -0.0000  | Total Loss: 0.28 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 187/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.00 | Critic loss: 0.46 | Entropy loss: -0.0001  | Total Loss: 0.46 | Total Steps: 40\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 188/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.00 | Critic loss: 3.09 | Entropy loss: -0.0000  | Total Loss: 3.09 | Total Steps: 31\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 189/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.00 | Critic loss: 1.41 | Entropy loss: -0.0000  | Total Loss: 1.41 | Total Steps: 31\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 190/94000  | Episode Reward: 5  | Average Reward 9.00  | Actor loss: -0.10 | Critic loss: 5.54 | Entropy loss: -0.0023  | Total Loss: 5.44 | Total Steps: 152\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 191/94000  | Episode Reward: 10  | Average Reward 9.00  | Actor loss: 0.44 | Critic loss: 2.33 | Entropy loss: -0.0013  | Total Loss: 2.77 | Total Steps: 14\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 192/94000  | Episode Reward: 10  | Average Reward 9.00  | Actor loss: 0.00 | Critic loss: 2.64 | Entropy loss: -0.0001  | Total Loss: 2.64 | Total Steps: 31\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 193/94000  | Episode Reward: 10  | Average Reward 9.00  | Actor loss: 0.04 | Critic loss: 1.38 | Entropy loss: -0.0002  | Total Loss: 1.42 | Total Steps: 38\n",
      "\n",
      "---yellow cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 194/94000  | Episode Reward: 8  | Average Reward 9.00  | Actor loss: -0.69 | Critic loss: 4.93 | Entropy loss: -0.0240  | Total Loss: 4.21 | Total Steps: 163\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 195/94000  | Episode Reward: 5  | Average Reward 9.00  | Actor loss: -0.62 | Critic loss: 9.87 | Entropy loss: -0.0076  | Total Loss: 9.24 | Total Steps: 139\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 9.175. Model has been saved-----\n",
      "Training  | Episode: 196/94000  | Episode Reward: 8  | Average Reward 9.18  | Actor loss: -0.00 | Critic loss: 0.53 | Entropy loss: -0.0001  | Total Loss: 0.53 | Total Steps: 38\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 197/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.01 | Critic loss: 0.35 | Entropy loss: -0.0000  | Total Loss: 0.35 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 198/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.15 | Critic loss: 1.98 | Entropy loss: -0.0004  | Total Loss: 2.12 | Total Steps: 9\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 199/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0000  | Total Loss: 0.12 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 200/94000  | Episode Reward: 8  | Average Reward 9.18  | Actor loss: 0.17 | Critic loss: 7.91 | Entropy loss: -0.0028  | Total Loss: 8.08 | Total Steps: 43\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 201/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.05 | Critic loss: 2.25 | Entropy loss: -0.0002  | Total Loss: 2.30 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 8  | Average Reward 8.54  | Actor loss: 0.00 | Critic loss: 0.77 | Entropy loss: -0.0002  | Total Loss: 0.77 | Total Steps: 29\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 8  | Average Reward 8.52  | Actor loss: 0.00 | Critic loss: 0.29 | Entropy loss: -0.0018  | Total Loss: 0.29 | Total Steps: 29\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 3/100  | Episode Reward: -25  | Average Reward 8.16  | Actor loss: -16.29 | Critic loss: 70.49 | Entropy loss: -0.0692  | Total Loss: 54.14 | Total Steps: 500\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 8  | Average Reward 8.14  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0164  | Total Loss: 0.06 | Total Steps: 42\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 5  | Average Reward 8.12  | Actor loss: 0.00 | Critic loss: 0.33 | Entropy loss: -0.0015  | Total Loss: 0.33 | Total Steps: 42\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 4  | Average Reward 8.09  | Actor loss: 0.00 | Critic loss: 0.79 | Entropy loss: -0.0662  | Total Loss: 0.73 | Total Steps: 131\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: 10  | Average Reward 8.16  | Actor loss: 0.01 | Critic loss: 2.31 | Entropy loss: -0.0127  | Total Loss: 2.30 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 5  | Average Reward 8.13  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0017  | Total Loss: 0.01 | Total Steps: 46\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 5  | Average Reward 8.09  | Actor loss: 0.00 | Critic loss: 6.20 | Entropy loss: -0.0023  | Total Loss: 6.20 | Total Steps: 48\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 10  | Average Reward 8.09  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0060  | Total Loss: -0.01 | Total Steps: 56\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 5  | Average Reward 8.04  | Actor loss: 0.00 | Critic loss: 0.38 | Entropy loss: -0.0016  | Total Loss: 0.38 | Total Steps: 49\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 10  | Average Reward 8.04  | Actor loss: 0.16 | Critic loss: 4.23 | Entropy loss: -0.0055  | Total Loss: 4.39 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 10  | Average Reward 8.04  | Actor loss: 0.03 | Critic loss: 3.84 | Entropy loss: -0.0339  | Total Loss: 3.84 | Total Steps: 7\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: 10  | Average Reward 8.04  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0083  | Total Loss: 0.19 | Total Steps: 35\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 8  | Average Reward 8.01  | Actor loss: 0.00 | Critic loss: 0.26 | Entropy loss: -0.0052  | Total Loss: 0.26 | Total Steps: 34\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 10  | Average Reward 8.01  | Actor loss: 0.01 | Critic loss: 2.58 | Entropy loss: -0.0027  | Total Loss: 2.59 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 10  | Average Reward 8.01  | Actor loss: 0.03 | Critic loss: 1.98 | Entropy loss: -0.0129  | Total Loss: 2.00 | Total Steps: 9\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 10  | Average Reward 8.01  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0023  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 10  | Average Reward 8.01  | Actor loss: 0.01 | Critic loss: 2.04 | Entropy loss: -0.0398  | Total Loss: 2.01 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: 10  | Average Reward 8.01  | Actor loss: 0.30 | Critic loss: 7.25 | Entropy loss: -0.0081  | Total Loss: 7.54 | Total Steps: 40\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 10  | Average Reward 8.01  | Actor loss: 0.10 | Critic loss: 5.11 | Entropy loss: -0.0156  | Total Loss: 5.20 | Total Steps: 34\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 22/100  | Episode Reward: -17  | Average Reward 7.74  | Actor loss: 0.00 | Critic loss: 4.41 | Entropy loss: -0.0795  | Total Loss: 4.33 | Total Steps: 471\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 8  | Average Reward 7.71  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0073  | Total Loss: 0.01 | Total Steps: 39\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 5  | Average Reward 7.67  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0006  | Total Loss: 0.02 | Total Steps: 47\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 10  | Average Reward 7.67  | Actor loss: 0.02 | Critic loss: 3.59 | Entropy loss: -0.0052  | Total Loss: 3.61 | Total Steps: 50\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 8  | Average Reward 7.64  | Actor loss: 0.18 | Critic loss: 20.61 | Entropy loss: -0.0211  | Total Loss: 20.77 | Total Steps: 101\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 10  | Average Reward 7.69  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0039  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 10  | Average Reward 7.71  | Actor loss: 0.20 | Critic loss: 5.35 | Entropy loss: -0.0026  | Total Loss: 5.55 | Total Steps: 50\n",
      "TEST: ---black sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 400\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 8  | Average Reward 7.74  | Actor loss: 0.07 | Critic loss: 0.08 | Entropy loss: -0.0017  | Total Loss: 0.15 | Total Steps: 425\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 30/100  | Episode Reward: -30  | Average Reward 7.34  | Actor loss: -1.14 | Critic loss: 89.01 | Entropy loss: -0.0707  | Total Loss: 87.80 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 8  | Average Reward 7.32  | Actor loss: 0.00 | Critic loss: 0.22 | Entropy loss: -0.0024  | Total Loss: 0.21 | Total Steps: 34\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 32/100  | Episode Reward: 8  | Average Reward 7.29  | Actor loss: -0.00 | Critic loss: 0.07 | Entropy loss: -0.0073  | Total Loss: 0.06 | Total Steps: 40\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 33/100  | Episode Reward: 10  | Average Reward 7.32  | Actor loss: 0.18 | Critic loss: 2.11 | Entropy loss: -0.0034  | Total Loss: 2.29 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 34/100  | Episode Reward: 8  | Average Reward 7.29  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0168  | Total Loss: -0.02 | Total Steps: 45\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 35/100  | Episode Reward: -11  | Average Reward 7.08  | Actor loss: -0.00 | Critic loss: 79.30 | Entropy loss: -0.0018  | Total Loss: 79.29 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 36/100  | Episode Reward: 5  | Average Reward 7.03  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0005  | Total Loss: 0.02 | Total Steps: 47\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 37/100  | Episode Reward: -27  | Average Reward 6.66  | Actor loss: -3.74 | Critic loss: 89.70 | Entropy loss: -0.0719  | Total Loss: 85.90 | Total Steps: 500\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: 10  | Average Reward 6.66  | Actor loss: 0.00 | Critic loss: 1.00 | Entropy loss: -0.0293  | Total Loss: 0.98 | Total Steps: 10\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 8  | Average Reward 6.66  | Actor loss: 0.00 | Critic loss: 0.28 | Entropy loss: -0.0020  | Total Loss: 0.28 | Total Steps: 29\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 8  | Average Reward 6.64  | Actor loss: 13.59 | Critic loss: 29.21 | Entropy loss: -0.0571  | Total Loss: 42.74 | Total Steps: 76\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 8  | Average Reward 6.62  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0130  | Total Loss: 0.06 | Total Steps: 59\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 10  | Average Reward 6.82  | Actor loss: 0.00 | Critic loss: 0.31 | Entropy loss: -0.0354  | Total Loss: 0.28 | Total Steps: 10\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 43/100  | Episode Reward: 10  | Average Reward 6.87  | Actor loss: 0.00 | Critic loss: 23.25 | Entropy loss: -0.0551  | Total Loss: 23.20 | Total Steps: 8\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 8  | Average Reward 6.84  | Actor loss: 0.09 | Critic loss: 0.11 | Entropy loss: -0.0040  | Total Loss: 0.20 | Total Steps: 95\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: 8  | Average Reward 6.82  | Actor loss: 0.00 | Critic loss: 0.34 | Entropy loss: -0.0044  | Total Loss: 0.33 | Total Steps: 65\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 5  | Average Reward 6.76  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0093  | Total Loss: 0.03 | Total Steps: 49\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 10  | Average Reward 6.76  | Actor loss: 0.08 | Critic loss: 1.83 | Entropy loss: -0.0026  | Total Loss: 1.90 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 10  | Average Reward 6.76  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0003  | Total Loss: 0.02 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 7  | Average Reward 6.76  | Actor loss: 8.97 | Critic loss: 32.38 | Entropy loss: -0.0574  | Total Loss: 41.30 | Total Steps: 137\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 10  | Average Reward 6.76  | Actor loss: 0.00 | Critic loss: 1.11 | Entropy loss: -0.0129  | Total Loss: 1.11 | Total Steps: 9\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 9  | Average Reward 6.75  | Actor loss: 0.01 | Critic loss: 4.77 | Entropy loss: -0.0542  | Total Loss: 4.73 | Total Steps: 103\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 10  | Average Reward 6.78  | Actor loss: 0.00 | Critic loss: 0.43 | Entropy loss: -0.0109  | Total Loss: 0.42 | Total Steps: 9\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing  | Episode: 53/100  | Episode Reward: 10  | Average Reward 6.83  | Actor loss: 0.00 | Critic loss: 0.74 | Entropy loss: -0.0211  | Total Loss: 0.72 | Total Steps: 9\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 54/100  | Episode Reward: 10  | Average Reward 6.85  | Actor loss: 0.09 | Critic loss: 1.70 | Entropy loss: -0.0049  | Total Loss: 1.79 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 5  | Average Reward 6.80  | Actor loss: 0.15 | Critic loss: 10.07 | Entropy loss: -0.0711  | Total Loss: 10.16 | Total Steps: 164\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: 8  | Average Reward 6.78  | Actor loss: 0.00 | Critic loss: 0.75 | Entropy loss: -0.0028  | Total Loss: 0.75 | Total Steps: 29\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 10  | Average Reward 6.78  | Actor loss: 0.00 | Critic loss: 0.45 | Entropy loss: -0.0125  | Total Loss: 0.44 | Total Steps: 10\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 10  | Average Reward 6.78  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0006  | Total Loss: -0.00 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 10  | Average Reward 6.78  | Actor loss: 0.00 | Critic loss: 0.41 | Entropy loss: -0.0209  | Total Loss: 0.39 | Total Steps: 10\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 60/100  | Episode Reward: 10  | Average Reward 6.78  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0009  | Total Loss: -0.00 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 61/100  | Episode Reward: 9  | Average Reward 6.92  | Actor loss: 0.03 | Critic loss: 9.13 | Entropy loss: -0.0551  | Total Loss: 9.11 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 8  | Average Reward 6.89  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0019  | Total Loss: 0.07 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: 4  | Average Reward 6.88  | Actor loss: 0.02 | Critic loss: 6.36 | Entropy loss: -0.0620  | Total Loss: 6.32 | Total Steps: 280\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 64/100  | Episode Reward: 8  | Average Reward 6.86  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0056  | Total Loss: 0.11 | Total Steps: 37\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 65/100  | Episode Reward: 8  | Average Reward 6.83  | Actor loss: -0.00 | Critic loss: 0.04 | Entropy loss: -0.0219  | Total Loss: 0.02 | Total Steps: 37\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 10  | Average Reward 6.86  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0038  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 8  | Average Reward 6.83  | Actor loss: 0.00 | Critic loss: 0.29 | Entropy loss: -0.0017  | Total Loss: 0.29 | Total Steps: 29\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 68/100  | Episode Reward: -10  | Average Reward 6.63  | Actor loss: -0.00 | Critic loss: 79.13 | Entropy loss: -0.0001  | Total Loss: 79.12 | Total Steps: 500\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 10  | Average Reward 6.63  | Actor loss: 0.12 | Critic loss: 4.82 | Entropy loss: -0.0020  | Total Loss: 4.93 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 70/100  | Episode Reward: 10  | Average Reward 6.66  | Actor loss: 0.00 | Critic loss: 0.96 | Entropy loss: -0.0065  | Total Loss: 0.96 | Total Steps: 8\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 10  | Average Reward 6.66  | Actor loss: 0.03 | Critic loss: 2.09 | Entropy loss: -0.0383  | Total Loss: 2.08 | Total Steps: 8\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: -10  | Average Reward 6.46  | Actor loss: 0.01 | Critic loss: 2.15 | Entropy loss: -0.0601  | Total Loss: 2.10 | Total Steps: 341\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 10  | Average Reward 6.46  | Actor loss: 0.44 | Critic loss: 5.60 | Entropy loss: -0.0218  | Total Loss: 6.02 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: -4  | Average Reward 6.33  | Actor loss: 3.79 | Critic loss: 20.09 | Entropy loss: -0.0717  | Total Loss: 23.81 | Total Steps: 156\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 10  | Average Reward 6.33  | Actor loss: -0.00 | Critic loss: 0.12 | Entropy loss: -0.0132  | Total Loss: 0.11 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 3  | Average Reward 6.25  | Actor loss: 0.00 | Critic loss: 4.75 | Entropy loss: -0.0685  | Total Loss: 4.69 | Total Steps: 145\n",
      "TEST: ---red capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 77/100  | Episode Reward: 10  | Average Reward 6.28  | Actor loss: 0.01 | Critic loss: 0.63 | Entropy loss: -0.0182  | Total Loss: 0.62 | Total Steps: 97\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 8  | Average Reward 6.28  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0009  | Total Loss: 0.20 | Total Steps: 34\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 10  | Average Reward 6.28  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0338  | Total Loss: 0.11 | Total Steps: 7\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 5  | Average Reward 6.23  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0029  | Total Loss: 0.00 | Total Steps: 46\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 10  | Average Reward 6.23  | Actor loss: 0.00 | Critic loss: 0.77 | Entropy loss: -0.0399  | Total Loss: 0.73 | Total Steps: 10\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: 10  | Average Reward 6.23  | Actor loss: 0.53 | Critic loss: 5.92 | Entropy loss: -0.0278  | Total Loss: 6.42 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 10  | Average Reward 6.23  | Actor loss: 0.01 | Critic loss: 2.90 | Entropy loss: -0.0406  | Total Loss: 2.87 | Total Steps: 9\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 84/100  | Episode Reward: 10  | Average Reward 6.23  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0121  | Total Loss: -0.01 | Total Steps: 49\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 85/100  | Episode Reward: -2  | Average Reward 6.16  | Actor loss: 0.25 | Critic loss: 2.51 | Entropy loss: -0.0531  | Total Loss: 2.71 | Total Steps: 186\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: 10  | Average Reward 6.18  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0828  | Total Loss: 0.13 | Total Steps: 11\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 10  | Average Reward 6.21  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0033  | Total Loss: -0.00 | Total Steps: 156\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 8  | Average Reward 6.18  | Actor loss: 0.00 | Critic loss: 1.11 | Entropy loss: -0.0117  | Total Loss: 1.10 | Total Steps: 46\n",
      "TEST: ---green cube---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 89/100  | Episode Reward: -10  | Average Reward 6.01  | Actor loss: -0.01 | Critic loss: 86.96 | Entropy loss: -0.0001  | Total Loss: 86.95 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 90/100  | Episode Reward: 10  | Average Reward 6.21  | Actor loss: 0.00 | Critic loss: 1.28 | Entropy loss: -0.0012  | Total Loss: 1.29 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 10  | Average Reward 6.21  | Actor loss: 0.01 | Critic loss: 1.57 | Entropy loss: -0.0123  | Total Loss: 1.57 | Total Steps: 9\n",
      "TEST: ---green cube---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 10  | Average Reward 6.21  | Actor loss: 0.00 | Critic loss: 6.35 | Entropy loss: -0.0089  | Total Loss: 6.34 | Total Steps: 214\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: 10  | Average Reward 6.21  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0038  | Total Loss: 0.20 | Total Steps: 36\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 10  | Average Reward 6.24  | Actor loss: 0.00 | Critic loss: 0.33 | Entropy loss: -0.0309  | Total Loss: 0.30 | Total Steps: 7\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: 8  | Average Reward 6.21  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0013  | Total Loss: 0.08 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 8  | Average Reward 6.18  | Actor loss: 0.04 | Critic loss: 22.29 | Entropy loss: -0.0183  | Total Loss: 22.31 | Total Steps: 29\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 10  | Average Reward 6.18  | Actor loss: 0.00 | Critic loss: 0.88 | Entropy loss: -0.0245  | Total Loss: 0.86 | Total Steps: 7\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: 10  | Average Reward 6.21  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0012  | Total Loss: 0.00 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 5  | Average Reward 6.18  | Actor loss: 0.00 | Critic loss: 0.91 | Entropy loss: -0.0007  | Total Loss: 0.91 | Total Steps: 42\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 10  | Average Reward 6.21  | Actor loss: 0.11 | Critic loss: 9.21 | Entropy loss: -0.0099  | Total Loss: 9.31 | Total Steps: 45\n",
      "\n",
      "---black prism---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 202/94000  | Episode Reward: -10  | Average Reward 8.97  | Actor loss: -0.00 | Critic loss: 5.14 | Entropy loss: -0.0001  | Total Loss: 5.14 | Total Steps: 500\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 203/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 204/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.24 | Critic loss: 0.53 | Entropy loss: -0.0007  | Total Loss: 0.77 | Total Steps: 11\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 205/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.08 | Critic loss: 1.72 | Entropy loss: -0.0003  | Total Loss: 1.80 | Total Steps: 9\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 206/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.00 | Critic loss: 1.95 | Entropy loss: -0.0000  | Total Loss: 1.95 | Total Steps: 31\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 207/94000  | Episode Reward: 8  | Average Reward 9.03  | Actor loss: -0.01 | Critic loss: 2.10 | Entropy loss: -0.0002  | Total Loss: 2.09 | Total Steps: 29\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 208/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.02 | Critic loss: 0.24 | Entropy loss: -0.0009  | Total Loss: 0.26 | Total Steps: 40\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 209/94000  | Episode Reward: 10  | Average Reward 9.07  | Actor loss: 1.72 | Critic loss: 4.03 | Entropy loss: -0.0015  | Total Loss: 5.75 | Total Steps: 8\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 210/94000  | Episode Reward: 8  | Average Reward 9.05  | Actor loss: -0.43 | Critic loss: 6.57 | Entropy loss: -0.0009  | Total Loss: 6.15 | Total Steps: 25\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 211/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.04 | Critic loss: 0.56 | Entropy loss: -0.0001  | Total Loss: 0.60 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 212/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.02 | Critic loss: 0.95 | Entropy loss: -0.0076  | Total Loss: 0.96 | Total Steps: 50\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 213/94000  | Episode Reward: 10  | Average Reward 9.07  | Actor loss: -0.04 | Critic loss: 2.62 | Entropy loss: -0.0005  | Total Loss: 2.58 | Total Steps: 47\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 214/94000  | Episode Reward: 10  | Average Reward 9.07  | Actor loss: -0.10 | Critic loss: 1.65 | Entropy loss: -0.0045  | Total Loss: 1.55 | Total Steps: 46\n",
      "\n",
      "---red sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 215/94000  | Episode Reward: 8  | Average Reward 9.07  | Actor loss: -0.43 | Critic loss: 5.92 | Entropy loss: -0.0027  | Total Loss: 5.49 | Total Steps: 50\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 216/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: -0.11 | Critic loss: 1.02 | Entropy loss: -0.0006  | Total Loss: 0.92 | Total Steps: 35\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 217/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: 0.28 | Critic loss: 1.05 | Entropy loss: -0.0006  | Total Loss: 1.33 | Total Steps: 8\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 218/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0000  | Total Loss: 0.11 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 219/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: 0.07 | Critic loss: 0.20 | Entropy loss: -0.0005  | Total Loss: 0.27 | Total Steps: 9\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 220/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.03 | Critic loss: 1.00 | Entropy loss: -0.0013  | Total Loss: 1.03 | Total Steps: 31\n",
      "\n",
      "---yellow sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 221/94000  | Episode Reward: 8  | Average Reward 9.10  | Actor loss: -0.41 | Critic loss: 6.53 | Entropy loss: -0.0062  | Total Loss: 6.11 | Total Steps: 59\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 222/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0000  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 223/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: -0.13 | Critic loss: 2.85 | Entropy loss: -0.0023  | Total Loss: 2.71 | Total Steps: 25\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 224/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: 0.59 | Critic loss: 2.15 | Entropy loss: -0.0017  | Total Loss: 2.74 | Total Steps: 12\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 225/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: -0.15 | Critic loss: 3.68 | Entropy loss: -0.0009  | Total Loss: 3.53 | Total Steps: 45\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 226/94000  | Episode Reward: 5  | Average Reward 9.05  | Actor loss: -0.11 | Critic loss: 3.01 | Entropy loss: -0.0006  | Total Loss: 2.89 | Total Steps: 45\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 227/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.12 | Critic loss: 0.81 | Entropy loss: -0.0006  | Total Loss: 0.93 | Total Steps: 12\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 228/94000  | Episode Reward: 5  | Average Reward 9.00  | Actor loss: -0.01 | Critic loss: 2.28 | Entropy loss: -0.0003  | Total Loss: 2.27 | Total Steps: 47\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 229/94000  | Episode Reward: 10  | Average Reward 9.00  | Actor loss: -0.50 | Critic loss: 1.66 | Entropy loss: -0.0032  | Total Loss: 1.16 | Total Steps: 46\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 230/94000  | Episode Reward: 10  | Average Reward 9.00  | Actor loss: -0.23 | Critic loss: 1.63 | Entropy loss: -0.0014  | Total Loss: 1.40 | Total Steps: 39\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 231/94000  | Episode Reward: 10  | Average Reward 9.00  | Actor loss: 0.00 | Critic loss: 1.66 | Entropy loss: -0.0000  | Total Loss: 1.67 | Total Steps: 31\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 232/94000  | Episode Reward: 10  | Average Reward 9.00  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 233/94000  | Episode Reward: 10  | Average Reward 9.00  | Actor loss: 0.11 | Critic loss: 0.17 | Entropy loss: -0.0006  | Total Loss: 0.27 | Total Steps: 8\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 234/94000  | Episode Reward: 10  | Average Reward 9.00  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0000  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 235/94000  | Episode Reward: 10  | Average Reward 9.00  | Actor loss: -0.00 | Critic loss: 0.28 | Entropy loss: -0.0001  | Total Loss: 0.28 | Total Steps: 38\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 236/94000  | Episode Reward: 10  | Average Reward 9.00  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 237/94000  | Episode Reward: -10  | Average Reward 8.82  | Actor loss: -0.00 | Critic loss: 3.55 | Entropy loss: -0.0001  | Total Loss: 3.55 | Total Steps: 500\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 238/94000  | Episode Reward: 10  | Average Reward 8.82  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 239/94000  | Episode Reward: 10  | Average Reward 8.82  | Actor loss: 0.02 | Critic loss: 4.12 | Entropy loss: -0.0004  | Total Loss: 4.13 | Total Steps: 29\n",
      "\n",
      "---red sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 240/94000  | Episode Reward: 10  | Average Reward 8.82  | Actor loss: -0.24 | Critic loss: 1.87 | Entropy loss: -0.0014  | Total Loss: 1.63 | Total Steps: 44\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 241/94000  | Episode Reward: 10  | Average Reward 8.82  | Actor loss: 0.00 | Critic loss: 2.69 | Entropy loss: -0.0000  | Total Loss: 2.69 | Total Steps: 31\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 242/94000  | Episode Reward: 8  | Average Reward 8.80  | Actor loss: -0.05 | Critic loss: 6.57 | Entropy loss: -0.0002  | Total Loss: 6.52 | Total Steps: 34\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 243/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: -0.13 | Critic loss: 4.35 | Entropy loss: -0.0016  | Total Loss: 4.22 | Total Steps: 61\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 244/94000  | Episode Reward: 8  | Average Reward 8.78  | Actor loss: -0.10 | Critic loss: 1.81 | Entropy loss: -0.0049  | Total Loss: 1.71 | Total Steps: 158\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 245/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: 0.01 | Critic loss: 0.28 | Entropy loss: -0.0000  | Total Loss: 0.29 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 246/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: 0.00 | Critic loss: 1.40 | Entropy loss: -0.0000  | Total Loss: 1.40 | Total Steps: 31\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 247/94000  | Episode Reward: 10  | Average Reward 8.82  | Actor loss: -0.87 | Critic loss: 4.29 | Entropy loss: -0.0105  | Total Loss: 3.41 | Total Steps: 74\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 248/94000  | Episode Reward: 8  | Average Reward 8.80  | Actor loss: -0.00 | Critic loss: 0.35 | Entropy loss: -0.0001  | Total Loss: 0.35 | Total Steps: 38\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 249/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: 0.01 | Critic loss: 2.23 | Entropy loss: -0.0001  | Total Loss: 2.23 | Total Steps: 31\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 250/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: -0.16 | Critic loss: 1.57 | Entropy loss: -0.0013  | Total Loss: 1.41 | Total Steps: 34\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 251/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0000  | Total Loss: 0.23 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 252/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0000  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 253/94000  | Episode Reward: 10  | Average Reward 8.85  | Actor loss: 0.11 | Critic loss: 1.02 | Entropy loss: -0.0007  | Total Loss: 1.13 | Total Steps: 12\n",
      "\n",
      "---blue capsule---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 254/94000  | Episode Reward: -10  | Average Reward 8.65  | Actor loss: -0.00 | Critic loss: 4.21 | Entropy loss: -0.0001  | Total Loss: 4.21 | Total Steps: 500\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 255/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.87 | Critic loss: 3.08 | Entropy loss: -0.0013  | Total Loss: 3.95 | Total Steps: 8\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 256/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: -0.02 | Critic loss: 0.35 | Entropy loss: -0.0013  | Total Loss: 0.33 | Total Steps: 40\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 257/94000  | Episode Reward: 8  | Average Reward 8.65  | Actor loss: 0.06 | Critic loss: 0.44 | Entropy loss: -0.0009  | Total Loss: 0.50 | Total Steps: 38\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 258/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.14 | Critic loss: 0.54 | Entropy loss: -0.0012  | Total Loss: 0.68 | Total Steps: 9\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 259/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.05 | Critic loss: 0.10 | Entropy loss: -0.0007  | Total Loss: 0.15 | Total Steps: 11\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 260/94000  | Episode Reward: 5  | Average Reward 8.62  | Actor loss: -0.29 | Critic loss: 5.93 | Entropy loss: -0.0013  | Total Loss: 5.64 | Total Steps: 49\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 261/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: -0.09 | Critic loss: 1.67 | Entropy loss: -0.0008  | Total Loss: 1.58 | Total Steps: 39\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 262/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0000  | Total Loss: 0.12 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 263/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: -0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 264/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 265/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: -0.07 | Critic loss: 2.13 | Entropy loss: -0.0003  | Total Loss: 2.07 | Total Steps: 40\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 266/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.01 | Critic loss: 0.75 | Entropy loss: -0.0000  | Total Loss: 0.76 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 267/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.07 | Critic loss: 0.31 | Entropy loss: -0.0003  | Total Loss: 0.38 | Total Steps: 9\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 268/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 269/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.00 | Critic loss: 2.34 | Entropy loss: -0.0000  | Total Loss: 2.34 | Total Steps: 31\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 270/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.17 | Critic loss: 0.30 | Entropy loss: -0.0007  | Total Loss: 0.47 | Total Steps: 9\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 271/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 0.27 | Entropy loss: -0.0000  | Total Loss: 0.27 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 272/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: -0.28 | Critic loss: 2.04 | Entropy loss: -0.0010  | Total Loss: 1.76 | Total Steps: 34\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 273/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 274/94000  | Episode Reward: 8  | Average Reward 8.72  | Actor loss: 0.00 | Critic loss: 0.49 | Entropy loss: -0.0000  | Total Loss: 0.49 | Total Steps: 38\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 275/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 276/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.12 | Critic loss: 0.84 | Entropy loss: -0.0007  | Total Loss: 0.96 | Total Steps: 13\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 277/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: -0.10 | Critic loss: 2.10 | Entropy loss: -0.0008  | Total Loss: 2.00 | Total Steps: 45\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 278/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: -0.06 | Critic loss: 3.18 | Entropy loss: -0.0011  | Total Loss: 3.12 | Total Steps: 51\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 279/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: -0.11 | Critic loss: 2.80 | Entropy loss: -0.0019  | Total Loss: 2.69 | Total Steps: 37\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 280/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: -0.41 | Critic loss: 1.22 | Entropy loss: -0.0022  | Total Loss: 0.81 | Total Steps: 36\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 281/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: 0.04 | Critic loss: 1.86 | Entropy loss: -0.0028  | Total Loss: 1.89 | Total Steps: 161\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 282/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: 0.02 | Critic loss: 0.23 | Entropy loss: -0.0001  | Total Loss: 0.25 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 283/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: 0.65 | Critic loss: 0.95 | Entropy loss: -0.0012  | Total Loss: 1.60 | Total Steps: 10\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 284/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: -0.05 | Critic loss: 0.21 | Entropy loss: -0.0015  | Total Loss: 0.16 | Total Steps: 12\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 285/94000  | Episode Reward: 10  | Average Reward 8.85  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0000  | Total Loss: 0.23 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 286/94000  | Episode Reward: 10  | Average Reward 8.85  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0000  | Total Loss: 0.00 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 287/94000  | Episode Reward: 10  | Average Reward 8.85  | Actor loss: 0.00 | Critic loss: 1.46 | Entropy loss: -0.0001  | Total Loss: 1.47 | Total Steps: 31\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 288/94000  | Episode Reward: 10  | Average Reward 8.85  | Actor loss: -0.00 | Critic loss: 0.11 | Entropy loss: -0.0014  | Total Loss: 0.10 | Total Steps: 40\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 289/94000  | Episode Reward: 10  | Average Reward 8.85  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 290/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.00 | Critic loss: 1.08 | Entropy loss: -0.0000  | Total Loss: 1.08 | Total Steps: 31\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 291/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.01 | Critic loss: 0.28 | Entropy loss: -0.0000  | Total Loss: 0.29 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 292/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0000  | Total Loss: 0.10 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 293/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 294/94000  | Episode Reward: 8  | Average Reward 8.90  | Actor loss: -0.00 | Critic loss: 0.95 | Entropy loss: -0.0009  | Total Loss: 0.95 | Total Steps: 41\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 295/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: -0.27 | Critic loss: 1.32 | Entropy loss: -0.0012  | Total Loss: 1.05 | Total Steps: 35\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 296/94000  | Episode Reward: 8  | Average Reward 8.95  | Actor loss: -0.06 | Critic loss: 0.99 | Entropy loss: -0.0013  | Total Loss: 0.93 | Total Steps: 46\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 297/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0000  | Total Loss: 0.11 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 298/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: -0.04 | Critic loss: 0.22 | Entropy loss: -0.0027  | Total Loss: 0.17 | Total Steps: 13\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 299/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: -0.55 | Critic loss: 7.39 | Entropy loss: -0.0037  | Total Loss: 6.84 | Total Steps: 68\n",
      "\n",
      "---yellow cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 300/94000  | Episode Reward: 8  | Average Reward 8.95  | Actor loss: -0.88 | Critic loss: 4.94 | Entropy loss: -0.0064  | Total Loss: 4.05 | Total Steps: 58\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 301/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: -0.30 | Critic loss: 2.53 | Entropy loss: -0.0014  | Total Loss: 2.23 | Total Steps: 36\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 10  | Average Reward 6.24  | Actor loss: 0.01 | Critic loss: 1.85 | Entropy loss: -0.0446  | Total Loss: 1.82 | Total Steps: 8\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 10  | Average Reward 6.26  | Actor loss: 0.02 | Critic loss: 3.29 | Entropy loss: -0.0365  | Total Loss: 3.28 | Total Steps: 9\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 3/100  | Episode Reward: 8  | Average Reward 6.58  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0058  | Total Loss: 0.00 | Total Steps: 68\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 2  | Average Reward 6.54  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0014  | Total Loss: 0.01 | Total Steps: 53\n",
      "TEST: ---red capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 10  | Average Reward 6.58  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0200  | Total Loss: 0.14 | Total Steps: 10\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 10  | Average Reward 6.64  | Actor loss: 1.36 | Critic loss: 8.20 | Entropy loss: -0.0533  | Total Loss: 9.51 | Total Steps: 9\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: 8  | Average Reward 6.62  | Actor loss: 0.02 | Critic loss: 0.81 | Entropy loss: -0.0054  | Total Loss: 0.82 | Total Steps: 44\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 10  | Average Reward 6.67  | Actor loss: -0.00 | Critic loss: 0.06 | Entropy loss: -0.0019  | Total Loss: 0.05 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 10  | Average Reward 6.71  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0010  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 10  | Average Reward 6.71  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0014  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 10  | Average Reward 6.76  | Actor loss: -0.00 | Critic loss: 0.06 | Entropy loss: -0.0252  | Total Loss: 0.04 | Total Steps: 53\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 8  | Average Reward 6.74  | Actor loss: 0.00 | Critic loss: 2.82 | Entropy loss: -0.0090  | Total Loss: 2.81 | Total Steps: 50\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 10  | Average Reward 6.74  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0019  | Total Loss: 0.02 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: 10  | Average Reward 6.74  | Actor loss: 0.03 | Critic loss: 2.93 | Entropy loss: -0.0023  | Total Loss: 2.96 | Total Steps: 39\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 8  | Average Reward 6.74  | Actor loss: 0.00 | Critic loss: 0.25 | Entropy loss: -0.0126  | Total Loss: 0.25 | Total Steps: 56\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 10  | Average Reward 6.74  | Actor loss: 0.86 | Critic loss: 4.89 | Entropy loss: -0.0496  | Total Loss: 5.71 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 8  | Average Reward 6.71  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0018  | Total Loss: -0.00 | Total Steps: 34\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 18/100  | Episode Reward: -20  | Average Reward 6.42  | Actor loss: -0.01 | Critic loss: 79.02 | Entropy loss: -0.0032  | Total Loss: 79.01 | Total Steps: 500\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 5  | Average Reward 6.37  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0017  | Total Loss: 0.10 | Total Steps: 47\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: 10  | Average Reward 6.37  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0004  | Total Loss: 0.00 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 10  | Average Reward 6.37  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0002  | Total Loss: 0.00 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 22/100  | Episode Reward: -10  | Average Reward 6.43  | Actor loss: -0.00 | Critic loss: 74.97 | Entropy loss: -0.0001  | Total Loss: 74.96 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 7  | Average Reward 6.43  | Actor loss: 0.11 | Critic loss: 10.05 | Entropy loss: -0.0551  | Total Loss: 10.11 | Total Steps: 155\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 8  | Average Reward 6.46  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0019  | Total Loss: 0.01 | Total Steps: 36\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 10  | Average Reward 6.46  | Actor loss: 0.01 | Critic loss: 1.35 | Entropy loss: -0.0353  | Total Loss: 1.32 | Total Steps: 9\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 10  | Average Reward 6.48  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0013  | Total Loss: -0.00 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 10  | Average Reward 6.48  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0003  | Total Loss: 0.00 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 8  | Average Reward 6.46  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0005  | Total Loss: 0.00 | Total Steps: 38\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 8  | Average Reward 6.46  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0040  | Total Loss: 0.11 | Total Steps: 46\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 10  | Average Reward 6.86  | Actor loss: 0.24 | Critic loss: 8.13 | Entropy loss: -0.0364  | Total Loss: 8.34 | Total Steps: 50\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 8  | Average Reward 6.86  | Actor loss: 0.00 | Critic loss: 1.32 | Entropy loss: -0.0125  | Total Loss: 1.32 | Total Steps: 34\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 32/100  | Episode Reward: 10  | Average Reward 6.88  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0207  | Total Loss: 0.07 | Total Steps: 10\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 33/100  | Episode Reward: 10  | Average Reward 6.88  | Actor loss: 0.01 | Critic loss: 3.94 | Entropy loss: -0.0135  | Total Loss: 3.94 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 34/100  | Episode Reward: 10  | Average Reward 6.91  | Actor loss: 0.58 | Critic loss: 7.65 | Entropy loss: -0.0180  | Total Loss: 8.21 | Total Steps: 9\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 35/100  | Episode Reward: 8  | Average Reward 7.09  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0043  | Total Loss: 0.20 | Total Steps: 45\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 36/100  | Episode Reward: 10  | Average Reward 7.14  | Actor loss: 0.03 | Critic loss: 3.00 | Entropy loss: -0.0097  | Total Loss: 3.02 | Total Steps: 41\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 37/100  | Episode Reward: 10  | Average Reward 7.51  | Actor loss: 0.00 | Critic loss: 1.40 | Entropy loss: -0.0204  | Total Loss: 1.39 | Total Steps: 9\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: 5  | Average Reward 7.46  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0029  | Total Loss: 0.18 | Total Steps: 49\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 5  | Average Reward 7.43  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0013  | Total Loss: 0.16 | Total Steps: 42\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 10  | Average Reward 7.46  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0074  | Total Loss: 0.15 | Total Steps: 8\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 10  | Average Reward 7.48  | Actor loss: 0.01 | Critic loss: 1.58 | Entropy loss: -0.0277  | Total Loss: 1.56 | Total Steps: 7\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 10  | Average Reward 7.48  | Actor loss: 0.01 | Critic loss: 5.22 | Entropy loss: -0.0571  | Total Loss: 5.17 | Total Steps: 7\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 43/100  | Episode Reward: 5  | Average Reward 7.43  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0019  | Total Loss: 0.16 | Total Steps: 42\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 5  | Average Reward 7.41  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0016  | Total Loss: 0.02 | Total Steps: 49\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: 10  | Average Reward 7.43  | Actor loss: 0.06 | Critic loss: 6.44 | Entropy loss: -0.0400  | Total Loss: 6.46 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 8  | Average Reward 7.46  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0037  | Total Loss: -0.00 | Total Steps: 49\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 8  | Average Reward 7.43  | Actor loss: 0.00 | Critic loss: 0.67 | Entropy loss: -0.0010  | Total Loss: 0.67 | Total Steps: 29\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 10  | Average Reward 7.43  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0017  | Total Loss: 0.09 | Total Steps: 40\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 5  | Average Reward 7.41  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0023  | Total Loss: -0.00 | Total Steps: 47\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 10  | Average Reward 7.41  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0003  | Total Loss: -0.00 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 10  | Average Reward 7.42  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0254  | Total Loss: 0.00 | Total Steps: 12\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 5  | Average Reward 7.37  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0179  | Total Loss: -0.00 | Total Steps: 48\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 53/100  | Episode Reward: 10  | Average Reward 7.37  | Actor loss: 0.00 | Critic loss: 0.31 | Entropy loss: -0.0518  | Total Loss: 0.26 | Total Steps: 7\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 54/100  | Episode Reward: 10  | Average Reward 7.37  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0088  | Total Loss: 0.02 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 10  | Average Reward 7.42  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0004  | Total Loss: -0.00 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: 10  | Average Reward 7.45  | Actor loss: 0.00 | Critic loss: 0.45 | Entropy loss: -0.0042  | Total Loss: 0.45 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 10  | Average Reward 7.45  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0008  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 58/100  | Episode Reward: -10  | Average Reward 7.25  | Actor loss: -0.00 | Critic loss: 78.96 | Entropy loss: -0.0005  | Total Loss: 78.95 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 10  | Average Reward 7.25  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0005  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 60/100  | Episode Reward: -11  | Average Reward 7.04  | Actor loss: -0.01 | Critic loss: 98.28 | Entropy loss: -0.0026  | Total Loss: 98.26 | Total Steps: 500\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 61/100  | Episode Reward: 10  | Average Reward 7.04  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0063  | Total Loss: 0.02 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 8  | Average Reward 7.04  | Actor loss: 0.00 | Critic loss: 0.83 | Entropy loss: -0.0101  | Total Loss: 0.83 | Total Steps: 40\n",
      "TEST: ---black sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: 8  | Average Reward 7.08  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0049  | Total Loss: -0.00 | Total Steps: 126\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 64/100  | Episode Reward: 10  | Average Reward 7.11  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0016  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 65/100  | Episode Reward: 10  | Average Reward 7.13  | Actor loss: 4.17 | Critic loss: 15.32 | Entropy loss: -0.0724  | Total Loss: 19.41 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 10  | Average Reward 7.13  | Actor loss: 0.02 | Critic loss: 11.03 | Entropy loss: -0.0625  | Total Loss: 10.98 | Total Steps: 17\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 5  | Average Reward 7.11  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0159  | Total Loss: -0.01 | Total Steps: 43\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 68/100  | Episode Reward: 10  | Average Reward 7.30  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0158  | Total Loss: 0.06 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 8  | Average Reward 7.28  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0044  | Total Loss: 0.04 | Total Steps: 55\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 70/100  | Episode Reward: 10  | Average Reward 7.28  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0424  | Total Loss: 0.10 | Total Steps: 7\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 10  | Average Reward 7.28  | Actor loss: 0.00 | Critic loss: 0.40 | Entropy loss: -0.0356  | Total Loss: 0.36 | Total Steps: 13\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 9  | Average Reward 7.47  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0389  | Total Loss: 0.09 | Total Steps: 27\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 10  | Average Reward 7.47  | Actor loss: 0.57 | Critic loss: 7.60 | Entropy loss: -0.0216  | Total Loss: 8.15 | Total Steps: 9\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: 10  | Average Reward 7.61  | Actor loss: 0.01 | Critic loss: 0.32 | Entropy loss: -0.0230  | Total Loss: 0.31 | Total Steps: 52\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 10  | Average Reward 7.61  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0248  | Total Loss: -0.02 | Total Steps: 10\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 10  | Average Reward 7.68  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0080  | Total Loss: 0.04 | Total Steps: 9\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 77/100  | Episode Reward: -31  | Average Reward 7.27  | Actor loss: 0.00 | Critic loss: 0.74 | Entropy loss: -0.0579  | Total Loss: 0.68 | Total Steps: 345\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 10  | Average Reward 7.29  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0110  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 10  | Average Reward 7.29  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0079  | Total Loss: 0.02 | Total Steps: 42\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 5  | Average Reward 7.29  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0065  | Total Loss: 0.02 | Total Steps: 79\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 10  | Average Reward 7.29  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0027  | Total Loss: 0.19 | Total Steps: 50\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: 10  | Average Reward 7.29  | Actor loss: -0.00 | Critic loss: 0.05 | Entropy loss: -0.0006  | Total Loss: 0.05 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 10  | Average Reward 7.29  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0009  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 84/100  | Episode Reward: 10  | Average Reward 7.29  | Actor loss: 0.00 | Critic loss: 0.30 | Entropy loss: -0.0636  | Total Loss: 0.24 | Total Steps: 11\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 85/100  | Episode Reward: 10  | Average Reward 7.42  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0116  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: 10  | Average Reward 7.42  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0063  | Total Loss: 0.01 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 8  | Average Reward 7.39  | Actor loss: -0.00 | Critic loss: 0.16 | Entropy loss: -0.0033  | Total Loss: 0.15 | Total Steps: 39\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 8  | Average Reward 7.39  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0006  | Total Loss: 0.00 | Total Steps: 36\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 89/100  | Episode Reward: 10  | Average Reward 7.59  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0009  | Total Loss: 0.01 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 90/100  | Episode Reward: 10  | Average Reward 7.59  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0002  | Total Loss: 0.00 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 10  | Average Reward 7.59  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0371  | Total Loss: 0.03 | Total Steps: 7\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 10  | Average Reward 7.59  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0073  | Total Loss: 0.14 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: 10  | Average Reward 7.59  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0360  | Total Loss: 0.01 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 10  | Average Reward 7.59  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0069  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: 10  | Average Reward 7.62  | Actor loss: 0.01 | Critic loss: 3.72 | Entropy loss: -0.0109  | Total Loss: 3.72 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 10  | Average Reward 7.64  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0004  | Total Loss: 0.00 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 10  | Average Reward 7.64  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0006  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: 10  | Average Reward 7.64  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0131  | Total Loss: 0.01 | Total Steps: 36\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 8  | Average Reward 7.67  | Actor loss: 0.00 | Critic loss: 0.66 | Entropy loss: -0.0017  | Total Loss: 0.66 | Total Steps: 29\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 300\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 8  | Average Reward 7.64  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0031  | Total Loss: 0.05 | Total Steps: 306\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 302/94000  | Episode Reward: 10  | Average Reward 9.15  | Actor loss: -0.00 | Critic loss: 1.80 | Entropy loss: -0.0002  | Total Loss: 1.80 | Total Steps: 34\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 303/94000  | Episode Reward: 10  | Average Reward 9.15  | Actor loss: 0.02 | Critic loss: 1.36 | Entropy loss: -0.0005  | Total Loss: 1.38 | Total Steps: 31\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 304/94000  | Episode Reward: 10  | Average Reward 9.15  | Actor loss: -0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 305/94000  | Episode Reward: 5  | Average Reward 9.10  | Actor loss: -0.31 | Critic loss: 11.10 | Entropy loss: -0.0012  | Total Loss: 10.79 | Total Steps: 53\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 306/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: -0.28 | Critic loss: 1.59 | Entropy loss: -0.0010  | Total Loss: 1.31 | Total Steps: 36\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 307/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.06 | Critic loss: 0.55 | Entropy loss: -0.0012  | Total Loss: 0.61 | Total Steps: 34\n",
      "\n",
      "---black capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Step: 250\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 308/94000  | Episode Reward: -8  | Average Reward 8.95  | Actor loss: 0.02 | Critic loss: 1.97 | Entropy loss: -0.0019  | Total Loss: 1.99 | Total Steps: 276\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 309/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.00 | Critic loss: 2.15 | Entropy loss: -0.0001  | Total Loss: 2.16 | Total Steps: 31\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 310/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0000  | Total Loss: 0.10 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 311/94000  | Episode Reward: 8  | Average Reward 8.95  | Actor loss: -0.00 | Critic loss: 6.69 | Entropy loss: -0.0020  | Total Loss: 6.68 | Total Steps: 54\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 312/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0000  | Total Loss: 0.14 | Total Steps: 6\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 313/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: -0.95 | Critic loss: 3.95 | Entropy loss: -0.0049  | Total Loss: 2.99 | Total Steps: 57\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 314/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: -0.00 | Critic loss: 0.45 | Entropy loss: -0.0001  | Total Loss: 0.45 | Total Steps: 38\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 315/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.00 | Critic loss: 1.40 | Entropy loss: -0.0000  | Total Loss: 1.40 | Total Steps: 31\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 316/94000  | Episode Reward: 8  | Average Reward 8.95  | Actor loss: -0.16 | Critic loss: 2.50 | Entropy loss: -0.0011  | Total Loss: 2.33 | Total Steps: 44\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 317/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.48 | Critic loss: 1.01 | Entropy loss: -0.0040  | Total Loss: 1.49 | Total Steps: 10\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 318/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.00 | Critic loss: 1.39 | Entropy loss: -0.0000  | Total Loss: 1.39 | Total Steps: 31\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 319/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 320/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 321/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: -0.07 | Critic loss: 4.62 | Entropy loss: -0.0019  | Total Loss: 4.55 | Total Steps: 40\n",
      "\n",
      "---green sphere---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 322/94000  | Episode Reward: -10  | Average Reward 8.78  | Actor loss: -0.00 | Critic loss: 5.73 | Entropy loss: -0.0002  | Total Loss: 5.73 | Total Steps: 500\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 323/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.16 | Critic loss: 2.60 | Entropy loss: -0.0009  | Total Loss: 2.76 | Total Steps: 8\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 324/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.00 | Critic loss: 1.79 | Entropy loss: -0.0000  | Total Loss: 1.79 | Total Steps: 31\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 325/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 326/94000  | Episode Reward: 10  | Average Reward 8.82  | Actor loss: 0.32 | Critic loss: 0.62 | Entropy loss: -0.0009  | Total Loss: 0.93 | Total Steps: 7\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 327/94000  | Episode Reward: 10  | Average Reward 8.82  | Actor loss: -0.06 | Critic loss: 4.68 | Entropy loss: -0.0002  | Total Loss: 4.62 | Total Steps: 40\n",
      "\n",
      "---black prism---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 328/94000  | Episode Reward: -10  | Average Reward 8.68  | Actor loss: -0.00 | Critic loss: 5.13 | Entropy loss: -0.0002  | Total Loss: 5.12 | Total Steps: 500\n",
      "\n",
      "---black cylinder---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 329/94000  | Episode Reward: -10  | Average Reward 8.47  | Actor loss: -0.00 | Critic loss: 2.88 | Entropy loss: -0.0001  | Total Loss: 2.88 | Total Steps: 500\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 330/94000  | Episode Reward: 10  | Average Reward 8.47  | Actor loss: -0.46 | Critic loss: 0.77 | Entropy loss: -0.0028  | Total Loss: 0.30 | Total Steps: 43\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 331/94000  | Episode Reward: 10  | Average Reward 8.47  | Actor loss: 0.00 | Critic loss: 2.92 | Entropy loss: -0.0001  | Total Loss: 2.92 | Total Steps: 31\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 332/94000  | Episode Reward: 10  | Average Reward 8.47  | Actor loss: 0.12 | Critic loss: 0.16 | Entropy loss: -0.0014  | Total Loss: 0.27 | Total Steps: 8\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 333/94000  | Episode Reward: 10  | Average Reward 8.47  | Actor loss: -0.02 | Critic loss: 0.69 | Entropy loss: -0.0004  | Total Loss: 0.67 | Total Steps: 49\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 334/94000  | Episode Reward: 10  | Average Reward 8.47  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 335/94000  | Episode Reward: 8  | Average Reward 8.45  | Actor loss: 0.24 | Critic loss: 0.58 | Entropy loss: -0.0022  | Total Loss: 0.82 | Total Steps: 38\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 336/94000  | Episode Reward: 10  | Average Reward 8.45  | Actor loss: -0.19 | Critic loss: 2.26 | Entropy loss: -0.0028  | Total Loss: 2.06 | Total Steps: 55\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 337/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.03 | Critic loss: 5.83 | Entropy loss: -0.0000  | Total Loss: 5.85 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 338/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 2.48 | Entropy loss: -0.0000  | Total Loss: 2.48 | Total Steps: 31\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 339/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.15 | Critic loss: 4.54 | Entropy loss: -0.0009  | Total Loss: 4.69 | Total Steps: 29\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 340/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.26 | Critic loss: 3.53 | Entropy loss: -0.0043  | Total Loss: 3.79 | Total Steps: 31\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 341/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: -0.47 | Critic loss: 6.78 | Entropy loss: -0.0026  | Total Loss: 6.30 | Total Steps: 54\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 342/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: -0.01 | Critic loss: 0.87 | Entropy loss: -0.0002  | Total Loss: 0.86 | Total Steps: 38\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 343/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.73 | Critic loss: 3.71 | Entropy loss: -0.0006  | Total Loss: 4.44 | Total Steps: 7\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 344/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.08 | Critic loss: 0.13 | Entropy loss: -0.0013  | Total Loss: 0.21 | Total Steps: 10\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 345/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 346/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: -0.17 | Critic loss: 1.46 | Entropy loss: -0.0010  | Total Loss: 1.30 | Total Steps: 43\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 347/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 348/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: -0.93 | Critic loss: 3.91 | Entropy loss: -0.0088  | Total Loss: 2.97 | Total Steps: 61\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 349/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: -0.26 | Critic loss: 2.97 | Entropy loss: -0.0023  | Total Loss: 2.72 | Total Steps: 41\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 350/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: -0.06 | Critic loss: 0.88 | Entropy loss: -0.0010  | Total Loss: 0.82 | Total Steps: 40\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 351/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 352/94000  | Episode Reward: 8  | Average Reward 8.70  | Actor loss: 0.21 | Critic loss: 7.10 | Entropy loss: -0.0023  | Total Loss: 7.30 | Total Steps: 35\n",
      "\n",
      "---black cube---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 353/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: -0.23 | Critic loss: 2.04 | Entropy loss: -0.0024  | Total Loss: 1.81 | Total Steps: 35\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 354/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0000  | Total Loss: 0.12 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 355/94000  | Episode Reward: 8  | Average Reward 8.88  | Actor loss: 0.01 | Critic loss: 0.38 | Entropy loss: -0.0001  | Total Loss: 0.39 | Total Steps: 38\n",
      "\n",
      "---red sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 356/94000  | Episode Reward: 8  | Average Reward 8.85  | Actor loss: -0.52 | Critic loss: 3.45 | Entropy loss: -0.0017  | Total Loss: 2.93 | Total Steps: 42\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 357/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.75 | Critic loss: 1.17 | Entropy loss: -0.0027  | Total Loss: 1.92 | Total Steps: 13\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 358/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 359/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.39 | Critic loss: 1.89 | Entropy loss: -0.0019  | Total Loss: 2.28 | Total Steps: 37\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 360/94000  | Episode Reward: 8  | Average Reward 8.90  | Actor loss: -0.02 | Critic loss: 1.48 | Entropy loss: -0.0007  | Total Loss: 1.45 | Total Steps: 44\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 361/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.16 | Critic loss: 0.98 | Entropy loss: -0.0008  | Total Loss: 1.14 | Total Steps: 12\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 362/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.00 | Critic loss: 1.70 | Entropy loss: -0.0001  | Total Loss: 1.70 | Total Steps: 31\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 363/94000  | Episode Reward: 8  | Average Reward 8.88  | Actor loss: -0.04 | Critic loss: 3.65 | Entropy loss: -0.0010  | Total Loss: 3.61 | Total Steps: 49\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 364/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.07 | Critic loss: 0.06 | Entropy loss: -0.0005  | Total Loss: 0.13 | Total Steps: 8\n",
      "\n",
      "---red cube---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 365/94000  | Episode Reward: 5  | Average Reward 8.82  | Actor loss: -0.57 | Critic loss: 8.56 | Entropy loss: -0.0050  | Total Loss: 7.99 | Total Steps: 57\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 366/94000  | Episode Reward: 10  | Average Reward 8.82  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 367/94000  | Episode Reward: 10  | Average Reward 8.82  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0000  | Total Loss: 0.08 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 368/94000  | Episode Reward: 10  | Average Reward 8.82  | Actor loss: -1.11 | Critic loss: 2.74 | Entropy loss: -0.0025  | Total Loss: 1.63 | Total Steps: 36\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 369/94000  | Episode Reward: 8  | Average Reward 8.80  | Actor loss: -0.05 | Critic loss: 2.67 | Entropy loss: -0.0004  | Total Loss: 2.62 | Total Steps: 49\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 370/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: -0.53 | Critic loss: 2.70 | Entropy loss: -0.0075  | Total Loss: 2.16 | Total Steps: 35\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 371/94000  | Episode Reward: 5  | Average Reward 8.75  | Actor loss: -0.33 | Critic loss: 9.21 | Entropy loss: -0.0026  | Total Loss: 8.87 | Total Steps: 45\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 372/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.01 | Critic loss: 3.78 | Entropy loss: -0.0002  | Total Loss: 3.79 | Total Steps: 34\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 373/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: -0.29 | Critic loss: 4.05 | Entropy loss: -0.0022  | Total Loss: 3.75 | Total Steps: 52\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 374/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0000  | Total Loss: 0.16 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 375/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.01 | Critic loss: 0.13 | Entropy loss: -0.0000  | Total Loss: 0.14 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 376/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.14 | Critic loss: 1.35 | Entropy loss: -0.0010  | Total Loss: 1.49 | Total Steps: 8\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 377/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: -0.16 | Critic loss: 5.64 | Entropy loss: -0.0018  | Total Loss: 5.48 | Total Steps: 104\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 378/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 379/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 1.62 | Critic loss: 7.47 | Entropy loss: -0.0013  | Total Loss: 9.09 | Total Steps: 10\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 380/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.00 | Critic loss: 1.83 | Entropy loss: -0.0000  | Total Loss: 1.83 | Total Steps: 31\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 381/94000  | Episode Reward: 8  | Average Reward 8.75  | Actor loss: -0.06 | Critic loss: 2.08 | Entropy loss: -0.0012  | Total Loss: 2.02 | Total Steps: 66\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 382/94000  | Episode Reward: 8  | Average Reward 8.72  | Actor loss: -0.00 | Critic loss: 0.62 | Entropy loss: -0.0000  | Total Loss: 0.62 | Total Steps: 38\n",
      "\n",
      "---blue sphere---\n",
      "Step: 250\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 383/94000  | Episode Reward: 8  | Average Reward 8.70  | Actor loss: 0.14 | Critic loss: 0.96 | Entropy loss: -0.0021  | Total Loss: 1.09 | Total Steps: 311\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 384/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0000  | Total Loss: 0.20 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 385/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 386/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0000  | Total Loss: 0.11 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Step: 250\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 387/94000  | Episode Reward: 8  | Average Reward 8.68  | Actor loss: -0.00 | Critic loss: 0.92 | Entropy loss: -0.0015  | Total Loss: 0.92 | Total Steps: 467\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 388/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.21 | Critic loss: 0.81 | Entropy loss: -0.0006  | Total Loss: 1.02 | Total Steps: 11\n",
      "\n",
      "---black cylinder---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 389/94000  | Episode Reward: -10  | Average Reward 8.47  | Actor loss: -0.00 | Critic loss: 3.19 | Entropy loss: -0.0001  | Total Loss: 3.19 | Total Steps: 500\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 390/94000  | Episode Reward: 10  | Average Reward 8.47  | Actor loss: 0.15 | Critic loss: 1.68 | Entropy loss: -0.0020  | Total Loss: 1.83 | Total Steps: 156\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 391/94000  | Episode Reward: 10  | Average Reward 8.47  | Actor loss: 0.05 | Critic loss: 0.06 | Entropy loss: -0.0006  | Total Loss: 0.10 | Total Steps: 9\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 392/94000  | Episode Reward: 10  | Average Reward 8.47  | Actor loss: -0.20 | Critic loss: 0.76 | Entropy loss: -0.0020  | Total Loss: 0.55 | Total Steps: 40\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 393/94000  | Episode Reward: 8  | Average Reward 8.45  | Actor loss: -0.58 | Critic loss: 7.19 | Entropy loss: -0.0029  | Total Loss: 6.61 | Total Steps: 71\n",
      "\n",
      "---yellow cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 394/94000  | Episode Reward: 8  | Average Reward 8.45  | Actor loss: -0.15 | Critic loss: 6.87 | Entropy loss: -0.0052  | Total Loss: 6.72 | Total Steps: 60\n",
      "\n",
      "---red cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 395/94000  | Episode Reward: 8  | Average Reward 8.43  | Actor loss: 0.00 | Critic loss: 1.32 | Entropy loss: -0.0003  | Total Loss: 1.33 | Total Steps: 50\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 396/94000  | Episode Reward: 10  | Average Reward 8.45  | Actor loss: 0.00 | Critic loss: 0.28 | Entropy loss: -0.0000  | Total Loss: 0.28 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 397/94000  | Episode Reward: 10  | Average Reward 8.45  | Actor loss: -0.20 | Critic loss: 3.40 | Entropy loss: -0.0009  | Total Loss: 3.20 | Total Steps: 47\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 398/94000  | Episode Reward: 8  | Average Reward 8.43  | Actor loss: -0.27 | Critic loss: 4.68 | Entropy loss: -0.0018  | Total Loss: 4.41 | Total Steps: 59\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 399/94000  | Episode Reward: 8  | Average Reward 8.40  | Actor loss: 0.01 | Critic loss: 0.62 | Entropy loss: -0.0001  | Total Loss: 0.62 | Total Steps: 38\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 400/94000  | Episode Reward: 10  | Average Reward 8.43  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0000  | Total Loss: 0.11 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 401/94000  | Episode Reward: 10  | Average Reward 8.43  | Actor loss: 0.00 | Critic loss: 0.84 | Entropy loss: -0.0001  | Total Loss: 0.84 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 8  | Average Reward 7.62  | Actor loss: 0.00 | Critic loss: 1.65 | Entropy loss: -0.0017  | Total Loss: 1.65 | Total Steps: 29\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 10  | Average Reward 7.62  | Actor loss: 0.00 | Critic loss: 1.88 | Entropy loss: -0.0056  | Total Loss: 1.88 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 3/100  | Episode Reward: 8  | Average Reward 7.62  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0111  | Total Loss: 0.04 | Total Steps: 39\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 10  | Average Reward 7.69  | Actor loss: 0.01 | Critic loss: 1.78 | Entropy loss: -0.0262  | Total Loss: 1.76 | Total Steps: 9\n",
      "TEST: ---green cube---\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 10  | Average Reward 7.69  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0152  | Total Loss: 0.01 | Total Steps: 118\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 10  | Average Reward 7.69  | Actor loss: 0.00 | Critic loss: 2.75 | Entropy loss: -0.0059  | Total Loss: 2.75 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: 8  | Average Reward 7.69  | Actor loss: 0.00 | Critic loss: 0.34 | Entropy loss: -0.0057  | Total Loss: 0.33 | Total Steps: 68\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 10  | Average Reward 7.69  | Actor loss: 0.00 | Critic loss: 0.39 | Entropy loss: -0.0373  | Total Loss: 0.35 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 8  | Average Reward 7.67  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0054  | Total Loss: 0.18 | Total Steps: 49\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 10  | Average Reward 7.67  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0009  | Total Loss: 0.16 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 8  | Average Reward 7.64  | Actor loss: 0.00 | Critic loss: 1.67 | Entropy loss: -0.0005  | Total Loss: 1.67 | Total Steps: 29\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 8  | Average Reward 7.64  | Actor loss: 0.00 | Critic loss: 0.63 | Entropy loss: -0.0005  | Total Loss: 0.63 | Total Steps: 38\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 9  | Average Reward 7.63  | Actor loss: 0.02 | Critic loss: 0.41 | Entropy loss: -0.0206  | Total Loss: 0.41 | Total Steps: 33\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: 10  | Average Reward 7.63  | Actor loss: 0.01 | Critic loss: 1.75 | Entropy loss: -0.0231  | Total Loss: 1.73 | Total Steps: 9\n",
      "TEST: ---green cube---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 10  | Average Reward 7.66  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0269  | Total Loss: -0.00 | Total Steps: 11\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 10  | Average Reward 7.66  | Actor loss: 0.01 | Critic loss: 0.85 | Entropy loss: -0.0494  | Total Loss: 0.81 | Total Steps: 11\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 8  | Average Reward 7.66  | Actor loss: 0.00 | Critic loss: 1.32 | Entropy loss: -0.0018  | Total Loss: 1.32 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 10  | Average Reward 7.96  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0100  | Total Loss: 0.04 | Total Steps: 41\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 10  | Average Reward 8.01  | Actor loss: 0.02 | Critic loss: 1.22 | Entropy loss: -0.0311  | Total Loss: 1.21 | Total Steps: 7\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: 10  | Average Reward 8.01  | Actor loss: 0.00 | Critic loss: 2.66 | Entropy loss: -0.0012  | Total Loss: 2.66 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 10  | Average Reward 8.01  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0003  | Total Loss: 0.09 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 22/100  | Episode Reward: 2  | Average Reward 8.13  | Actor loss: 0.00 | Critic loss: 0.96 | Entropy loss: -0.0188  | Total Loss: 0.94 | Total Steps: 57\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 10  | Average Reward 8.16  | Actor loss: -0.00 | Critic loss: 0.07 | Entropy loss: -0.0036  | Total Loss: 0.07 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 10  | Average Reward 8.19  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0008  | Total Loss: 0.21 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 10  | Average Reward 8.19  | Actor loss: 0.00 | Critic loss: 1.43 | Entropy loss: -0.0097  | Total Loss: 1.42 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 10  | Average Reward 8.19  | Actor loss: 0.01 | Critic loss: 0.29 | Entropy loss: -0.0035  | Total Loss: 0.29 | Total Steps: 66\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 10  | Average Reward 8.19  | Actor loss: 0.00 | Critic loss: 1.65 | Entropy loss: -0.0002  | Total Loss: 1.65 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.30 | Entropy loss: -0.0308  | Total Loss: 0.27 | Total Steps: 7\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 8  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0025  | Total Loss: 0.18 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.02 | Critic loss: 1.41 | Entropy loss: -0.0413  | Total Loss: 1.39 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 10  | Average Reward 8.23  | Actor loss: 0.00 | Critic loss: 0.27 | Entropy loss: -0.0156  | Total Loss: 0.26 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 32/100  | Episode Reward: 10  | Average Reward 8.23  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0028  | Total Loss: 0.20 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 33/100  | Episode Reward: -3  | Average Reward 8.11  | Actor loss: 0.00 | Critic loss: 1.91 | Entropy loss: -0.0551  | Total Loss: 1.86 | Total Steps: 220\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 34/100  | Episode Reward: 10  | Average Reward 8.11  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0866  | Total Loss: 0.13 | Total Steps: 13\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 35/100  | Episode Reward: 10  | Average Reward 8.13  | Actor loss: 0.00 | Critic loss: 0.53 | Entropy loss: -0.0643  | Total Loss: 0.47 | Total Steps: 9\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 36/100  | Episode Reward: 10  | Average Reward 8.13  | Actor loss: 0.09 | Critic loss: 0.31 | Entropy loss: -0.0340  | Total Loss: 0.37 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 37/100  | Episode Reward: 10  | Average Reward 8.13  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0059  | Total Loss: 0.19 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0151  | Total Loss: 0.02 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 10  | Average Reward 8.23  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0155  | Total Loss: 0.06 | Total Steps: 8\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 10  | Average Reward 8.23  | Actor loss: 0.04 | Critic loss: 1.30 | Entropy loss: -0.0426  | Total Loss: 1.29 | Total Steps: 8\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 8  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0015  | Total Loss: 0.17 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 8  | Average Reward 8.18  | Actor loss: 0.01 | Critic loss: 0.07 | Entropy loss: -0.0079  | Total Loss: 0.07 | Total Steps: 50\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 43/100  | Episode Reward: 8  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 1.33 | Entropy loss: -0.0006  | Total Loss: 1.33 | Total Steps: 29\n",
      "TEST: ---red capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 8  | Average Reward 8.23  | Actor loss: 0.00 | Critic loss: 0.42 | Entropy loss: -0.0114  | Total Loss: 0.41 | Total Steps: 58\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: 10  | Average Reward 8.23  | Actor loss: 0.00 | Critic loss: 1.45 | Entropy loss: -0.0511  | Total Loss: 1.40 | Total Steps: 10\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 2  | Average Reward 8.17  | Actor loss: 0.01 | Critic loss: 4.05 | Entropy loss: -0.0563  | Total Loss: 4.00 | Total Steps: 133\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 10  | Average Reward 8.20  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0099  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 5  | Average Reward 8.14  | Actor loss: 0.01 | Critic loss: 7.25 | Entropy loss: -0.0130  | Total Loss: 7.24 | Total Steps: 46\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 10  | Average Reward 8.20  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0066  | Total Loss: 0.19 | Total Steps: 66\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 8  | Average Reward 8.17  | Actor loss: 0.00 | Critic loss: 0.22 | Entropy loss: -0.0143  | Total Loss: 0.21 | Total Steps: 53\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 10  | Average Reward 8.17  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0025  | Total Loss: 0.10 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 5  | Average Reward 8.17  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0022  | Total Loss: 0.23 | Total Steps: 346\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 53/100  | Episode Reward: -31  | Average Reward 7.76  | Actor loss: 0.00 | Critic loss: 1.16 | Entropy loss: -0.0508  | Total Loss: 1.11 | Total Steps: 307\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 54/100  | Episode Reward: 10  | Average Reward 7.76  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0176  | Total Loss: 0.03 | Total Steps: 8\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 2  | Average Reward 7.68  | Actor loss: 0.12 | Critic loss: 0.32 | Entropy loss: -0.0109  | Total Loss: 0.43 | Total Steps: 51\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: 10  | Average Reward 7.68  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0074  | Total Loss: 0.05 | Total Steps: 39\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 10  | Average Reward 7.68  | Actor loss: 0.00 | Critic loss: 0.24 | Entropy loss: -0.0884  | Total Loss: 0.15 | Total Steps: 11\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 8  | Average Reward 7.86  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0032  | Total Loss: 0.07 | Total Steps: 34\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 10  | Average Reward 7.86  | Actor loss: 0.05 | Critic loss: 1.22 | Entropy loss: -0.0333  | Total Loss: 1.23 | Total Steps: 7\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 60/100  | Episode Reward: 9  | Average Reward 8.06  | Actor loss: 1.29 | Critic loss: 12.17 | Entropy loss: -0.0317  | Total Loss: 13.43 | Total Steps: 64\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 61/100  | Episode Reward: 10  | Average Reward 8.06  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0258  | Total Loss: 0.17 | Total Steps: 8\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 5  | Average Reward 8.04  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0122  | Total Loss: 0.09 | Total Steps: 47\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: 10  | Average Reward 8.06  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0022  | Total Loss: 0.20 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 64/100  | Episode Reward: 10  | Average Reward 8.06  | Actor loss: -0.00 | Critic loss: 0.08 | Entropy loss: -0.0008  | Total Loss: 0.08 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 65/100  | Episode Reward: 10  | Average Reward 8.06  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0004  | Total Loss: 0.09 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 10  | Average Reward 8.06  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0307  | Total Loss: -0.01 | Total Steps: 43\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 10  | Average Reward 8.11  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0126  | Total Loss: 0.00 | Total Steps: 50\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing  | Episode: 68/100  | Episode Reward: 10  | Average Reward 8.11  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0735  | Total Loss: 0.14 | Total Steps: 11\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 5  | Average Reward 8.09  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0114  | Total Loss: 0.06 | Total Steps: 48\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 70/100  | Episode Reward: 10  | Average Reward 8.09  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0006  | Total Loss: 0.12 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 10  | Average Reward 8.09  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0204  | Total Loss: 0.04 | Total Steps: 51\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 8  | Average Reward 8.07  | Actor loss: 0.03 | Critic loss: 9.53 | Entropy loss: -0.0058  | Total Loss: 9.56 | Total Steps: 59\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 10  | Average Reward 8.07  | Actor loss: 0.00 | Critic loss: 0.48 | Entropy loss: -0.0173  | Total Loss: 0.47 | Total Steps: 10\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: 8  | Average Reward 8.04  | Actor loss: 0.02 | Critic loss: 5.96 | Entropy loss: -0.0181  | Total Loss: 5.96 | Total Steps: 37\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 8  | Average Reward 8.02  | Actor loss: 0.00 | Critic loss: 0.50 | Entropy loss: -0.0163  | Total Loss: 0.48 | Total Steps: 39\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 5  | Average Reward 7.97  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0251  | Total Loss: 0.06 | Total Steps: 57\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 77/100  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0018  | Total Loss: 0.13 | Total Steps: 40\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0153  | Total Loss: -0.01 | Total Steps: 39\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 8  | Average Reward 8.36  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0030  | Total Loss: 0.05 | Total Steps: 49\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 10  | Average Reward 8.40  | Actor loss: 0.00 | Critic loss: 0.26 | Entropy loss: -0.0548  | Total Loss: 0.21 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 10  | Average Reward 8.40  | Actor loss: 0.03 | Critic loss: 2.44 | Entropy loss: -0.0960  | Total Loss: 2.37 | Total Steps: 11\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: 10  | Average Reward 8.40  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0033  | Total Loss: 0.10 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 8  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 0.64 | Entropy loss: -0.0015  | Total Loss: 0.64 | Total Steps: 432\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 84/100  | Episode Reward: 8  | Average Reward 8.36  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0007  | Total Loss: 0.20 | Total Steps: 34\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 85/100  | Episode Reward: 10  | Average Reward 8.36  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0004  | Total Loss: 0.20 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: 10  | Average Reward 8.36  | Actor loss: 0.00 | Critic loss: 0.27 | Entropy loss: -0.0222  | Total Loss: 0.25 | Total Steps: 7\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0087  | Total Loss: 0.05 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 10  | Average Reward 8.40  | Actor loss: 0.00 | Critic loss: 0.37 | Entropy loss: -0.0016  | Total Loss: 0.36 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 89/100  | Episode Reward: 5  | Average Reward 8.36  | Actor loss: 0.00 | Critic loss: 0.88 | Entropy loss: -0.0067  | Total Loss: 0.87 | Total Steps: 51\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 90/100  | Episode Reward: 10  | Average Reward 8.36  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0416  | Total Loss: 0.06 | Total Steps: 9\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 8  | Average Reward 8.33  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0020  | Total Loss: 0.09 | Total Steps: 34\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 8  | Average Reward 8.30  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0025  | Total Loss: 0.01 | Total Steps: 48\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: 8  | Average Reward 8.28  | Actor loss: 0.01 | Critic loss: 1.25 | Entropy loss: -0.0167  | Total Loss: 1.24 | Total Steps: 35\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 10  | Average Reward 8.28  | Actor loss: 0.00 | Critic loss: 0.25 | Entropy loss: -0.0031  | Total Loss: 0.24 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: 5  | Average Reward 8.23  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0054  | Total Loss: 0.04 | Total Steps: 53\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 5  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0176  | Total Loss: 0.07 | Total Steps: 41\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 2  | Average Reward 8.11  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0062  | Total Loss: 0.04 | Total Steps: 39\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 200\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: 8  | Average Reward 8.08  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0039  | Total Loss: 0.01 | Total Steps: 253\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 10  | Average Reward 8.11  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0003  | Total Loss: 0.09 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 10  | Average Reward 8.13  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0177  | Total Loss: 0.17 | Total Steps: 8\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 402/94000  | Episode Reward: 10  | Average Reward 8.43  | Actor loss: 0.01 | Critic loss: 1.99 | Entropy loss: -0.0001  | Total Loss: 2.00 | Total Steps: 38\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 403/94000  | Episode Reward: 10  | Average Reward 8.43  | Actor loss: 0.06 | Critic loss: 0.39 | Entropy loss: -0.0002  | Total Loss: 0.45 | Total Steps: 8\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 404/94000  | Episode Reward: 10  | Average Reward 8.43  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0000  | Total Loss: 0.17 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 405/94000  | Episode Reward: 10  | Average Reward 8.47  | Actor loss: 0.00 | Critic loss: 2.49 | Entropy loss: -0.0000  | Total Loss: 2.50 | Total Steps: 31\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 406/94000  | Episode Reward: 10  | Average Reward 8.47  | Actor loss: 0.01 | Critic loss: 0.28 | Entropy loss: -0.0000  | Total Loss: 0.29 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 407/94000  | Episode Reward: 8  | Average Reward 8.45  | Actor loss: -0.67 | Critic loss: 5.03 | Entropy loss: -0.0023  | Total Loss: 4.37 | Total Steps: 55\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 408/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.07 | Critic loss: 0.57 | Entropy loss: -0.0004  | Total Loss: 0.64 | Total Steps: 9\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 409/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: -0.00 | Critic loss: 1.15 | Entropy loss: -0.0011  | Total Loss: 1.15 | Total Steps: 94\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 410/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.00 | Critic loss: 0.31 | Entropy loss: -0.0000  | Total Loss: 0.32 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 411/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.50 | Critic loss: 0.46 | Entropy loss: -0.0016  | Total Loss: 0.96 | Total Steps: 7\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 412/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 413/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0000  | Total Loss: 0.14 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 414/94000  | Episode Reward: 8  | Average Reward 8.62  | Actor loss: 0.09 | Critic loss: 6.63 | Entropy loss: -0.0020  | Total Loss: 6.72 | Total Steps: 48\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 415/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 416/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 417/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0000  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 418/94000  | Episode Reward: 8  | Average Reward 8.62  | Actor loss: 0.01 | Critic loss: 0.49 | Entropy loss: -0.0001  | Total Loss: 0.50 | Total Steps: 38\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 419/94000  | Episode Reward: 8  | Average Reward 8.60  | Actor loss: 0.03 | Critic loss: 7.53 | Entropy loss: -0.0005  | Total Loss: 7.56 | Total Steps: 30\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 420/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: -0.05 | Critic loss: 0.25 | Entropy loss: -0.0009  | Total Loss: 0.21 | Total Steps: 10\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 421/94000  | Episode Reward: 8  | Average Reward 8.57  | Actor loss: -0.04 | Critic loss: 0.20 | Entropy loss: -0.0008  | Total Loss: 0.15 | Total Steps: 40\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 422/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: -0.08 | Critic loss: 4.14 | Entropy loss: -0.0005  | Total Loss: 4.07 | Total Steps: 41\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 423/94000  | Episode Reward: 8  | Average Reward 8.75  | Actor loss: -0.12 | Critic loss: 3.16 | Entropy loss: -0.0006  | Total Loss: 3.04 | Total Steps: 48\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 424/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0000  | Total Loss: 0.16 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 425/94000  | Episode Reward: 8  | Average Reward 8.72  | Actor loss: -0.27 | Critic loss: 4.49 | Entropy loss: -0.0006  | Total Loss: 4.22 | Total Steps: 34\n",
      "\n",
      "---black capsule---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 426/94000  | Episode Reward: -10  | Average Reward 8.53  | Actor loss: -0.00 | Critic loss: 3.03 | Entropy loss: -0.0001  | Total Loss: 3.03 | Total Steps: 500\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 427/94000  | Episode Reward: 10  | Average Reward 8.53  | Actor loss: 0.11 | Critic loss: 1.58 | Entropy loss: -0.0019  | Total Loss: 1.69 | Total Steps: 11\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 428/94000  | Episode Reward: 8  | Average Reward 8.70  | Actor loss: 0.06 | Critic loss: 0.76 | Entropy loss: -0.0018  | Total Loss: 0.82 | Total Steps: 103\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 429/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: -0.07 | Critic loss: 2.11 | Entropy loss: -0.0008  | Total Loss: 2.04 | Total Steps: 49\n",
      "\n",
      "---blue prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 430/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: -0.04 | Critic loss: 0.70 | Entropy loss: -0.0010  | Total Loss: 0.66 | Total Steps: 46\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 431/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.00 | Critic loss: 3.56 | Entropy loss: -0.0000  | Total Loss: 3.56 | Total Steps: 31\n",
      "\n",
      "---yellow capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 432/94000  | Episode Reward: 8  | Average Reward 8.88  | Actor loss: -0.76 | Critic loss: 6.11 | Entropy loss: -0.0074  | Total Loss: 5.34 | Total Steps: 63\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 433/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: -0.29 | Critic loss: 5.25 | Entropy loss: -0.0016  | Total Loss: 4.97 | Total Steps: 22\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 434/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.00 | Critic loss: 2.61 | Entropy loss: -0.0000  | Total Loss: 2.61 | Total Steps: 31\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 435/94000  | Episode Reward: 8  | Average Reward 8.88  | Actor loss: -0.98 | Critic loss: 9.13 | Entropy loss: -0.0051  | Total Loss: 8.15 | Total Steps: 55\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 436/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 437/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.05 | Critic loss: 0.93 | Entropy loss: -0.0001  | Total Loss: 0.98 | Total Steps: 8\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 438/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.00 | Critic loss: 0.24 | Entropy loss: -0.0000  | Total Loss: 0.24 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 439/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: -0.53 | Critic loss: 1.36 | Entropy loss: -0.0037  | Total Loss: 0.83 | Total Steps: 40\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 440/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.00 | Critic loss: 0.32 | Entropy loss: -0.0000  | Total Loss: 0.32 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 441/94000  | Episode Reward: 8  | Average Reward 8.85  | Actor loss: -0.02 | Critic loss: 1.44 | Entropy loss: -0.0012  | Total Loss: 1.42 | Total Steps: 155\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 442/94000  | Episode Reward: 10  | Average Reward 8.85  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0000  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 443/94000  | Episode Reward: 10  | Average Reward 8.85  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 444/94000  | Episode Reward: 10  | Average Reward 8.85  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 445/94000  | Episode Reward: -10  | Average Reward 8.65  | Actor loss: -0.09 | Critic loss: 4.55 | Entropy loss: -0.0023  | Total Loss: 4.46 | Total Steps: 500\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 446/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.01 | Critic loss: 0.01 | Entropy loss: -0.0005  | Total Loss: 0.02 | Total Steps: 8\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 447/94000  | Episode Reward: 8  | Average Reward 8.62  | Actor loss: 0.13 | Critic loss: 0.70 | Entropy loss: -0.0013  | Total Loss: 0.83 | Total Steps: 44\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 448/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: -0.36 | Critic loss: 3.65 | Entropy loss: -0.0034  | Total Loss: 3.29 | Total Steps: 56\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 449/94000  | Episode Reward: 8  | Average Reward 8.60  | Actor loss: -0.13 | Critic loss: 4.38 | Entropy loss: -0.0038  | Total Loss: 4.25 | Total Steps: 37\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 450/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: -0.04 | Critic loss: 4.74 | Entropy loss: -0.0015  | Total Loss: 4.69 | Total Steps: 49\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 451/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0000  | Total Loss: 0.20 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 452/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 453/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.01 | Critic loss: 1.80 | Entropy loss: -0.0001  | Total Loss: 1.81 | Total Steps: 38\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 454/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: -0.13 | Critic loss: 3.13 | Entropy loss: -0.0018  | Total Loss: 3.00 | Total Steps: 55\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 455/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 456/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0000  | Total Loss: 0.08 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 457/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.00 | Critic loss: 0.22 | Entropy loss: -0.0000  | Total Loss: 0.22 | Total Steps: 6\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 458/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0000  | Total Loss: 0.15 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 459/94000  | Episode Reward: 8  | Average Reward 8.65  | Actor loss: 0.04 | Critic loss: 1.08 | Entropy loss: -0.0016  | Total Loss: 1.11 | Total Steps: 103\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 460/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.01 | Critic loss: 2.32 | Entropy loss: -0.0001  | Total Loss: 2.33 | Total Steps: 31\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 461/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.03 | Critic loss: 1.40 | Entropy loss: -0.0002  | Total Loss: 1.42 | Total Steps: 38\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 462/94000  | Episode Reward: 5  | Average Reward 8.62  | Actor loss: -0.02 | Critic loss: 5.48 | Entropy loss: -0.0003  | Total Loss: 5.46 | Total Steps: 47\n",
      "\n",
      "---green cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 463/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 0.55 | Entropy loss: -0.0001  | Total Loss: 0.55 | Total Steps: 38\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 464/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: -0.07 | Critic loss: 5.06 | Entropy loss: -0.0010  | Total Loss: 4.99 | Total Steps: 104\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 465/94000  | Episode Reward: 8  | Average Reward 8.68  | Actor loss: -0.14 | Critic loss: 4.16 | Entropy loss: -0.0024  | Total Loss: 4.01 | Total Steps: 49\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 466/94000  | Episode Reward: 8  | Average Reward 8.65  | Actor loss: -0.04 | Critic loss: 2.89 | Entropy loss: -0.0002  | Total Loss: 2.84 | Total Steps: 39\n",
      "\n",
      "---yellow cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 467/94000  | Episode Reward: 8  | Average Reward 8.62  | Actor loss: -0.30 | Critic loss: 7.54 | Entropy loss: -0.0075  | Total Loss: 7.24 | Total Steps: 67\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 468/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.00 | Critic loss: 0.45 | Entropy loss: -0.0018  | Total Loss: 0.45 | Total Steps: 13\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 469/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.11 | Critic loss: 0.48 | Entropy loss: -0.0008  | Total Loss: 0.59 | Total Steps: 12\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 470/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: -0.28 | Critic loss: 5.98 | Entropy loss: -0.0044  | Total Loss: 5.70 | Total Steps: 73\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 471/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: -0.98 | Critic loss: 3.95 | Entropy loss: -0.0039  | Total Loss: 2.97 | Total Steps: 48\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 472/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.07 | Critic loss: 1.65 | Entropy loss: -0.0022  | Total Loss: 1.72 | Total Steps: 45\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 473/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 2.50 | Entropy loss: -0.0000  | Total Loss: 2.50 | Total Steps: 31\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 474/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.14 | Critic loss: 0.39 | Entropy loss: -0.0006  | Total Loss: 0.53 | Total Steps: 9\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 475/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.15 | Critic loss: 0.86 | Entropy loss: -0.0004  | Total Loss: 1.00 | Total Steps: 9\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 476/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 2.85 | Entropy loss: -0.0000  | Total Loss: 2.85 | Total Steps: 31\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 477/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.07 | Critic loss: 4.38 | Entropy loss: -0.0033  | Total Loss: 4.45 | Total Steps: 56\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 478/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 479/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0000  | Total Loss: 0.15 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 480/94000  | Episode Reward: 8  | Average Reward 8.68  | Actor loss: 0.02 | Critic loss: 6.36 | Entropy loss: -0.0022  | Total Loss: 6.37 | Total Steps: 56\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 481/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 1.61 | Entropy loss: -0.0001  | Total Loss: 1.62 | Total Steps: 31\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 482/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: 0.31 | Critic loss: 7.41 | Entropy loss: -0.0009  | Total Loss: 7.72 | Total Steps: 12\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 483/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: -0.00 | Critic loss: 3.13 | Entropy loss: -0.0000  | Total Loss: 3.12 | Total Steps: 34\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 484/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: -0.53 | Critic loss: 0.98 | Entropy loss: -0.0054  | Total Loss: 0.44 | Total Steps: 34\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 485/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.00 | Critic loss: 0.32 | Entropy loss: -0.0001  | Total Loss: 0.32 | Total Steps: 38\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 486/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 487/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 488/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: -0.11 | Critic loss: 1.01 | Entropy loss: -0.0017  | Total Loss: 0.89 | Total Steps: 51\n",
      "\n",
      "---yellow cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 489/94000  | Episode Reward: 5  | Average Reward 8.93  | Actor loss: -1.78 | Critic loss: 9.38 | Entropy loss: -0.0178  | Total Loss: 7.58 | Total Steps: 100\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 490/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: 0.04 | Critic loss: 0.58 | Entropy loss: -0.0008  | Total Loss: 0.62 | Total Steps: 48\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 491/94000  | Episode Reward: 8  | Average Reward 8.90  | Actor loss: 0.07 | Critic loss: 2.07 | Entropy loss: -0.0006  | Total Loss: 2.15 | Total Steps: 36\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 492/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: -0.00 | Critic loss: 4.11 | Entropy loss: -0.0014  | Total Loss: 4.11 | Total Steps: 45\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 493/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: 0.06 | Critic loss: 0.68 | Entropy loss: -0.0010  | Total Loss: 0.74 | Total Steps: 44\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 494/94000  | Episode Reward: 5  | Average Reward 8.90  | Actor loss: -0.10 | Critic loss: 5.53 | Entropy loss: -0.0018  | Total Loss: 5.42 | Total Steps: 54\n",
      "\n",
      "---blue sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 495/94000  | Episode Reward: 5  | Average Reward 8.88  | Actor loss: -0.36 | Critic loss: 6.12 | Entropy loss: -0.0034  | Total Loss: 5.76 | Total Steps: 54\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 496/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.05 | Critic loss: 0.80 | Entropy loss: -0.0001  | Total Loss: 0.84 | Total Steps: 8\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 497/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.00 | Critic loss: 1.78 | Entropy loss: -0.0000  | Total Loss: 1.78 | Total Steps: 31\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 498/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.02 | Critic loss: 1.00 | Entropy loss: -0.0002  | Total Loss: 1.01 | Total Steps: 37\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 499/94000  | Episode Reward: 2  | Average Reward 8.85  | Actor loss: -0.24 | Critic loss: 13.00 | Entropy loss: -0.0015  | Total Loss: 12.76 | Total Steps: 48\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 500/94000  | Episode Reward: 10  | Average Reward 8.85  | Actor loss: 0.00 | Critic loss: 0.29 | Entropy loss: -0.0000  | Total Loss: 0.29 | Total Steps: 6\n",
      "\n",
      "---red cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 501/94000  | Episode Reward: 8  | Average Reward 8.82  | Actor loss: -0.11 | Critic loss: 5.13 | Entropy loss: -0.0008  | Total Loss: 5.02 | Total Steps: 32\n",
      "Model has been saved\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 200\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: -18  | Average Reward 7.88  | Actor loss: 0.00 | Critic loss: 1.06 | Entropy loss: -0.0095  | Total Loss: 1.05 | Total Steps: 213\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 8  | Average Reward 7.86  | Actor loss: 0.00 | Critic loss: 1.46 | Entropy loss: -0.0015  | Total Loss: 1.46 | Total Steps: 343\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 3/100  | Episode Reward: 10  | Average Reward 7.88  | Actor loss: 6.78 | Critic loss: 28.51 | Entropy loss: -0.0721  | Total Loss: 35.22 | Total Steps: 76\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 10  | Average Reward 7.88  | Actor loss: 0.00 | Critic loss: 1.33 | Entropy loss: -0.0033  | Total Loss: 1.33 | Total Steps: 50\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 10  | Average Reward 7.88  | Actor loss: 0.00 | Critic loss: 0.39 | Entropy loss: -0.0002  | Total Loss: 0.39 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 10  | Average Reward 7.88  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0130  | Total Loss: 0.06 | Total Steps: 12\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: 10  | Average Reward 7.91  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0006  | Total Loss: 0.17 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 5  | Average Reward 7.86  | Actor loss: 0.00 | Critic loss: 0.91 | Entropy loss: -0.0024  | Total Loss: 0.91 | Total Steps: 57\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 10  | Average Reward 7.88  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0042  | Total Loss: 0.14 | Total Steps: 34\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 9  | Average Reward 7.87  | Actor loss: 0.01 | Critic loss: 4.00 | Entropy loss: -0.0572  | Total Loss: 3.95 | Total Steps: 195\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 10  | Average Reward 7.89  | Actor loss: 0.00 | Critic loss: 1.29 | Entropy loss: -0.0104  | Total Loss: 1.28 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 8  | Average Reward 7.89  | Actor loss: 0.00 | Critic loss: 0.63 | Entropy loss: -0.0059  | Total Loss: 0.62 | Total Steps: 68\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 5  | Average Reward 7.86  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0220  | Total Loss: -0.02 | Total Steps: 47\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: 10  | Average Reward 7.86  | Actor loss: 8.73 | Critic loss: 28.80 | Entropy loss: -0.0409  | Total Loss: 37.49 | Total Steps: 62\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 2  | Average Reward 7.78  | Actor loss: 0.00 | Critic loss: 0.22 | Entropy loss: -0.0041  | Total Loss: 0.22 | Total Steps: 50\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 8  | Average Reward 7.75  | Actor loss: 0.00 | Critic loss: 0.81 | Entropy loss: -0.0008  | Total Loss: 0.81 | Total Steps: 29\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 10  | Average Reward 7.78  | Actor loss: 0.12 | Critic loss: 7.25 | Entropy loss: -0.0177  | Total Loss: 7.35 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 10  | Average Reward 7.78  | Actor loss: 0.00 | Critic loss: 0.96 | Entropy loss: -0.0174  | Total Loss: 0.94 | Total Steps: 32\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 8  | Average Reward 7.75  | Actor loss: 0.00 | Critic loss: 9.11 | Entropy loss: -0.0082  | Total Loss: 9.10 | Total Steps: 95\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 20/100  | Episode Reward: -10  | Average Reward 7.55  | Actor loss: -0.01 | Critic loss: 76.37 | Entropy loss: -0.0001  | Total Loss: 76.36 | Total Steps: 500\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 10  | Average Reward 7.55  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0010  | Total Loss: 0.19 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 22/100  | Episode Reward: -10  | Average Reward 7.43  | Actor loss: -0.01 | Critic loss: 80.84 | Entropy loss: -0.0001  | Total Loss: 80.84 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 10  | Average Reward 7.43  | Actor loss: 0.00 | Critic loss: 0.74 | Entropy loss: -0.0165  | Total Loss: 0.72 | Total Steps: 7\n",
      "TEST: ---yellow prism---\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 9  | Average Reward 7.42  | Actor loss: 0.04 | Critic loss: 4.05 | Entropy loss: -0.0679  | Total Loss: 4.03 | Total Steps: 148\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 8  | Average Reward 7.39  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0213  | Total Loss: 0.02 | Total Steps: 36\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 9  | Average Reward 7.38  | Actor loss: 4.31 | Critic loss: 25.61 | Entropy loss: -0.0395  | Total Loss: 29.88 | Total Steps: 74\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 10  | Average Reward 7.38  | Actor loss: 0.01 | Critic loss: 4.60 | Entropy loss: -0.0079  | Total Loss: 4.60 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 5  | Average Reward 7.33  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0056  | Total Loss: 0.06 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 10  | Average Reward 7.36  | Actor loss: 0.00 | Critic loss: 0.70 | Entropy loss: -0.0293  | Total Loss: 0.67 | Total Steps: 7\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 10  | Average Reward 7.36  | Actor loss: 0.01 | Critic loss: 5.42 | Entropy loss: -0.0071  | Total Loss: 5.42 | Total Steps: 66\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 10  | Average Reward 7.36  | Actor loss: 0.00 | Critic loss: 0.49 | Entropy loss: -0.0165  | Total Loss: 0.48 | Total Steps: 10\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 32/100  | Episode Reward: -7  | Average Reward 7.19  | Actor loss: 0.03 | Critic loss: 3.47 | Entropy loss: -0.0552  | Total Loss: 3.45 | Total Steps: 183\n",
      "TEST: ---yellow prism---\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 33/100  | Episode Reward: 10  | Average Reward 7.32  | Actor loss: 0.59 | Critic loss: 4.00 | Entropy loss: -0.0596  | Total Loss: 4.53 | Total Steps: 132\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 34/100  | Episode Reward: 10  | Average Reward 7.32  | Actor loss: 0.00 | Critic loss: 1.22 | Entropy loss: -0.0745  | Total Loss: 1.15 | Total Steps: 65\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 35/100  | Episode Reward: 10  | Average Reward 7.32  | Actor loss: 0.00 | Critic loss: 0.32 | Entropy loss: -0.0125  | Total Loss: 0.31 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 36/100  | Episode Reward: -10  | Average Reward 7.12  | Actor loss: -0.01 | Critic loss: 79.81 | Entropy loss: -0.0002  | Total Loss: 79.80 | Total Steps: 500\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 37/100  | Episode Reward: 8  | Average Reward 7.09  | Actor loss: 0.00 | Critic loss: 1.14 | Entropy loss: -0.0011  | Total Loss: 1.14 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: 10  | Average Reward 7.09  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0009  | Total Loss: 0.10 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 10  | Average Reward 7.09  | Actor loss: 0.00 | Critic loss: 0.30 | Entropy loss: -0.0084  | Total Loss: 0.29 | Total Steps: 9\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 8  | Average Reward 7.07  | Actor loss: 0.00 | Critic loss: 1.24 | Entropy loss: -0.0253  | Total Loss: 1.22 | Total Steps: 39\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 10  | Average Reward 7.09  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0396  | Total Loss: 0.16 | Total Steps: 9\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 10  | Average Reward 7.12  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0076  | Total Loss: 0.18 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 43/100  | Episode Reward: 10  | Average Reward 7.14  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0313  | Total Loss: 0.20 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 10  | Average Reward 7.17  | Actor loss: 0.01 | Critic loss: 0.27 | Entropy loss: -0.0063  | Total Loss: 0.27 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: 10  | Average Reward 7.17  | Actor loss: 0.00 | Critic loss: 0.74 | Entropy loss: -0.0003  | Total Loss: 0.74 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 10  | Average Reward 7.25  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0002  | Total Loss: 0.11 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 8  | Average Reward 7.23  | Actor loss: 0.00 | Critic loss: 0.62 | Entropy loss: -0.0002  | Total Loss: 0.62 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 10  | Average Reward 7.28  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0006  | Total Loss: 0.02 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 8  | Average Reward 7.25  | Actor loss: 0.46 | Critic loss: 1.69 | Entropy loss: -0.0040  | Total Loss: 2.15 | Total Steps: 366\n",
      "TEST: ---red capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 10  | Average Reward 7.28  | Actor loss: 0.00 | Critic loss: 0.66 | Entropy loss: -0.0056  | Total Loss: 0.65 | Total Steps: 36\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 5  | Average Reward 7.23  | Actor loss: 0.00 | Critic loss: 0.33 | Entropy loss: -0.0014  | Total Loss: 0.33 | Total Steps: 46\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 10  | Average Reward 7.28  | Actor loss: 0.00 | Critic loss: 0.44 | Entropy loss: -0.0004  | Total Loss: 0.44 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 53/100  | Episode Reward: 8  | Average Reward 7.67  | Actor loss: 0.00 | Critic loss: 0.42 | Entropy loss: -0.0006  | Total Loss: 0.42 | Total Steps: 38\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 54/100  | Episode Reward: 10  | Average Reward 7.67  | Actor loss: 0.02 | Critic loss: 10.48 | Entropy loss: -0.0490  | Total Loss: 10.45 | Total Steps: 11\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 10  | Average Reward 7.74  | Actor loss: 0.00 | Critic loss: 0.39 | Entropy loss: -0.0244  | Total Loss: 0.37 | Total Steps: 9\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: 10  | Average Reward 7.74  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0051  | Total Loss: 0.15 | Total Steps: 34\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 57/100  | Episode Reward: -10  | Average Reward 7.54  | Actor loss: -0.00 | Critic loss: 84.42 | Entropy loss: -0.0000  | Total Loss: 84.41 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 10  | Average Reward 7.57  | Actor loss: 0.00 | Critic loss: 0.27 | Entropy loss: -0.0003  | Total Loss: 0.28 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 10  | Average Reward 7.57  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0011  | Total Loss: 0.12 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 60/100  | Episode Reward: 10  | Average Reward 7.58  | Actor loss: 0.00 | Critic loss: 1.26 | Entropy loss: -0.0042  | Total Loss: 1.26 | Total Steps: 40\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 61/100  | Episode Reward: 8  | Average Reward 7.55  | Actor loss: 0.00 | Critic loss: 1.00 | Entropy loss: -0.0046  | Total Loss: 1.00 | Total Steps: 29\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 8  | Average Reward 7.58  | Actor loss: 0.00 | Critic loss: 1.01 | Entropy loss: -0.0212  | Total Loss: 1.00 | Total Steps: 30\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: 10  | Average Reward 7.58  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0115  | Total Loss: 0.19 | Total Steps: 10\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 64/100  | Episode Reward: 10  | Average Reward 7.58  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0027  | Total Loss: 0.11 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 65/100  | Episode Reward: 10  | Average Reward 7.58  | Actor loss: 0.00 | Critic loss: 0.84 | Entropy loss: -0.0409  | Total Loss: 0.80 | Total Steps: 12\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 8  | Average Reward 7.55  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0141  | Total Loss: -0.01 | Total Steps: 41\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 10  | Average Reward 7.55  | Actor loss: 0.01 | Critic loss: 2.25 | Entropy loss: -0.0010  | Total Loss: 2.25 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 68/100  | Episode Reward: 10  | Average Reward 7.55  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0012  | Total Loss: 0.21 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 10  | Average Reward 7.60  | Actor loss: 0.00 | Critic loss: 0.31 | Entropy loss: -0.0005  | Total Loss: 0.31 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 70/100  | Episode Reward: 5  | Average Reward 7.55  | Actor loss: 0.00 | Critic loss: 0.71 | Entropy loss: -0.0019  | Total Loss: 0.71 | Total Steps: 42\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 10  | Average Reward 7.55  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0134  | Total Loss: 0.16 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 10  | Average Reward 7.58  | Actor loss: 0.00 | Critic loss: 0.66 | Entropy loss: -0.0264  | Total Loss: 0.63 | Total Steps: 10\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 10  | Average Reward 7.58  | Actor loss: 0.00 | Critic loss: 0.63 | Entropy loss: -0.0125  | Total Loss: 0.62 | Total Steps: 11\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: 10  | Average Reward 7.60  | Actor loss: 0.00 | Critic loss: 0.35 | Entropy loss: -0.0023  | Total Loss: 0.35 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 6  | Average Reward 7.59  | Actor loss: 0.00 | Critic loss: 0.59 | Entropy loss: -0.0529  | Total Loss: 0.54 | Total Steps: 96\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 10  | Average Reward 7.64  | Actor loss: 0.00 | Critic loss: 0.75 | Entropy loss: -0.0021  | Total Loss: 0.75 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 77/100  | Episode Reward: 3  | Average Reward 7.57  | Actor loss: 5.38 | Critic loss: 23.69 | Entropy loss: -0.0712  | Total Loss: 29.00 | Total Steps: 114\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 10  | Average Reward 7.57  | Actor loss: 0.00 | Critic loss: 0.58 | Entropy loss: -0.0412  | Total Loss: 0.54 | Total Steps: 11\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 10  | Average Reward 7.59  | Actor loss: 0.00 | Critic loss: 0.34 | Entropy loss: -0.0070  | Total Loss: 0.33 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 10  | Average Reward 7.59  | Actor loss: 0.01 | Critic loss: 0.26 | Entropy loss: -0.0022  | Total Loss: 0.26 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 10  | Average Reward 7.59  | Actor loss: 13.84 | Critic loss: 16.21 | Entropy loss: -0.0421  | Total Loss: 30.01 | Total Steps: 24\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: 8  | Average Reward 7.57  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0081  | Total Loss: 0.04 | Total Steps: 55\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 10  | Average Reward 7.59  | Actor loss: 1.13 | Critic loss: 11.52 | Entropy loss: -0.0391  | Total Loss: 12.61 | Total Steps: 27\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 84/100  | Episode Reward: 10  | Average Reward 7.62  | Actor loss: 0.00 | Critic loss: 0.40 | Entropy loss: -0.0090  | Total Loss: 0.39 | Total Steps: 9\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 85/100  | Episode Reward: 8  | Average Reward 7.59  | Actor loss: 0.00 | Critic loss: 1.56 | Entropy loss: -0.0008  | Total Loss: 1.56 | Total Steps: 29\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 86/100  | Episode Reward: -10  | Average Reward 7.39  | Actor loss: -0.00 | Critic loss: 84.42 | Entropy loss: -0.0000  | Total Loss: 84.41 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 10  | Average Reward 7.39  | Actor loss: 0.01 | Critic loss: 10.44 | Entropy loss: -0.0040  | Total Loss: 10.44 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 10  | Average Reward 7.39  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0015  | Total Loss: 0.08 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 89/100  | Episode Reward: 10  | Average Reward 7.45  | Actor loss: 0.00 | Critic loss: 0.35 | Entropy loss: -0.0002  | Total Loss: 0.35 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 90/100  | Episode Reward: 10  | Average Reward 7.45  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0132  | Total Loss: 0.06 | Total Steps: 12\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 10  | Average Reward 7.47  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0129  | Total Loss: 0.22 | Total Steps: 9\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 2  | Average Reward 7.42  | Actor loss: 0.00 | Critic loss: 0.22 | Entropy loss: -0.0035  | Total Loss: 0.22 | Total Steps: 50\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: 8  | Average Reward 7.42  | Actor loss: 0.00 | Critic loss: 1.01 | Entropy loss: -0.0050  | Total Loss: 1.00 | Total Steps: 29\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 10  | Average Reward 7.42  | Actor loss: 0.00 | Critic loss: 0.55 | Entropy loss: -0.0442  | Total Loss: 0.51 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: 8  | Average Reward 7.45  | Actor loss: 0.00 | Critic loss: 1.61 | Entropy loss: -0.0116  | Total Loss: 1.60 | Total Steps: 43\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 10  | Average Reward 7.50  | Actor loss: 0.04 | Critic loss: 1.29 | Entropy loss: -0.0626  | Total Loss: 1.27 | Total Steps: 7\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 8  | Average Reward 7.54  | Actor loss: 0.00 | Critic loss: 1.46 | Entropy loss: -0.0033  | Total Loss: 1.46 | Total Steps: 29\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: 8  | Average Reward 7.54  | Actor loss: 0.00 | Critic loss: 0.81 | Entropy loss: -0.0022  | Total Loss: 0.81 | Total Steps: 29\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 10  | Average Reward 7.54  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0002  | Total Loss: 0.17 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 10  | Average Reward 7.54  | Actor loss: 0.66 | Critic loss: 9.05 | Entropy loss: -0.0284  | Total Loss: 9.69 | Total Steps: 23\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 502/94000  | Episode Reward: 10  | Average Reward 8.82  | Actor loss: 0.48 | Critic loss: 2.94 | Entropy loss: -0.0010  | Total Loss: 3.42 | Total Steps: 8\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 503/94000  | Episode Reward: 8  | Average Reward 8.80  | Actor loss: -0.09 | Critic loss: 2.67 | Entropy loss: -0.0014  | Total Loss: 2.58 | Total Steps: 54\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 504/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: 0.01 | Critic loss: 1.18 | Entropy loss: -0.0002  | Total Loss: 1.19 | Total Steps: 43\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 505/94000  | Episode Reward: 8  | Average Reward 8.78  | Actor loss: 0.05 | Critic loss: 2.47 | Entropy loss: -0.0015  | Total Loss: 2.52 | Total Steps: 48\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 506/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.01 | Critic loss: 2.15 | Entropy loss: -0.0002  | Total Loss: 2.16 | Total Steps: 31\n",
      "\n",
      "---black capsule---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 507/94000  | Episode Reward: -10  | Average Reward 8.60  | Actor loss: -0.00 | Critic loss: 5.88 | Entropy loss: -0.0000  | Total Loss: 5.88 | Total Steps: 500\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 508/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.00 | Critic loss: 1.60 | Entropy loss: -0.0000  | Total Loss: 1.61 | Total Steps: 6\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 509/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: -0.51 | Critic loss: 3.49 | Entropy loss: -0.0050  | Total Loss: 2.97 | Total Steps: 64\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 510/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.04 | Critic loss: 0.95 | Entropy loss: -0.0001  | Total Loss: 0.99 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 511/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.00 | Critic loss: 3.64 | Entropy loss: -0.0001  | Total Loss: 3.65 | Total Steps: 34\n",
      "\n",
      "---blue cube---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 512/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: -0.03 | Critic loss: 1.39 | Entropy loss: -0.0013  | Total Loss: 1.35 | Total Steps: 44\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 513/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: -0.05 | Critic loss: 1.31 | Entropy loss: -0.0003  | Total Loss: 1.26 | Total Steps: 39\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 514/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.26 | Critic loss: 0.97 | Entropy loss: -0.0005  | Total Loss: 1.23 | Total Steps: 8\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 515/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.01 | Critic loss: 2.07 | Entropy loss: -0.0001  | Total Loss: 2.08 | Total Steps: 31\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 516/94000  | Episode Reward: 8  | Average Reward 8.60  | Actor loss: -0.01 | Critic loss: 6.53 | Entropy loss: -0.0003  | Total Loss: 6.52 | Total Steps: 32\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 517/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.02 | Critic loss: 0.81 | Entropy loss: -0.0012  | Total Loss: 0.83 | Total Steps: 14\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 518/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.30 | Critic loss: 0.34 | Entropy loss: -0.0012  | Total Loss: 0.64 | Total Steps: 9\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 519/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.05 | Critic loss: 0.11 | Entropy loss: -0.0004  | Total Loss: 0.16 | Total Steps: 8\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 520/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.01 | Critic loss: 1.39 | Entropy loss: -0.0000  | Total Loss: 1.40 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 521/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 522/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.34 | Critic loss: 0.12 | Entropy loss: -0.0043  | Total Loss: 0.46 | Total Steps: 12\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 523/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 524/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: -0.32 | Critic loss: 1.63 | Entropy loss: -0.0024  | Total Loss: 1.30 | Total Steps: 42\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 525/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 526/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0000  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 527/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: 0.24 | Critic loss: 0.96 | Entropy loss: -0.0026  | Total Loss: 1.20 | Total Steps: 12\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 528/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 529/94000  | Episode Reward: 8  | Average Reward 8.93  | Actor loss: -0.08 | Critic loss: 1.27 | Entropy loss: -0.0004  | Total Loss: 1.20 | Total Steps: 38\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 530/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0000  | Total Loss: 0.11 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 531/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: 0.13 | Critic loss: 0.23 | Entropy loss: -0.0010  | Total Loss: 0.37 | Total Steps: 10\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 532/94000  | Episode Reward: 5  | Average Reward 8.90  | Actor loss: -0.98 | Critic loss: 9.32 | Entropy loss: -0.0059  | Total Loss: 8.34 | Total Steps: 93\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 533/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.22 | Critic loss: 1.07 | Entropy loss: -0.0028  | Total Loss: 1.29 | Total Steps: 33\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 534/94000  | Episode Reward: 8  | Average Reward 8.88  | Actor loss: 0.00 | Critic loss: 0.28 | Entropy loss: -0.0001  | Total Loss: 0.28 | Total Steps: 38\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 535/94000  | Episode Reward: 8  | Average Reward 8.88  | Actor loss: 0.00 | Critic loss: 2.74 | Entropy loss: -0.0016  | Total Loss: 2.74 | Total Steps: 45\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 536/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 537/94000  | Episode Reward: 8  | Average Reward 8.85  | Actor loss: -0.04 | Critic loss: 2.04 | Entropy loss: -0.0008  | Total Loss: 2.00 | Total Steps: 64\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 538/94000  | Episode Reward: 8  | Average Reward 8.82  | Actor loss: -0.00 | Critic loss: 1.73 | Entropy loss: -0.0001  | Total Loss: 1.73 | Total Steps: 49\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 539/94000  | Episode Reward: 10  | Average Reward 8.82  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0000  | Total Loss: 0.13 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 540/94000  | Episode Reward: 10  | Average Reward 8.82  | Actor loss: -0.26 | Critic loss: 1.35 | Entropy loss: -0.0011  | Total Loss: 1.09 | Total Steps: 31\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 541/94000  | Episode Reward: 10  | Average Reward 8.85  | Actor loss: -0.21 | Critic loss: 2.68 | Entropy loss: -0.0012  | Total Loss: 2.47 | Total Steps: 44\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 542/94000  | Episode Reward: 10  | Average Reward 8.85  | Actor loss: 0.19 | Critic loss: 0.45 | Entropy loss: -0.0006  | Total Loss: 0.63 | Total Steps: 11\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 543/94000  | Episode Reward: 8  | Average Reward 8.82  | Actor loss: -0.16 | Critic loss: 3.69 | Entropy loss: -0.0016  | Total Loss: 3.52 | Total Steps: 49\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 544/94000  | Episode Reward: 10  | Average Reward 8.82  | Actor loss: -0.11 | Critic loss: 1.44 | Entropy loss: -0.0051  | Total Loss: 1.32 | Total Steps: 58\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 545/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.36 | Critic loss: 0.31 | Entropy loss: -0.0015  | Total Loss: 0.66 | Total Steps: 7\n",
      "\n",
      "---green sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 546/94000  | Episode Reward: 8  | Average Reward 9.00  | Actor loss: -0.00 | Critic loss: 2.07 | Entropy loss: -0.0002  | Total Loss: 2.07 | Total Steps: 29\n",
      "\n",
      "---black cylinder---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 547/94000  | Episode Reward: -10  | Average Reward 8.82  | Actor loss: -0.00 | Critic loss: 3.67 | Entropy loss: -0.0000  | Total Loss: 3.67 | Total Steps: 500\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 548/94000  | Episode Reward: 10  | Average Reward 8.82  | Actor loss: 0.01 | Critic loss: 2.86 | Entropy loss: -0.0001  | Total Loss: 2.87 | Total Steps: 31\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 549/94000  | Episode Reward: 10  | Average Reward 8.85  | Actor loss: 0.39 | Critic loss: 2.15 | Entropy loss: -0.0009  | Total Loss: 2.53 | Total Steps: 10\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 550/94000  | Episode Reward: 10  | Average Reward 8.85  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 551/94000  | Episode Reward: 10  | Average Reward 8.85  | Actor loss: -0.00 | Critic loss: 1.80 | Entropy loss: -0.0001  | Total Loss: 1.80 | Total Steps: 31\n",
      "\n",
      "---black cube---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 552/94000  | Episode Reward: -10  | Average Reward 8.65  | Actor loss: -0.00 | Critic loss: 4.26 | Entropy loss: -0.0001  | Total Loss: 4.26 | Total Steps: 500\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 553/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.02 | Critic loss: 0.19 | Entropy loss: -0.0006  | Total Loss: 0.21 | Total Steps: 11\n",
      "\n",
      "---red sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 554/94000  | Episode Reward: 8  | Average Reward 8.62  | Actor loss: -0.52 | Critic loss: 3.96 | Entropy loss: -0.0083  | Total Loss: 3.43 | Total Steps: 64\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 555/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.03 | Critic loss: 0.02 | Entropy loss: -0.0005  | Total Loss: 0.05 | Total Steps: 8\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 556/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: -0.04 | Critic loss: 0.47 | Entropy loss: -0.0025  | Total Loss: 0.43 | Total Steps: 45\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 557/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0000  | Total Loss: 0.16 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 558/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.07 | Critic loss: 1.45 | Entropy loss: -0.0014  | Total Loss: 1.52 | Total Steps: 65\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 559/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.18 | Critic loss: 0.15 | Entropy loss: -0.0009  | Total Loss: 0.33 | Total Steps: 9\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 560/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: -0.16 | Critic loss: 0.11 | Entropy loss: -0.0010  | Total Loss: -0.05 | Total Steps: 9\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 561/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.24 | Critic loss: 0.14 | Entropy loss: -0.0011  | Total Loss: 0.38 | Total Steps: 9\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 562/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 563/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 564/94000  | Episode Reward: 8  | Average Reward 8.68  | Actor loss: -0.33 | Critic loss: 2.61 | Entropy loss: -0.0022  | Total Loss: 2.27 | Total Steps: 44\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 565/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 566/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 567/94000  | Episode Reward: 8  | Average Reward 8.72  | Actor loss: -0.06 | Critic loss: 1.94 | Entropy loss: -0.0032  | Total Loss: 1.88 | Total Steps: 31\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 568/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0000  | Total Loss: 0.11 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 569/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 570/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: 0.00 | Critic loss: 1.71 | Entropy loss: -0.0000  | Total Loss: 1.71 | Total Steps: 31\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 571/94000  | Episode Reward: 8  | Average Reward 8.70  | Actor loss: -0.03 | Critic loss: 1.43 | Entropy loss: -0.0005  | Total Loss: 1.40 | Total Steps: 29\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 572/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 573/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 574/94000  | Episode Reward: 8  | Average Reward 8.68  | Actor loss: -0.00 | Critic loss: 6.34 | Entropy loss: -0.0001  | Total Loss: 6.34 | Total Steps: 42\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 575/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.00 | Critic loss: 1.54 | Entropy loss: -0.0000  | Total Loss: 1.54 | Total Steps: 31\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 576/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: -0.07 | Critic loss: 6.45 | Entropy loss: -0.0008  | Total Loss: 6.38 | Total Steps: 36\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 577/94000  | Episode Reward: 8  | Average Reward 8.65  | Actor loss: -0.17 | Critic loss: 4.63 | Entropy loss: -0.0007  | Total Loss: 4.46 | Total Steps: 44\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 578/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.10 | Critic loss: 0.17 | Entropy loss: -0.0009  | Total Loss: 0.27 | Total Steps: 8\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 579/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---black prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 580/94000  | Episode Reward: 5  | Average Reward 8.62  | Actor loss: -0.02 | Critic loss: 3.56 | Entropy loss: -0.0003  | Total Loss: 3.54 | Total Steps: 49\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 581/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 582/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 583/94000  | Episode Reward: 8  | Average Reward 8.60  | Actor loss: 0.01 | Critic loss: 6.28 | Entropy loss: -0.0014  | Total Loss: 6.29 | Total Steps: 43\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 584/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.01 | Critic loss: 0.04 | Entropy loss: -0.0005  | Total Loss: 0.05 | Total Steps: 10\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 585/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0000  | Total Loss: 0.10 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 586/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.00 | Critic loss: 1.27 | Entropy loss: -0.0002  | Total Loss: 1.27 | Total Steps: 36\n",
      "\n",
      "---red cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 587/94000  | Episode Reward: 8  | Average Reward 8.57  | Actor loss: -0.15 | Critic loss: 1.82 | Entropy loss: -0.0018  | Total Loss: 1.67 | Total Steps: 52\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 588/94000  | Episode Reward: 10  | Average Reward 8.57  | Actor loss: -0.18 | Critic loss: 0.95 | Entropy loss: -0.0021  | Total Loss: 0.77 | Total Steps: 54\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 589/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.76 | Critic loss: 3.03 | Entropy loss: -0.0046  | Total Loss: 3.79 | Total Steps: 14\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 590/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: -0.74 | Critic loss: 4.23 | Entropy loss: -0.0059  | Total Loss: 3.49 | Total Steps: 61\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 591/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0000  | Total Loss: 0.11 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 592/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: -0.03 | Critic loss: 0.09 | Entropy loss: -0.0004  | Total Loss: 0.06 | Total Steps: 10\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 593/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 594/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.02 | Critic loss: 0.27 | Entropy loss: -0.0005  | Total Loss: 0.29 | Total Steps: 40\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 595/94000  | Episode Reward: 5  | Average Reward 8.70  | Actor loss: -0.13 | Critic loss: 3.08 | Entropy loss: -0.0024  | Total Loss: 2.95 | Total Steps: 49\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 596/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 2.69 | Entropy loss: -0.0000  | Total Loss: 2.69 | Total Steps: 31\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 597/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 598/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.01 | Critic loss: 2.07 | Entropy loss: -0.0001  | Total Loss: 2.08 | Total Steps: 31\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 599/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.06 | Critic loss: 0.66 | Entropy loss: -0.0017  | Total Loss: 0.72 | Total Steps: 36\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 600/94000  | Episode Reward: 8  | Average Reward 8.75  | Actor loss: -0.27 | Critic loss: 2.52 | Entropy loss: -0.0015  | Total Loss: 2.24 | Total Steps: 30\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 601/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.01 | Critic loss: 0.10 | Entropy loss: -0.0000  | Total Loss: 0.10 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 10  | Average Reward 7.82  | Actor loss: 0.00 | Critic loss: 0.96 | Entropy loss: -0.0081  | Total Loss: 0.95 | Total Steps: 11\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 10  | Average Reward 7.84  | Actor loss: -0.00 | Critic loss: 0.04 | Entropy loss: -0.0246  | Total Loss: 0.02 | Total Steps: 11\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 3/100  | Episode Reward: 8  | Average Reward 7.82  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0016  | Total Loss: 0.18 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 10  | Average Reward 7.82  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0762  | Total Loss: -0.07 | Total Steps: 9\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 9  | Average Reward 7.81  | Actor loss: 0.41 | Critic loss: 6.94 | Entropy loss: -0.0299  | Total Loss: 7.32 | Total Steps: 36\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 10  | Average Reward 7.81  | Actor loss: 0.00 | Critic loss: 0.34 | Entropy loss: -0.0089  | Total Loss: 0.33 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: 10  | Average Reward 7.81  | Actor loss: 0.00 | Critic loss: 0.27 | Entropy loss: -0.0016  | Total Loss: 0.27 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 10  | Average Reward 7.86  | Actor loss: 0.01 | Critic loss: 2.23 | Entropy loss: -0.0423  | Total Loss: 2.20 | Total Steps: 24\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 10  | Average Reward 7.86  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0175  | Total Loss: 0.00 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 10  | Average Reward 7.87  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0033  | Total Loss: 0.03 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 10  | Average Reward 7.87  | Actor loss: 0.00 | Critic loss: 0.35 | Entropy loss: -0.0053  | Total Loss: 0.34 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 8  | Average Reward 7.87  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0011  | Total Loss: 0.14 | Total Steps: 34\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 10  | Average Reward 7.92  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0083  | Total Loss: -0.00 | Total Steps: 40\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: 10  | Average Reward 7.92  | Actor loss: -0.00 | Critic loss: 0.08 | Entropy loss: -0.0018  | Total Loss: 0.07 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 5  | Average Reward 7.95  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0099  | Total Loss: 0.01 | Total Steps: 47\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 10  | Average Reward 7.97  | Actor loss: -0.00 | Critic loss: 0.04 | Entropy loss: -0.0021  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 8  | Average Reward 7.95  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0003  | Total Loss: 0.20 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 10  | Average Reward 7.95  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0006  | Total Loss: 0.16 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 10  | Average Reward 7.97  | Actor loss: -0.00 | Critic loss: 0.08 | Entropy loss: -0.0005  | Total Loss: 0.08 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: 10  | Average Reward 8.17  | Actor loss: 0.00 | Critic loss: 0.26 | Entropy loss: -0.0002  | Total Loss: 0.26 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 10  | Average Reward 8.17  | Actor loss: 0.13 | Critic loss: 4.11 | Entropy loss: -0.0593  | Total Loss: 4.18 | Total Steps: 9\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 22/100  | Episode Reward: 8  | Average Reward 8.35  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0021  | Total Loss: 0.14 | Total Steps: 36\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 10  | Average Reward 8.35  | Actor loss: -0.00 | Critic loss: 0.09 | Entropy loss: -0.0008  | Total Loss: 0.08 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 10  | Average Reward 8.36  | Actor loss: 0.00 | Critic loss: 0.80 | Entropy loss: -0.0223  | Total Loss: 0.78 | Total Steps: 9\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 1.29 | Entropy loss: -0.0197  | Total Loss: 1.28 | Total Steps: 37\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 10  | Average Reward 8.39  | Actor loss: -0.00 | Critic loss: 0.08 | Entropy loss: -0.0037  | Total Loss: 0.08 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 10  | Average Reward 8.39  | Actor loss: 0.00 | Critic loss: 0.46 | Entropy loss: -0.0007  | Total Loss: 0.46 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 10  | Average Reward 8.44  | Actor loss: 0.05 | Critic loss: 0.45 | Entropy loss: -0.0410  | Total Loss: 0.46 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 10  | Average Reward 8.44  | Actor loss: 0.00 | Critic loss: 0.24 | Entropy loss: -0.0015  | Total Loss: 0.24 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 10  | Average Reward 8.44  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0002  | Total Loss: 0.02 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 8  | Average Reward 8.41  | Actor loss: 0.00 | Critic loss: 0.25 | Entropy loss: -0.0002  | Total Loss: 0.25 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 32/100  | Episode Reward: 10  | Average Reward 8.59  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0960  | Total Loss: -0.10 | Total Steps: 11\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 33/100  | Episode Reward: 10  | Average Reward 8.59  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0076  | Total Loss: 0.02 | Total Steps: 40\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 34/100  | Episode Reward: -10  | Average Reward 8.38  | Actor loss: -0.00 | Critic loss: 79.43 | Entropy loss: -0.0001  | Total Loss: 79.43 | Total Steps: 500\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 35/100  | Episode Reward: 8  | Average Reward 8.36  | Actor loss: -0.00 | Critic loss: 0.04 | Entropy loss: -0.0082  | Total Loss: 0.03 | Total Steps: 39\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 36/100  | Episode Reward: 10  | Average Reward 8.56  | Actor loss: 0.00 | Critic loss: 1.07 | Entropy loss: -0.0198  | Total Loss: 1.05 | Total Steps: 9\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 37/100  | Episode Reward: -5  | Average Reward 8.44  | Actor loss: 0.00 | Critic loss: 0.97 | Entropy loss: -0.0054  | Total Loss: 0.97 | Total Steps: 380\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: 8  | Average Reward 8.41  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0095  | Total Loss: 0.20 | Total Steps: 73\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 10  | Average Reward 8.41  | Actor loss: 0.00 | Critic loss: 0.24 | Entropy loss: -0.0018  | Total Loss: 0.24 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 10  | Average Reward 8.44  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0004  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 5  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0018  | Total Loss: 0.04 | Total Steps: 47\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 0.36 | Entropy loss: -0.0005  | Total Loss: 0.36 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 43/100  | Episode Reward: 5  | Average Reward 8.34  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0057  | Total Loss: 0.03 | Total Steps: 77\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 10  | Average Reward 8.34  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0334  | Total Loss: -0.03 | Total Steps: 8\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: 10  | Average Reward 8.34  | Actor loss: 0.01 | Critic loss: 4.24 | Entropy loss: -0.0090  | Total Loss: 4.24 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 10  | Average Reward 8.34  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0016  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 8  | Average Reward 8.34  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0041  | Total Loss: 0.09 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 10  | Average Reward 8.34  | Actor loss: 0.00 | Critic loss: 0.84 | Entropy loss: -0.1042  | Total Loss: 0.73 | Total Steps: 9\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 10  | Average Reward 8.36  | Actor loss: 0.00 | Critic loss: 0.44 | Entropy loss: -0.0175  | Total Loss: 0.42 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 10  | Average Reward 8.36  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0034  | Total Loss: 0.01 | Total Steps: 275\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 10  | Average Reward 8.41  | Actor loss: 0.00 | Critic loss: 0.34 | Entropy loss: -0.0055  | Total Loss: 0.33 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 5  | Average Reward 8.36  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0010  | Total Loss: 0.11 | Total Steps: 46\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 53/100  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 1.30 | Entropy loss: -0.0001  | Total Loss: 1.30 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 54/100  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: 0.24 | Critic loss: 0.84 | Entropy loss: -0.0362  | Total Loss: 1.04 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0062  | Total Loss: 0.08 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: 8  | Average Reward 8.36  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0009  | Total Loss: 0.03 | Total Steps: 36\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 8  | Average Reward 8.54  | Actor loss: 0.00 | Critic loss: 0.76 | Entropy loss: -0.0084  | Total Loss: 0.75 | Total Steps: 34\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 10  | Average Reward 8.54  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0107  | Total Loss: 0.00 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 8  | Average Reward 8.51  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0050  | Total Loss: 0.06 | Total Steps: 193\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 60/100  | Episode Reward: 8  | Average Reward 8.48  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0005  | Total Loss: 0.03 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 61/100  | Episode Reward: 8  | Average Reward 8.48  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0088  | Total Loss: 0.07 | Total Steps: 44\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 5  | Average Reward 8.46  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0143  | Total Loss: 0.03 | Total Steps: 67\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: 9  | Average Reward 8.45  | Actor loss: 0.00 | Critic loss: 0.53 | Entropy loss: -0.0304  | Total Loss: 0.50 | Total Steps: 22\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 64/100  | Episode Reward: 10  | Average Reward 8.45  | Actor loss: 0.00 | Critic loss: 0.47 | Entropy loss: -0.0012  | Total Loss: 0.47 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 65/100  | Episode Reward: 10  | Average Reward 8.45  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0447  | Total Loss: -0.04 | Total Steps: 10\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 10  | Average Reward 8.47  | Actor loss: 0.04 | Critic loss: 0.80 | Entropy loss: -0.0508  | Total Loss: 0.79 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 8  | Average Reward 8.45  | Actor loss: 0.00 | Critic loss: 0.54 | Entropy loss: -0.0016  | Total Loss: 0.54 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 68/100  | Episode Reward: 10  | Average Reward 8.45  | Actor loss: 0.02 | Critic loss: 12.33 | Entropy loss: -0.0115  | Total Loss: 12.33 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 10  | Average Reward 8.45  | Actor loss: 0.00 | Critic loss: 0.33 | Entropy loss: -0.0071  | Total Loss: 0.32 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 70/100  | Episode Reward: -10  | Average Reward 8.30  | Actor loss: -0.00 | Critic loss: 82.30 | Entropy loss: -0.0001  | Total Loss: 82.29 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 10  | Average Reward 8.30  | Actor loss: 0.01 | Critic loss: 8.16 | Entropy loss: -0.0043  | Total Loss: 8.17 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 10  | Average Reward 8.30  | Actor loss: 0.03 | Critic loss: 2.19 | Entropy loss: -0.0454  | Total Loss: 2.18 | Total Steps: 37\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 10  | Average Reward 8.30  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0077  | Total Loss: 0.08 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: 2  | Average Reward 8.22  | Actor loss: 0.00 | Critic loss: 0.32 | Entropy loss: -0.0229  | Total Loss: 0.30 | Total Steps: 49\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 10  | Average Reward 8.26  | Actor loss: -0.00 | Critic loss: 0.07 | Entropy loss: -0.0042  | Total Loss: 0.07 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 9  | Average Reward 8.25  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0211  | Total Loss: -0.01 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 77/100  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: 0.00 | Critic loss: 0.27 | Entropy loss: -0.0037  | Total Loss: 0.26 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: 0.00 | Critic loss: 0.33 | Entropy loss: -0.0003  | Total Loss: 0.33 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: 0.00 | Critic loss: 0.27 | Entropy loss: -0.0088  | Total Loss: 0.26 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: -0.00 | Critic loss: 0.07 | Entropy loss: -0.0018  | Total Loss: 0.07 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: 0.01 | Critic loss: 1.25 | Entropy loss: -0.0547  | Total Loss: 1.21 | Total Steps: 7\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: -46  | Average Reward 7.79  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0521  | Total Loss: -0.00 | Total Steps: 285\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 8  | Average Reward 7.76  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0016  | Total Loss: 0.20 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 84/100  | Episode Reward: -10  | Average Reward 7.56  | Actor loss: -0.00 | Critic loss: 83.48 | Entropy loss: -0.0013  | Total Loss: 83.48 | Total Steps: 500\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 85/100  | Episode Reward: 8  | Average Reward 7.56  | Actor loss: 0.00 | Critic loss: 0.62 | Entropy loss: -0.0012  | Total Loss: 0.62 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: 5  | Average Reward 7.71  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0015  | Total Loss: 0.02 | Total Steps: 46\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 10  | Average Reward 7.71  | Actor loss: 0.00 | Critic loss: 0.27 | Entropy loss: -0.0095  | Total Loss: 0.26 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 10  | Average Reward 7.71  | Actor loss: 0.00 | Critic loss: 2.73 | Entropy loss: -0.0006  | Total Loss: 2.73 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 89/100  | Episode Reward: 10  | Average Reward 7.71  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0002  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 90/100  | Episode Reward: 10  | Average Reward 7.71  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0023  | Total Loss: 0.09 | Total Steps: 36\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 10  | Average Reward 7.71  | Actor loss: -0.00 | Critic loss: 0.08 | Entropy loss: -0.0009  | Total Loss: 0.07 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 2  | Average Reward 7.71  | Actor loss: 0.00 | Critic loss: 0.22 | Entropy loss: -0.0038  | Total Loss: 0.22 | Total Steps: 49\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: 8  | Average Reward 7.71  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0015  | Total Loss: 0.00 | Total Steps: 39\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 10  | Average Reward 7.71  | Actor loss: 0.00 | Critic loss: 0.48 | Entropy loss: -0.0001  | Total Loss: 0.48 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: -17  | Average Reward 7.46  | Actor loss: 0.00 | Critic loss: 0.78 | Entropy loss: -0.0447  | Total Loss: 0.74 | Total Steps: 204\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 8  | Average Reward 7.44  | Actor loss: 0.00 | Critic loss: 0.26 | Entropy loss: -0.0098  | Total Loss: 0.26 | Total Steps: 35\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 10  | Average Reward 7.46  | Actor loss: 0.01 | Critic loss: 5.00 | Entropy loss: -0.0045  | Total Loss: 5.00 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: 10  | Average Reward 7.49  | Actor loss: 0.00 | Critic loss: 0.25 | Entropy loss: -0.0009  | Total Loss: 0.25 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 8  | Average Reward 7.46  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0004  | Total Loss: 0.04 | Total Steps: 34\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 8  | Average Reward 7.44  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0077  | Total Loss: 0.05 | Total Steps: 59\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 602/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: -0.05 | Critic loss: 1.38 | Entropy loss: -0.0017  | Total Loss: 1.33 | Total Steps: 42\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 603/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: 0.14 | Critic loss: 0.45 | Entropy loss: -0.0006  | Total Loss: 0.59 | Total Steps: 12\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 604/94000  | Episode Reward: 8  | Average Reward 8.78  | Actor loss: -0.00 | Critic loss: 0.37 | Entropy loss: -0.0000  | Total Loss: 0.37 | Total Steps: 38\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 605/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 606/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 607/94000  | Episode Reward: 10  | Average Reward 9.00  | Actor loss: 0.00 | Critic loss: 0.47 | Entropy loss: -0.0005  | Total Loss: 0.47 | Total Steps: 44\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 608/94000  | Episode Reward: 10  | Average Reward 9.00  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 609/94000  | Episode Reward: 10  | Average Reward 9.00  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 610/94000  | Episode Reward: 10  | Average Reward 9.00  | Actor loss: 0.06 | Critic loss: 0.38 | Entropy loss: -0.0009  | Total Loss: 0.44 | Total Steps: 12\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 611/94000  | Episode Reward: 8  | Average Reward 8.97  | Actor loss: -0.20 | Critic loss: 4.80 | Entropy loss: -0.0013  | Total Loss: 4.60 | Total Steps: 47\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 612/94000  | Episode Reward: 8  | Average Reward 8.95  | Actor loss: -0.06 | Critic loss: 5.42 | Entropy loss: -0.0024  | Total Loss: 5.35 | Total Steps: 39\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 613/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.00 | Critic loss: 2.16 | Entropy loss: -0.0000  | Total Loss: 2.16 | Total Steps: 31\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 614/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: -1.12 | Critic loss: 4.68 | Entropy loss: -0.0053  | Total Loss: 3.55 | Total Steps: 61\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 615/94000  | Episode Reward: 2  | Average Reward 8.88  | Actor loss: -0.20 | Critic loss: 8.04 | Entropy loss: -0.0025  | Total Loss: 7.84 | Total Steps: 57\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 616/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.01 | Critic loss: 0.45 | Entropy loss: -0.0000  | Total Loss: 0.46 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 617/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.23 | Critic loss: 1.27 | Entropy loss: -0.0010  | Total Loss: 1.50 | Total Steps: 9\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 618/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.06 | Critic loss: 5.30 | Entropy loss: -0.0003  | Total Loss: 5.36 | Total Steps: 31\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 619/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.16 | Critic loss: 0.18 | Entropy loss: -0.0017  | Total Loss: 0.34 | Total Steps: 10\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 620/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 621/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.01 | Critic loss: 0.24 | Entropy loss: -0.0004  | Total Loss: 0.25 | Total Steps: 38\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 622/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.01 | Critic loss: 0.28 | Entropy loss: -0.0000  | Total Loss: 0.29 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 623/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---green prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 624/94000  | Episode Reward: 8  | Average Reward 8.88  | Actor loss: 0.23 | Critic loss: 0.63 | Entropy loss: -0.0017  | Total Loss: 0.86 | Total Steps: 37\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 625/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.02 | Critic loss: 0.01 | Entropy loss: -0.0003  | Total Loss: 0.03 | Total Steps: 8\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 626/94000  | Episode Reward: 8  | Average Reward 8.85  | Actor loss: -0.01 | Critic loss: 1.43 | Entropy loss: -0.0011  | Total Loss: 1.42 | Total Steps: 48\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 627/94000  | Episode Reward: 10  | Average Reward 8.85  | Actor loss: 0.01 | Critic loss: 0.66 | Entropy loss: -0.0014  | Total Loss: 0.67 | Total Steps: 14\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 628/94000  | Episode Reward: 10  | Average Reward 8.85  | Actor loss: -0.06 | Critic loss: 1.29 | Entropy loss: -0.0005  | Total Loss: 1.24 | Total Steps: 34\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 629/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 630/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.11 | Critic loss: 0.12 | Entropy loss: -0.0005  | Total Loss: 0.23 | Total Steps: 8\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 631/94000  | Episode Reward: 8  | Average Reward 8.85  | Actor loss: -0.28 | Critic loss: 3.27 | Entropy loss: -0.0045  | Total Loss: 2.99 | Total Steps: 56\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 632/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.00 | Critic loss: 1.67 | Entropy loss: -0.0000  | Total Loss: 1.67 | Total Steps: 31\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 633/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: -0.24 | Critic loss: 3.72 | Entropy loss: -0.0013  | Total Loss: 3.48 | Total Steps: 52\n",
      "\n",
      "---black capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 634/94000  | Episode Reward: 8  | Average Reward 8.90  | Actor loss: -0.03 | Critic loss: 1.75 | Entropy loss: -0.0009  | Total Loss: 1.72 | Total Steps: 38\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 635/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: 0.09 | Critic loss: 0.10 | Entropy loss: -0.0005  | Total Loss: 0.19 | Total Steps: 8\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 636/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: -0.02 | Critic loss: 1.55 | Entropy loss: -0.0003  | Total Loss: 1.53 | Total Steps: 34\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 637/94000  | Episode Reward: 8  | Average Reward 8.93  | Actor loss: -0.11 | Critic loss: 3.42 | Entropy loss: -0.0008  | Total Loss: 3.31 | Total Steps: 36\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 638/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: -0.24 | Critic loss: 0.74 | Entropy loss: -0.0009  | Total Loss: 0.50 | Total Steps: 11\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 639/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.03 | Critic loss: 0.56 | Entropy loss: -0.0005  | Total Loss: 0.59 | Total Steps: 44\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 640/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.07 | Critic loss: 8.10 | Entropy loss: -0.0000  | Total Loss: 8.17 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 641/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.28 | Critic loss: 0.42 | Entropy loss: -0.0010  | Total Loss: 0.70 | Total Steps: 11\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 642/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.01 | Critic loss: 1.08 | Entropy loss: -0.0001  | Total Loss: 1.09 | Total Steps: 31\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 643/94000  | Episode Reward: 8  | Average Reward 8.95  | Actor loss: -0.17 | Critic loss: 6.02 | Entropy loss: -0.0016  | Total Loss: 5.85 | Total Steps: 59\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 644/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: -0.03 | Critic loss: 3.76 | Entropy loss: -0.0004  | Total Loss: 3.73 | Total Steps: 17\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 645/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.00 | Critic loss: 3.87 | Entropy loss: -0.0001  | Total Loss: 3.87 | Total Steps: 34\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 646/94000  | Episode Reward: 8  | Average Reward 8.95  | Actor loss: -0.21 | Critic loss: 3.56 | Entropy loss: -0.0021  | Total Loss: 3.34 | Total Steps: 49\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 647/94000  | Episode Reward: 10  | Average Reward 9.15  | Actor loss: 0.04 | Critic loss: 0.56 | Entropy loss: -0.0012  | Total Loss: 0.59 | Total Steps: 46\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 648/94000  | Episode Reward: 10  | Average Reward 9.15  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 649/94000  | Episode Reward: 8  | Average Reward 9.12  | Actor loss: 0.06 | Critic loss: 1.87 | Entropy loss: -0.0023  | Total Loss: 1.93 | Total Steps: 49\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 650/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: -0.01 | Critic loss: 0.54 | Entropy loss: -0.0007  | Total Loss: 0.53 | Total Steps: 50\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 651/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 9.325. Model has been saved-----\n",
      "Training  | Episode: 652/94000  | Episode Reward: 10  | Average Reward 9.32  | Actor loss: -1.41 | Critic loss: 6.07 | Entropy loss: -0.0088  | Total Loss: 4.65 | Total Steps: 58\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 653/94000  | Episode Reward: 5  | Average Reward 9.28  | Actor loss: -0.72 | Critic loss: 9.92 | Entropy loss: -0.0062  | Total Loss: 9.20 | Total Steps: 54\n",
      "\n",
      "---red sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 654/94000  | Episode Reward: 8  | Average Reward 9.28  | Actor loss: 0.00 | Critic loss: 6.26 | Entropy loss: -0.0003  | Total Loss: 6.27 | Total Steps: 32\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 655/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.00 | Critic loss: 0.29 | Entropy loss: -0.0000  | Total Loss: 0.29 | Total Steps: 6\n",
      "\n",
      "---red cube---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 656/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0000  | Total Loss: 0.08 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 657/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: -0.63 | Critic loss: 4.39 | Entropy loss: -0.0021  | Total Loss: 3.76 | Total Steps: 42\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 658/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.00 | Critic loss: 2.43 | Entropy loss: -0.0000  | Total Loss: 2.43 | Total Steps: 31\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 659/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.05 | Critic loss: 1.80 | Entropy loss: -0.0008  | Total Loss: 1.85 | Total Steps: 49\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 660/94000  | Episode Reward: 5  | Average Reward 9.22  | Actor loss: -0.01 | Critic loss: 7.54 | Entropy loss: -0.0001  | Total Loss: 7.54 | Total Steps: 49\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 661/94000  | Episode Reward: 8  | Average Reward 9.20  | Actor loss: -0.41 | Critic loss: 3.64 | Entropy loss: -0.0016  | Total Loss: 3.22 | Total Steps: 42\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 662/94000  | Episode Reward: 8  | Average Reward 9.18  | Actor loss: -0.02 | Critic loss: 2.57 | Entropy loss: -0.0009  | Total Loss: 2.54 | Total Steps: 107\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 663/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.01 | Critic loss: 0.19 | Entropy loss: -0.0000  | Total Loss: 0.20 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 664/94000  | Episode Reward: 8  | Average Reward 9.18  | Actor loss: -0.03 | Critic loss: 1.59 | Entropy loss: -0.0001  | Total Loss: 1.56 | Total Steps: 38\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 665/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.00 | Critic loss: 0.45 | Entropy loss: -0.0000  | Total Loss: 0.45 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 666/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 667/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: -0.74 | Critic loss: 2.16 | Entropy loss: -0.0047  | Total Loss: 1.41 | Total Steps: 54\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 668/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0000  | Total Loss: 0.16 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 669/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: 0.20 | Critic loss: 1.18 | Entropy loss: -0.0004  | Total Loss: 1.38 | Total Steps: 11\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 670/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: 0.03 | Critic loss: 0.18 | Entropy loss: -0.0001  | Total Loss: 0.21 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 671/94000  | Episode Reward: 10  | Average Reward 9.22  | Actor loss: 0.37 | Critic loss: 0.43 | Entropy loss: -0.0023  | Total Loss: 0.80 | Total Steps: 11\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 672/94000  | Episode Reward: 10  | Average Reward 9.22  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 673/94000  | Episode Reward: 10  | Average Reward 9.22  | Actor loss: 0.01 | Critic loss: 0.15 | Entropy loss: -0.0000  | Total Loss: 0.15 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 674/94000  | Episode Reward: 10  | Average Reward 9.25  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0000  | Total Loss: 0.08 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 675/94000  | Episode Reward: 10  | Average Reward 9.25  | Actor loss: -0.11 | Critic loss: 2.18 | Entropy loss: -0.0023  | Total Loss: 2.06 | Total Steps: 55\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 676/94000  | Episode Reward: 8  | Average Reward 9.22  | Actor loss: -0.11 | Critic loss: 2.46 | Entropy loss: -0.0010  | Total Loss: 2.35 | Total Steps: 30\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 677/94000  | Episode Reward: 10  | Average Reward 9.25  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 678/94000  | Episode Reward: 10  | Average Reward 9.25  | Actor loss: 0.00 | Critic loss: 1.75 | Entropy loss: -0.0000  | Total Loss: 1.75 | Total Steps: 31\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 679/94000  | Episode Reward: 10  | Average Reward 9.25  | Actor loss: -0.02 | Critic loss: 0.08 | Entropy loss: -0.0004  | Total Loss: 0.06 | Total Steps: 11\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 680/94000  | Episode Reward: 10  | Average Reward 9.30  | Actor loss: -0.11 | Critic loss: 2.82 | Entropy loss: -0.0011  | Total Loss: 2.71 | Total Steps: 47\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 681/94000  | Episode Reward: 8  | Average Reward 9.28  | Actor loss: -0.17 | Critic loss: 2.48 | Entropy loss: -0.0031  | Total Loss: 2.31 | Total Steps: 57\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 682/94000  | Episode Reward: 8  | Average Reward 9.25  | Actor loss: -0.40 | Critic loss: 3.40 | Entropy loss: -0.0037  | Total Loss: 3.00 | Total Steps: 47\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 683/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: -0.06 | Critic loss: 1.69 | Entropy loss: -0.0003  | Total Loss: 1.63 | Total Steps: 35\n",
      "\n",
      "---black capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 684/94000  | Episode Reward: 8  | Average Reward 9.25  | Actor loss: -0.11 | Critic loss: 3.93 | Entropy loss: -0.0008  | Total Loss: 3.81 | Total Steps: 67\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 685/94000  | Episode Reward: 10  | Average Reward 9.25  | Actor loss: -0.01 | Critic loss: 0.78 | Entropy loss: -0.0006  | Total Loss: 0.77 | Total Steps: 49\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 686/94000  | Episode Reward: 10  | Average Reward 9.25  | Actor loss: 0.40 | Critic loss: 0.23 | Entropy loss: -0.0016  | Total Loss: 0.63 | Total Steps: 9\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 687/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 688/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: -0.01 | Critic loss: 3.84 | Entropy loss: -0.0007  | Total Loss: 3.83 | Total Steps: 45\n",
      "\n",
      "---red cube---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 689/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.00 | Critic loss: 0.24 | Entropy loss: -0.0000  | Total Loss: 0.24 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 690/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 691/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.01 | Critic loss: 0.04 | Entropy loss: -0.0006  | Total Loss: 0.05 | Total Steps: 9\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 692/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0000  | Total Loss: 0.16 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 693/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 694/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.09 | Critic loss: 0.50 | Entropy loss: -0.0004  | Total Loss: 0.59 | Total Steps: 9\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 695/94000  | Episode Reward: 10  | Average Reward 9.32  | Actor loss: 0.01 | Critic loss: 0.25 | Entropy loss: -0.0000  | Total Loss: 0.27 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 696/94000  | Episode Reward: 10  | Average Reward 9.32  | Actor loss: -0.21 | Critic loss: 0.09 | Entropy loss: -0.0019  | Total Loss: -0.12 | Total Steps: 10\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 697/94000  | Episode Reward: 10  | Average Reward 9.32  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0000  | Total Loss: 0.08 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 698/94000  | Episode Reward: 10  | Average Reward 9.32  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 699/94000  | Episode Reward: 10  | Average Reward 9.32  | Actor loss: 0.02 | Critic loss: 0.27 | Entropy loss: -0.0007  | Total Loss: 0.29 | Total Steps: 40\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 9.35. Model has been saved-----\n",
      "Training  | Episode: 700/94000  | Episode Reward: 10  | Average Reward 9.35  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 701/94000  | Episode Reward: -10  | Average Reward 9.15  | Actor loss: -0.00 | Critic loss: 3.78 | Entropy loss: -0.0001  | Total Loss: 3.77 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 10  | Average Reward 7.44  | Actor loss: 0.20 | Critic loss: 4.62 | Entropy loss: -0.0143  | Total Loss: 4.80 | Total Steps: 7\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 10  | Average Reward 7.44  | Actor loss: -0.00 | Critic loss: 0.07 | Entropy loss: -0.0028  | Total Loss: 0.07 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 3/100  | Episode Reward: 10  | Average Reward 7.46  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0054  | Total Loss: -0.00 | Total Steps: 40\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 10  | Average Reward 7.46  | Actor loss: 0.11 | Critic loss: 0.52 | Entropy loss: -0.0413  | Total Loss: 0.59 | Total Steps: 7\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 10  | Average Reward 7.47  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0071  | Total Loss: -0.01 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 6/100  | Episode Reward: -10  | Average Reward 7.28  | Actor loss: -0.00 | Critic loss: 58.94 | Entropy loss: -0.0001  | Total Loss: 58.93 | Total Steps: 500\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: 10  | Average Reward 7.28  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0228  | Total Loss: 0.08 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 10  | Average Reward 7.28  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0026  | Total Loss: 0.04 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 0  | Average Reward 7.17  | Actor loss: 0.31 | Critic loss: 0.57 | Entropy loss: -0.0087  | Total Loss: 0.87 | Total Steps: 49\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 10  | Average Reward 7.17  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0133  | Total Loss: 0.00 | Total Steps: 61\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 10  | Average Reward 7.17  | Actor loss: -0.00 | Critic loss: 0.04 | Entropy loss: -0.0027  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 10  | Average Reward 7.20  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0158  | Total Loss: -0.00 | Total Steps: 10\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 10  | Average Reward 7.20  | Actor loss: 0.00 | Critic loss: 1.81 | Entropy loss: -0.0044  | Total Loss: 1.81 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: 10  | Average Reward 7.20  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0169  | Total Loss: 0.13 | Total Steps: 12\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 10  | Average Reward 7.25  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0403  | Total Loss: 0.09 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 10  | Average Reward 7.25  | Actor loss: 0.00 | Critic loss: 0.90 | Entropy loss: -0.0016  | Total Loss: 0.90 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 10  | Average Reward 7.28  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0004  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 10  | Average Reward 7.28  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0003  | Total Loss: 0.08 | Total Steps: 6\n",
      "TEST: ---red capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 8  | Average Reward 7.25  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0177  | Total Loss: -0.00 | Total Steps: 59\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: 10  | Average Reward 7.25  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0031  | Total Loss: 0.11 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 10  | Average Reward 7.25  | Actor loss: 0.00 | Critic loss: 0.58 | Entropy loss: -0.0015  | Total Loss: 0.58 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 22/100  | Episode Reward: 10  | Average Reward 7.28  | Actor loss: 0.01 | Critic loss: 4.20 | Entropy loss: -0.0035  | Total Loss: 4.21 | Total Steps: 188\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 10  | Average Reward 7.28  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0019  | Total Loss: 0.10 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 8  | Average Reward 7.25  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0005  | Total Loss: 0.02 | Total Steps: 38\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 10  | Average Reward 7.25  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0190  | Total Loss: 0.15 | Total Steps: 13\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 10  | Average Reward 7.25  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0228  | Total Loss: 0.10 | Total Steps: 47\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 10  | Average Reward 7.25  | Actor loss: -0.00 | Critic loss: 0.06 | Entropy loss: -0.0275  | Total Loss: 0.03 | Total Steps: 11\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 28/100  | Episode Reward: -15  | Average Reward 7.00  | Actor loss: -0.00 | Critic loss: 74.47 | Entropy loss: -0.0016  | Total Loss: 74.46 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 29/100  | Episode Reward: -12  | Average Reward 6.78  | Actor loss: -0.00 | Critic loss: 79.00 | Entropy loss: -0.0001  | Total Loss: 78.99 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 8  | Average Reward 6.75  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0002  | Total Loss: 0.03 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 2  | Average Reward 6.70  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0051  | Total Loss: 0.08 | Total Steps: 43\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 32/100  | Episode Reward: 10  | Average Reward 6.70  | Actor loss: 0.00 | Critic loss: 0.52 | Entropy loss: -0.0074  | Total Loss: 0.52 | Total Steps: 8\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 33/100  | Episode Reward: 10  | Average Reward 6.70  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0357  | Total Loss: -0.02 | Total Steps: 52\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 34/100  | Episode Reward: 5  | Average Reward 6.85  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0040  | Total Loss: 0.00 | Total Steps: 46\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 35/100  | Episode Reward: 8  | Average Reward 6.85  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0004  | Total Loss: 0.04 | Total Steps: 38\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 36/100  | Episode Reward: 10  | Average Reward 6.85  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0193  | Total Loss: 0.15 | Total Steps: 13\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 37/100  | Episode Reward: 10  | Average Reward 7.00  | Actor loss: 0.00 | Critic loss: 1.13 | Entropy loss: -0.0007  | Total Loss: 1.13 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: 10  | Average Reward 7.03  | Actor loss: 0.00 | Critic loss: 0.30 | Entropy loss: -0.0439  | Total Loss: 0.26 | Total Steps: 40\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 10  | Average Reward 7.03  | Actor loss: -0.00 | Critic loss: 0.07 | Entropy loss: -0.0078  | Total Loss: 0.07 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 10  | Average Reward 7.03  | Actor loss: 0.01 | Critic loss: 4.77 | Entropy loss: -0.0037  | Total Loss: 4.78 | Total Steps: 36\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 10  | Average Reward 7.08  | Actor loss: -0.00 | Critic loss: 0.05 | Entropy loss: -0.0011  | Total Loss: 0.05 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 8  | Average Reward 7.05  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0046  | Total Loss: -0.00 | Total Steps: 46\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 43/100  | Episode Reward: 10  | Average Reward 7.10  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0009  | Total Loss: 0.14 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 10  | Average Reward 7.10  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0946  | Total Loss: -0.06 | Total Steps: 8\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: 10  | Average Reward 7.10  | Actor loss: 0.00 | Critic loss: 0.42 | Entropy loss: -0.0508  | Total Loss: 0.37 | Total Steps: 7\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 8  | Average Reward 7.08  | Actor loss: -0.00 | Critic loss: 0.15 | Entropy loss: -0.0037  | Total Loss: 0.14 | Total Steps: 50\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 10  | Average Reward 7.10  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0018  | Total Loss: 0.03 | Total Steps: 50\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 10  | Average Reward 7.10  | Actor loss: 0.00 | Critic loss: 1.22 | Entropy loss: -0.0024  | Total Loss: 1.23 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 9  | Average Reward 7.09  | Actor loss: 0.14 | Critic loss: 5.96 | Entropy loss: -0.0318  | Total Loss: 6.06 | Total Steps: 152\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 10  | Average Reward 7.09  | Actor loss: 0.17 | Critic loss: 4.09 | Entropy loss: -0.0680  | Total Loss: 4.19 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 10  | Average Reward 7.09  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0041  | Total Loss: -0.00 | Total Steps: 40\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 8  | Average Reward 7.12  | Actor loss: 0.00 | Critic loss: 0.95 | Entropy loss: -0.0168  | Total Loss: 0.93 | Total Steps: 56\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 53/100  | Episode Reward: 10  | Average Reward 7.12  | Actor loss: 0.00 | Critic loss: 2.17 | Entropy loss: -0.0008  | Total Loss: 2.18 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 54/100  | Episode Reward: 10  | Average Reward 7.12  | Actor loss: 0.00 | Critic loss: 0.42 | Entropy loss: -0.0001  | Total Loss: 0.42 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 10  | Average Reward 7.12  | Actor loss: 0.00 | Critic loss: 0.99 | Entropy loss: -0.0026  | Total Loss: 0.99 | Total Steps: 276\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: 8  | Average Reward 7.12  | Actor loss: 0.00 | Critic loss: 1.54 | Entropy loss: -0.0006  | Total Loss: 1.54 | Total Steps: 29\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 10  | Average Reward 7.14  | Actor loss: 0.20 | Critic loss: 4.65 | Entropy loss: -0.0139  | Total Loss: 4.83 | Total Steps: 7\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 10  | Average Reward 7.14  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0025  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 10  | Average Reward 7.17  | Actor loss: 0.00 | Critic loss: 0.47 | Entropy loss: -0.0441  | Total Loss: 0.43 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 60/100  | Episode Reward: 10  | Average Reward 7.19  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0181  | Total Loss: 0.05 | Total Steps: 41\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 61/100  | Episode Reward: 10  | Average Reward 7.21  | Actor loss: -0.00 | Critic loss: 0.07 | Entropy loss: -0.0035  | Total Loss: 0.07 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 62/100  | Episode Reward: -10  | Average Reward 7.07  | Actor loss: -0.00 | Critic loss: 57.04 | Entropy loss: -0.0019  | Total Loss: 57.03 | Total Steps: 500\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: 10  | Average Reward 7.08  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0084  | Total Loss: 0.04 | Total Steps: 11\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 64/100  | Episode Reward: -10  | Average Reward 6.88  | Actor loss: -0.01 | Critic loss: 59.10 | Entropy loss: -0.0001  | Total Loss: 59.10 | Total Steps: 500\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 65/100  | Episode Reward: 10  | Average Reward 6.88  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0002  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 5  | Average Reward 6.83  | Actor loss: 0.00 | Critic loss: 0.81 | Entropy loss: -0.0018  | Total Loss: 0.81 | Total Steps: 47\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 10  | Average Reward 6.85  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0004  | Total Loss: 0.09 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 68/100  | Episode Reward: 8  | Average Reward 6.83  | Actor loss: 0.00 | Critic loss: 0.28 | Entropy loss: -0.0004  | Total Loss: 0.28 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 8  | Average Reward 6.80  | Actor loss: 0.02 | Critic loss: 0.66 | Entropy loss: -0.0049  | Total Loss: 0.67 | Total Steps: 35\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 70/100  | Episode Reward: 10  | Average Reward 7.00  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0003  | Total Loss: 0.07 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 10  | Average Reward 7.00  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0002  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 8  | Average Reward 6.97  | Actor loss: 0.00 | Critic loss: 0.29 | Entropy loss: -0.0081  | Total Loss: 0.28 | Total Steps: 30\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 10  | Average Reward 6.97  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0160  | Total Loss: -0.00 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: 10  | Average Reward 7.05  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0007  | Total Loss: 0.06 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 10  | Average Reward 7.05  | Actor loss: 0.00 | Critic loss: 2.17 | Entropy loss: -0.0003  | Total Loss: 2.18 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 10  | Average Reward 7.06  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0003  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 77/100  | Episode Reward: 10  | Average Reward 7.06  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0086  | Total Loss: -0.00 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 10  | Average Reward 7.06  | Actor loss: 0.00 | Critic loss: 0.40 | Entropy loss: -0.0016  | Total Loss: 0.40 | Total Steps: 6\n",
      "TEST: ---green cube---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 8  | Average Reward 7.04  | Actor loss: 0.00 | Critic loss: 0.68 | Entropy loss: -0.0039  | Total Loss: 0.68 | Total Steps: 277\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 10  | Average Reward 7.04  | Actor loss: -0.00 | Critic loss: 0.17 | Entropy loss: -0.0153  | Total Loss: 0.16 | Total Steps: 50\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 10  | Average Reward 7.04  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0006  | Total Loss: 0.18 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: 10  | Average Reward 7.59  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0513  | Total Loss: -0.02 | Total Steps: 9\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 8  | Average Reward 7.59  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0103  | Total Loss: -0.01 | Total Steps: 57\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 84/100  | Episode Reward: 5  | Average Reward 7.75  | Actor loss: 0.00 | Critic loss: 0.27 | Entropy loss: -0.0015  | Total Loss: 0.28 | Total Steps: 47\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 85/100  | Episode Reward: 10  | Average Reward 7.77  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0286  | Total Loss: 0.10 | Total Steps: 7\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: 10  | Average Reward 7.82  | Actor loss: -0.00 | Critic loss: 0.04 | Entropy loss: -0.0052  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 10  | Average Reward 7.82  | Actor loss: 0.00 | Critic loss: 0.38 | Entropy loss: -0.0004  | Total Loss: 0.38 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 8  | Average Reward 7.79  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0024  | Total Loss: 0.05 | Total Steps: 34\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 89/100  | Episode Reward: 10  | Average Reward 7.79  | Actor loss: 1.80 | Critic loss: 1.27 | Entropy loss: -0.0849  | Total Loss: 2.98 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 90/100  | Episode Reward: 10  | Average Reward 7.79  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0143  | Total Loss: 0.02 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 8  | Average Reward 7.77  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0046  | Total Loss: -0.00 | Total Steps: 51\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 10  | Average Reward 7.84  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0011  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: 10  | Average Reward 7.87  | Actor loss: -0.00 | Critic loss: 0.10 | Entropy loss: -0.0122  | Total Loss: 0.09 | Total Steps: 54\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 10  | Average Reward 7.87  | Actor loss: 0.00 | Critic loss: 0.81 | Entropy loss: -0.0244  | Total Loss: 0.79 | Total Steps: 55\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: 10  | Average Reward 8.14  | Actor loss: -0.00 | Critic loss: 0.07 | Entropy loss: -0.0044  | Total Loss: 0.07 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 10  | Average Reward 8.16  | Actor loss: 0.00 | Critic loss: 0.27 | Entropy loss: -0.0304  | Total Loss: 0.24 | Total Steps: 13\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 10  | Average Reward 8.16  | Actor loss: 0.00 | Critic loss: 2.22 | Entropy loss: -0.0321  | Total Loss: 2.19 | Total Steps: 51\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: 10  | Average Reward 8.16  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0055  | Total Loss: 0.08 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 8  | Average Reward 8.16  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0095  | Total Loss: -0.01 | Total Steps: 30\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 5  | Average Reward 8.14  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0010  | Total Loss: 0.07 | Total Steps: 47\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 702/94000  | Episode Reward: 8  | Average Reward 9.12  | Actor loss: -0.05 | Critic loss: 4.46 | Entropy loss: -0.0008  | Total Loss: 4.41 | Total Steps: 50\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 703/94000  | Episode Reward: 8  | Average Reward 9.10  | Actor loss: 0.07 | Critic loss: 0.79 | Entropy loss: -0.0053  | Total Loss: 0.86 | Total Steps: 125\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 704/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: -0.07 | Critic loss: 3.11 | Entropy loss: -0.0003  | Total Loss: 3.04 | Total Steps: 51\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 705/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 706/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.03 | Critic loss: 0.57 | Entropy loss: -0.0001  | Total Loss: 0.60 | Total Steps: 8\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 707/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: -0.06 | Critic loss: 3.57 | Entropy loss: -0.0016  | Total Loss: 3.51 | Total Steps: 34\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 708/94000  | Episode Reward: 5  | Average Reward 9.07  | Actor loss: -0.01 | Critic loss: 0.75 | Entropy loss: -0.0031  | Total Loss: 0.74 | Total Steps: 77\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 709/94000  | Episode Reward: 10  | Average Reward 9.07  | Actor loss: 0.52 | Critic loss: 2.10 | Entropy loss: -0.0009  | Total Loss: 2.61 | Total Steps: 11\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 710/94000  | Episode Reward: 10  | Average Reward 9.07  | Actor loss: 0.17 | Critic loss: 0.46 | Entropy loss: -0.0005  | Total Loss: 0.63 | Total Steps: 8\n",
      "\n",
      "---blue sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 711/94000  | Episode Reward: 5  | Average Reward 9.05  | Actor loss: -0.05 | Critic loss: 7.09 | Entropy loss: -0.0005  | Total Loss: 7.04 | Total Steps: 42\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 712/94000  | Episode Reward: 10  | Average Reward 9.07  | Actor loss: 1.13 | Critic loss: 6.23 | Entropy loss: -0.0037  | Total Loss: 7.36 | Total Steps: 30\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 713/94000  | Episode Reward: 10  | Average Reward 9.07  | Actor loss: -0.15 | Critic loss: 2.44 | Entropy loss: -0.0022  | Total Loss: 2.29 | Total Steps: 49\n",
      "\n",
      "---green cylinder---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 714/94000  | Episode Reward: -10  | Average Reward 8.88  | Actor loss: -0.00 | Critic loss: 3.89 | Entropy loss: -0.0001  | Total Loss: 3.89 | Total Steps: 500\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 715/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.09 | Critic loss: 1.24 | Entropy loss: -0.0003  | Total Loss: 1.33 | Total Steps: 11\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 716/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.12 | Critic loss: 0.05 | Entropy loss: -0.0014  | Total Loss: 0.17 | Total Steps: 7\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 717/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.00 | Critic loss: 3.62 | Entropy loss: -0.0000  | Total Loss: 3.62 | Total Steps: 31\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 718/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: -0.55 | Critic loss: 0.84 | Entropy loss: -0.0021  | Total Loss: 0.29 | Total Steps: 11\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 719/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 720/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 721/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: -0.06 | Critic loss: 0.10 | Entropy loss: -0.0005  | Total Loss: 0.04 | Total Steps: 10\n",
      "\n",
      "---red cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 722/94000  | Episode Reward: 8  | Average Reward 8.93  | Actor loss: 0.08 | Critic loss: 7.58 | Entropy loss: -0.0038  | Total Loss: 7.66 | Total Steps: 50\n",
      "\n",
      "---black cube---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 723/94000  | Episode Reward: -10  | Average Reward 8.72  | Actor loss: -0.00 | Critic loss: 2.57 | Entropy loss: -0.0001  | Total Loss: 2.57 | Total Steps: 500\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 724/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.05 | Critic loss: 5.09 | Entropy loss: -0.0004  | Total Loss: 5.13 | Total Steps: 29\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 725/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 726/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 727/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.01 | Critic loss: 0.98 | Entropy loss: -0.0000  | Total Loss: 0.98 | Total Steps: 6\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 728/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.00 | Critic loss: 2.29 | Entropy loss: -0.0000  | Total Loss: 2.29 | Total Steps: 31\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 729/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.01 | Critic loss: 0.43 | Entropy loss: -0.0013  | Total Loss: 0.44 | Total Steps: 41\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 730/94000  | Episode Reward: 5  | Average Reward 8.72  | Actor loss: -0.01 | Critic loss: 5.16 | Entropy loss: -0.0002  | Total Loss: 5.15 | Total Steps: 49\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 731/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.06 | Critic loss: 0.75 | Entropy loss: -0.0002  | Total Loss: 0.81 | Total Steps: 11\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 732/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.10 | Critic loss: 0.47 | Entropy loss: -0.0004  | Total Loss: 0.57 | Total Steps: 10\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 733/94000  | Episode Reward: 5  | Average Reward 8.70  | Actor loss: -0.01 | Critic loss: 2.73 | Entropy loss: -0.0001  | Total Loss: 2.72 | Total Steps: 49\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 734/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: -0.84 | Critic loss: 3.83 | Entropy loss: -0.0050  | Total Loss: 2.99 | Total Steps: 43\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 735/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 736/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 737/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.01 | Critic loss: 4.48 | Entropy loss: -0.0015  | Total Loss: 4.49 | Total Steps: 44\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 738/94000  | Episode Reward: 8  | Average Reward 8.72  | Actor loss: -0.08 | Critic loss: 2.50 | Entropy loss: -0.0012  | Total Loss: 2.42 | Total Steps: 35\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 739/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: 0.00 | Critic loss: 3.21 | Entropy loss: -0.0000  | Total Loss: 3.21 | Total Steps: 31\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 740/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: 0.01 | Critic loss: 0.19 | Entropy loss: -0.0000  | Total Loss: 0.20 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 741/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 742/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: -0.08 | Critic loss: 4.59 | Entropy loss: -0.0007  | Total Loss: 4.51 | Total Steps: 53\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 743/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: -0.06 | Critic loss: 3.46 | Entropy loss: -0.0014  | Total Loss: 3.40 | Total Steps: 46\n",
      "\n",
      "---black cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 744/94000  | Episode Reward: 8  | Average Reward 8.72  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0001  | Total Loss: 0.20 | Total Steps: 38\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 745/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: -0.07 | Critic loss: 0.14 | Entropy loss: -0.0007  | Total Loss: 0.08 | Total Steps: 11\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 746/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: -0.01 | Critic loss: 0.02 | Entropy loss: -0.0006  | Total Loss: 0.01 | Total Steps: 9\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 747/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.15 | Critic loss: 0.35 | Entropy loss: -0.0017  | Total Loss: 0.50 | Total Steps: 7\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 748/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 749/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.01 | Critic loss: 1.02 | Entropy loss: -0.0008  | Total Loss: 1.03 | Total Steps: 64\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 750/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.12 | Critic loss: 1.58 | Entropy loss: -0.0018  | Total Loss: 1.70 | Total Steps: 186\n",
      "\n",
      "---black cube---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 751/94000  | Episode Reward: -10  | Average Reward 8.57  | Actor loss: -0.00 | Critic loss: 3.31 | Entropy loss: -0.0000  | Total Loss: 3.31 | Total Steps: 500\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 752/94000  | Episode Reward: 10  | Average Reward 8.57  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0000  | Total Loss: 0.15 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 753/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 754/94000  | Episode Reward: 8  | Average Reward 8.62  | Actor loss: -0.05 | Critic loss: 2.50 | Entropy loss: -0.0005  | Total Loss: 2.45 | Total Steps: 29\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 755/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: -0.02 | Critic loss: 4.62 | Entropy loss: -0.0004  | Total Loss: 4.60 | Total Steps: 29\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 756/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0000  | Total Loss: 0.08 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 757/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: -0.64 | Critic loss: 4.24 | Entropy loss: -0.0042  | Total Loss: 3.60 | Total Steps: 62\n",
      "\n",
      "---black capsule---\n",
      "Step: 250\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 758/94000  | Episode Reward: 8  | Average Reward 8.60  | Actor loss: -0.04 | Critic loss: 0.60 | Entropy loss: -0.0037  | Total Loss: 0.55 | Total Steps: 426\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 759/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.32 | Critic loss: 0.62 | Entropy loss: -0.0007  | Total Loss: 0.94 | Total Steps: 8\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 760/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 2.78 | Entropy loss: -0.0000  | Total Loss: 2.78 | Total Steps: 31\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 761/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 762/94000  | Episode Reward: 8  | Average Reward 8.68  | Actor loss: -0.00 | Critic loss: 5.92 | Entropy loss: -0.0001  | Total Loss: 5.92 | Total Steps: 30\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 763/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: -0.00 | Critic loss: 3.67 | Entropy loss: -0.0001  | Total Loss: 3.66 | Total Steps: 29\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 764/94000  | Episode Reward: 8  | Average Reward 8.68  | Actor loss: -0.08 | Critic loss: 5.98 | Entropy loss: -0.0002  | Total Loss: 5.90 | Total Steps: 42\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 765/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 766/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.00 | Critic loss: 1.86 | Entropy loss: -0.0000  | Total Loss: 1.86 | Total Steps: 31\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 767/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.02 | Critic loss: 0.29 | Entropy loss: -0.0001  | Total Loss: 0.31 | Total Steps: 8\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 768/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.01 | Critic loss: 2.00 | Entropy loss: -0.0002  | Total Loss: 2.01 | Total Steps: 31\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 769/94000  | Episode Reward: 8  | Average Reward 8.65  | Actor loss: 0.01 | Critic loss: 0.43 | Entropy loss: -0.0001  | Total Loss: 0.44 | Total Steps: 38\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 770/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: -0.01 | Critic loss: 1.56 | Entropy loss: -0.0010  | Total Loss: 1.55 | Total Steps: 68\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 771/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 772/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 773/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: -0.30 | Critic loss: 1.68 | Entropy loss: -0.0025  | Total Loss: 1.38 | Total Steps: 35\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 774/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.03 | Critic loss: 1.29 | Entropy loss: -0.0009  | Total Loss: 1.32 | Total Steps: 31\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 775/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 776/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.22 | Critic loss: 0.35 | Entropy loss: -0.0013  | Total Loss: 0.58 | Total Steps: 9\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 777/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 778/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 779/94000  | Episode Reward: 5  | Average Reward 8.62  | Actor loss: -0.19 | Critic loss: 9.66 | Entropy loss: -0.0014  | Total Loss: 9.46 | Total Steps: 51\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 780/94000  | Episode Reward: 8  | Average Reward 8.60  | Actor loss: -0.29 | Critic loss: 6.02 | Entropy loss: -0.0020  | Total Loss: 5.72 | Total Steps: 46\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 781/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: -0.19 | Critic loss: 2.26 | Entropy loss: -0.0023  | Total Loss: 2.07 | Total Steps: 51\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 782/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.01 | Critic loss: 2.57 | Entropy loss: -0.0000  | Total Loss: 2.58 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 783/94000  | Episode Reward: 5  | Average Reward 8.60  | Actor loss: -0.06 | Critic loss: 2.96 | Entropy loss: -0.0019  | Total Loss: 2.90 | Total Steps: 229\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 784/94000  | Episode Reward: 8  | Average Reward 8.60  | Actor loss: -0.04 | Critic loss: 2.53 | Entropy loss: -0.0006  | Total Loss: 2.49 | Total Steps: 66\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 785/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.02 | Critic loss: 0.90 | Entropy loss: -0.0000  | Total Loss: 0.92 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 786/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.50 | Critic loss: 0.81 | Entropy loss: -0.0009  | Total Loss: 1.31 | Total Steps: 8\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 787/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: -0.78 | Critic loss: 4.47 | Entropy loss: -0.0080  | Total Loss: 3.69 | Total Steps: 54\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 788/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0000  | Total Loss: 0.11 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 789/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.01 | Critic loss: 0.58 | Entropy loss: -0.0000  | Total Loss: 0.58 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 790/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.07 | Critic loss: 0.60 | Entropy loss: -0.0001  | Total Loss: 0.66 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 791/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0000  | Total Loss: 0.21 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 792/94000  | Episode Reward: 5  | Average Reward 8.55  | Actor loss: -0.58 | Critic loss: 9.93 | Entropy loss: -0.0033  | Total Loss: 9.34 | Total Steps: 74\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 793/94000  | Episode Reward: 10  | Average Reward 8.55  | Actor loss: 0.00 | Critic loss: 1.47 | Entropy loss: -0.0000  | Total Loss: 1.48 | Total Steps: 31\n",
      "\n",
      "---red cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 794/94000  | Episode Reward: 8  | Average Reward 8.53  | Actor loss: -0.15 | Critic loss: 5.39 | Entropy loss: -0.0029  | Total Loss: 5.23 | Total Steps: 50\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 795/94000  | Episode Reward: 10  | Average Reward 8.53  | Actor loss: 0.00 | Critic loss: 2.01 | Entropy loss: -0.0000  | Total Loss: 2.01 | Total Steps: 31\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 796/94000  | Episode Reward: 8  | Average Reward 8.50  | Actor loss: -0.34 | Critic loss: 6.63 | Entropy loss: -0.0016  | Total Loss: 6.28 | Total Steps: 50\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 797/94000  | Episode Reward: 10  | Average Reward 8.50  | Actor loss: 0.00 | Critic loss: 0.22 | Entropy loss: -0.0000  | Total Loss: 0.22 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 798/94000  | Episode Reward: 10  | Average Reward 8.50  | Actor loss: -0.20 | Critic loss: 3.70 | Entropy loss: -0.0019  | Total Loss: 3.50 | Total Steps: 62\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 799/94000  | Episode Reward: 10  | Average Reward 8.50  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 800/94000  | Episode Reward: 10  | Average Reward 8.50  | Actor loss: 0.49 | Critic loss: 1.27 | Entropy loss: -0.0010  | Total Loss: 1.75 | Total Steps: 7\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 801/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 1.67 | Entropy loss: -0.0000  | Total Loss: 1.67 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 10  | Average Reward 8.14  | Actor loss: 0.37 | Critic loss: 28.83 | Entropy loss: -0.0278  | Total Loss: 29.18 | Total Steps: 23\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 8  | Average Reward 8.12  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0165  | Total Loss: -0.02 | Total Steps: 61\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 3/100  | Episode Reward: 5  | Average Reward 8.06  | Actor loss: 0.00 | Critic loss: 0.47 | Entropy loss: -0.0010  | Total Loss: 0.47 | Total Steps: 42\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 10  | Average Reward 8.06  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0009  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 10  | Average Reward 8.06  | Actor loss: 2.09 | Critic loss: 8.36 | Entropy loss: -0.0287  | Total Loss: 10.42 | Total Steps: 7\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 10  | Average Reward 8.27  | Actor loss: 0.13 | Critic loss: 8.42 | Entropy loss: -0.0218  | Total Loss: 8.53 | Total Steps: 46\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: 2  | Average Reward 8.19  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0010  | Total Loss: 0.09 | Total Steps: 50\n",
      "TEST: ---red capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 10  | Average Reward 8.19  | Actor loss: 0.00 | Critic loss: 0.33 | Entropy loss: -0.0084  | Total Loss: 0.32 | Total Steps: 56\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 10  | Average Reward 8.29  | Actor loss: 0.28 | Critic loss: 8.02 | Entropy loss: -0.0229  | Total Loss: 8.27 | Total Steps: 36\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 5  | Average Reward 8.24  | Actor loss: 0.05 | Critic loss: 2.34 | Entropy loss: -0.0118  | Total Loss: 2.37 | Total Steps: 47\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 8  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.30 | Entropy loss: -0.0007  | Total Loss: 0.30 | Total Steps: 38\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0003  | Total Loss: 0.02 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0001  | Total Loss: 0.04 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0010  | Total Loss: 0.11 | Total Steps: 36\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 1.76 | Critic loss: 13.49 | Entropy loss: -0.0585  | Total Loss: 15.19 | Total Steps: 59\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0307  | Total Loss: -0.02 | Total Steps: 10\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0055  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 9  | Average Reward 8.21  | Actor loss: 0.17 | Critic loss: 6.91 | Entropy loss: -0.0399  | Total Loss: 7.05 | Total Steps: 48\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 10  | Average Reward 8.23  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0068  | Total Loss: 0.02 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: 10  | Average Reward 8.23  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0019  | Total Loss: 0.16 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 21/100  | Episode Reward: -10  | Average Reward 8.03  | Actor loss: -0.00 | Critic loss: 87.29 | Entropy loss: -0.0016  | Total Loss: 87.28 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 22/100  | Episode Reward: 10  | Average Reward 8.03  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0231  | Total Loss: 0.16 | Total Steps: 7\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 10  | Average Reward 8.03  | Actor loss: 0.00 | Critic loss: 0.22 | Entropy loss: -0.0105  | Total Loss: 0.21 | Total Steps: 12\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 24/100  | Episode Reward: -10  | Average Reward 7.86  | Actor loss: -0.01 | Critic loss: 78.94 | Entropy loss: -0.0042  | Total Loss: 78.93 | Total Steps: 500\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 8  | Average Reward 7.83  | Actor loss: 0.00 | Critic loss: 0.51 | Entropy loss: -0.0004  | Total Loss: 0.51 | Total Steps: 29\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 8  | Average Reward 7.80  | Actor loss: 0.00 | Critic loss: 0.41 | Entropy loss: -0.0030  | Total Loss: 0.41 | Total Steps: 46\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 5  | Average Reward 7.75  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0012  | Total Loss: 0.08 | Total Steps: 49\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 8  | Average Reward 7.98  | Actor loss: -0.00 | Critic loss: 0.11 | Entropy loss: -0.0194  | Total Loss: 0.09 | Total Steps: 45\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0034  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 10  | Average Reward 8.23  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0007  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 10  | Average Reward 8.30  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0168  | Total Loss: 0.01 | Total Steps: 12\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 32/100  | Episode Reward: 10  | Average Reward 8.30  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0034  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 33/100  | Episode Reward: 10  | Average Reward 8.30  | Actor loss: -0.00 | Critic loss: 0.06 | Entropy loss: -0.0010  | Total Loss: 0.06 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 34/100  | Episode Reward: 8  | Average Reward 8.33  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0068  | Total Loss: 0.09 | Total Steps: 35\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 35/100  | Episode Reward: 10  | Average Reward 8.36  | Actor loss: 0.04 | Critic loss: 4.42 | Entropy loss: -0.0288  | Total Loss: 4.43 | Total Steps: 8\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 36/100  | Episode Reward: 9  | Average Reward 8.35  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0593  | Total Loss: -0.01 | Total Steps: 35\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 37/100  | Episode Reward: 8  | Average Reward 8.32  | Actor loss: 0.01 | Critic loss: 0.16 | Entropy loss: -0.0127  | Total Loss: 0.16 | Total Steps: 51\n",
      "TEST: ---black sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0005  | Total Loss: 0.04 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: -0.00 | Critic loss: 0.08 | Entropy loss: -0.0005  | Total Loss: 0.08 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 5  | Average Reward 8.27  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0167  | Total Loss: 0.18 | Total Steps: 53\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 8  | Average Reward 8.24  | Actor loss: 0.79 | Critic loss: 1.54 | Entropy loss: -0.0347  | Total Loss: 2.30 | Total Steps: 63\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 5  | Average Reward 8.22  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0017  | Total Loss: 0.10 | Total Steps: 49\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 43/100  | Episode Reward: 10  | Average Reward 8.22  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0002  | Total Loss: 0.05 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 10  | Average Reward 8.22  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0077  | Total Loss: 0.16 | Total Steps: 40\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: 8  | Average Reward 8.20  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0038  | Total Loss: 0.04 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 7  | Average Reward 8.19  | Actor loss: 0.01 | Critic loss: 0.47 | Entropy loss: -0.0453  | Total Loss: 0.42 | Total Steps: 140\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 8  | Average Reward 8.16  | Actor loss: 0.01 | Critic loss: 0.73 | Entropy loss: -0.0279  | Total Loss: 0.71 | Total Steps: 53\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 10  | Average Reward 8.16  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0436  | Total Loss: -0.01 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0476  | Total Loss: -0.03 | Total Steps: 12\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: -0.00 | Critic loss: 0.06 | Entropy loss: -0.0083  | Total Loss: 0.05 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 8  | Average Reward 8.15  | Actor loss: 0.00 | Critic loss: 0.47 | Entropy loss: -0.0006  | Total Loss: 0.47 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.57 | Critic loss: 3.49 | Entropy loss: -0.0385  | Total Loss: 4.02 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 53/100  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0066  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 54/100  | Episode Reward: 8  | Average Reward 8.15  | Actor loss: 0.00 | Critic loss: 0.33 | Entropy loss: -0.0004  | Total Loss: 0.33 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 10  | Average Reward 8.15  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0011  | Total Loss: 0.14 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 1.05 | Entropy loss: -0.0006  | Total Loss: 1.05 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0002  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 8  | Average Reward 8.15  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0004  | Total Loss: 0.05 | Total Steps: 34\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 10  | Average Reward 8.15  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0089  | Total Loss: 0.12 | Total Steps: 11\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 60/100  | Episode Reward: -10  | Average Reward 7.95  | Actor loss: -0.00 | Critic loss: 82.43 | Entropy loss: -0.0001  | Total Loss: 82.42 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 61/100  | Episode Reward: 10  | Average Reward 7.95  | Actor loss: 0.64 | Critic loss: 6.92 | Entropy loss: -0.0477  | Total Loss: 7.52 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 10  | Average Reward 8.15  | Actor loss: -0.00 | Critic loss: 0.07 | Entropy loss: -0.0084  | Total Loss: 0.07 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: 10  | Average Reward 8.15  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0083  | Total Loss: 0.13 | Total Steps: 11\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 64/100  | Episode Reward: 10  | Average Reward 8.35  | Actor loss: -0.00 | Critic loss: 0.14 | Entropy loss: -0.0183  | Total Loss: 0.12 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 65/100  | Episode Reward: 10  | Average Reward 8.35  | Actor loss: 0.02 | Critic loss: 1.19 | Entropy loss: -0.0409  | Total Loss: 1.17 | Total Steps: 7\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 10  | Average Reward 8.40  | Actor loss: 0.02 | Critic loss: 1.04 | Entropy loss: -0.0484  | Total Loss: 1.01 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 5  | Average Reward 8.35  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0015  | Total Loss: 0.10 | Total Steps: 46\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing  | Episode: 68/100  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0334  | Total Loss: -0.03 | Total Steps: 10\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 10  | Average Reward 8.40  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0276  | Total Loss: -0.03 | Total Steps: 11\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 70/100  | Episode Reward: 10  | Average Reward 8.40  | Actor loss: -0.00 | Critic loss: 0.07 | Entropy loss: -0.0156  | Total Loss: 0.05 | Total Steps: 53\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 10  | Average Reward 8.40  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0164  | Total Loss: -0.01 | Total Steps: 12\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 10  | Average Reward 8.43  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0171  | Total Loss: 0.02 | Total Steps: 56\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 10  | Average Reward 8.43  | Actor loss: 0.01 | Critic loss: 4.17 | Entropy loss: -0.0092  | Total Loss: 4.17 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: 10  | Average Reward 8.43  | Actor loss: -0.00 | Critic loss: 0.09 | Entropy loss: -0.0020  | Total Loss: 0.09 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 10  | Average Reward 8.43  | Actor loss: -0.00 | Critic loss: 0.06 | Entropy loss: -0.0207  | Total Loss: 0.04 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 8  | Average Reward 8.40  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0054  | Total Loss: 0.15 | Total Steps: 30\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 77/100  | Episode Reward: 8  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0007  | Total Loss: 0.01 | Total Steps: 36\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0005  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 8  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 0.32 | Entropy loss: -0.0003  | Total Loss: 0.32 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 8  | Average Reward 8.35  | Actor loss: 0.00 | Critic loss: 8.21 | Entropy loss: -0.0180  | Total Loss: 8.19 | Total Steps: 35\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 10  | Average Reward 8.35  | Actor loss: 0.00 | Critic loss: 1.05 | Entropy loss: -0.0011  | Total Loss: 1.05 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: 10  | Average Reward 8.35  | Actor loss: -0.00 | Critic loss: 0.05 | Entropy loss: -0.0101  | Total Loss: 0.04 | Total Steps: 8\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0005  | Total Loss: 0.19 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 84/100  | Episode Reward: 10  | Average Reward 8.43  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0005  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 85/100  | Episode Reward: 10  | Average Reward 8.43  | Actor loss: 0.01 | Critic loss: 0.15 | Entropy loss: -0.0715  | Total Loss: 0.09 | Total Steps: 8\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: 5  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0038  | Total Loss: 0.04 | Total Steps: 42\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0002  | Total Loss: 0.11 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 8  | Average Reward 8.38  | Actor loss: 0.01 | Critic loss: 0.09 | Entropy loss: -0.0057  | Total Loss: 0.09 | Total Steps: 49\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 89/100  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: 0.04 | Critic loss: 1.88 | Entropy loss: -0.0028  | Total Loss: 1.92 | Total Steps: 39\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 90/100  | Episode Reward: 2  | Average Reward 8.30  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0022  | Total Loss: 0.10 | Total Steps: 53\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: 0.01 | Critic loss: 3.88 | Entropy loss: -0.0063  | Total Loss: 3.88 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0990  | Total Loss: 0.02 | Total Steps: 7\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0285  | Total Loss: -0.01 | Total Steps: 12\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 5  | Average Reward 8.28  | Actor loss: 0.00 | Critic loss: 0.27 | Entropy loss: -0.0022  | Total Loss: 0.27 | Total Steps: 47\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: 2  | Average Reward 8.20  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0041  | Total Loss: 0.08 | Total Steps: 63\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 5  | Average Reward 8.15  | Actor loss: 0.27 | Critic loss: 1.60 | Entropy loss: -0.0066  | Total Loss: 1.87 | Total Steps: 182\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 10  | Average Reward 8.15  | Actor loss: 0.01 | Critic loss: 0.47 | Entropy loss: -0.0320  | Total Loss: 0.44 | Total Steps: 11\n",
      "TEST: ---blue cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: 10  | Average Reward 8.15  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0011  | Total Loss: 0.05 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 5  | Average Reward 8.12  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0048  | Total Loss: 0.00 | Total Steps: 46\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0010  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 802/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: -0.41 | Critic loss: 3.38 | Entropy loss: -0.0037  | Total Loss: 2.97 | Total Steps: 61\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 803/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.09 | Critic loss: 0.45 | Entropy loss: -0.0002  | Total Loss: 0.54 | Total Steps: 8\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 804/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.01 | Critic loss: 0.46 | Entropy loss: -0.0000  | Total Loss: 0.47 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 805/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: -0.05 | Critic loss: 2.11 | Entropy loss: -0.0008  | Total Loss: 2.06 | Total Steps: 49\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 806/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 807/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.15 | Critic loss: 0.79 | Entropy loss: -0.0032  | Total Loss: 0.93 | Total Steps: 14\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 808/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: -0.34 | Critic loss: 1.66 | Entropy loss: -0.0021  | Total Loss: 1.31 | Total Steps: 36\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 809/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: 0.15 | Critic loss: 0.31 | Entropy loss: -0.0008  | Total Loss: 0.46 | Total Steps: 11\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 810/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 811/94000  | Episode Reward: 10  | Average Reward 8.85  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 812/94000  | Episode Reward: 10  | Average Reward 8.85  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 813/94000  | Episode Reward: 10  | Average Reward 8.85  | Actor loss: -0.08 | Critic loss: 5.84 | Entropy loss: -0.0005  | Total Loss: 5.76 | Total Steps: 47\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 814/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.13 | Critic loss: 0.23 | Entropy loss: -0.0019  | Total Loss: 0.36 | Total Steps: 8\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 815/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: -0.00 | Critic loss: 3.47 | Entropy loss: -0.0001  | Total Loss: 3.47 | Total Steps: 34\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 816/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 817/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.04 | Critic loss: 0.22 | Entropy loss: -0.0007  | Total Loss: 0.26 | Total Steps: 11\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 818/94000  | Episode Reward: 8  | Average Reward 9.03  | Actor loss: 0.02 | Critic loss: 0.39 | Entropy loss: -0.0003  | Total Loss: 0.40 | Total Steps: 38\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 819/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.08 | Critic loss: 0.42 | Entropy loss: -0.0002  | Total Loss: 0.50 | Total Steps: 8\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 820/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.01 | Critic loss: 1.45 | Entropy loss: -0.0001  | Total Loss: 1.46 | Total Steps: 31\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 821/94000  | Episode Reward: 8  | Average Reward 9.00  | Actor loss: -0.06 | Critic loss: 5.84 | Entropy loss: -0.0005  | Total Loss: 5.78 | Total Steps: 44\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 822/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: -1.42 | Critic loss: 6.60 | Entropy loss: -0.0085  | Total Loss: 5.18 | Total Steps: 59\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 823/94000  | Episode Reward: 10  | Average Reward 9.22  | Actor loss: -0.18 | Critic loss: 3.93 | Entropy loss: -0.0013  | Total Loss: 3.75 | Total Steps: 60\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 824/94000  | Episode Reward: 10  | Average Reward 9.22  | Actor loss: -0.28 | Critic loss: 2.94 | Entropy loss: -0.0022  | Total Loss: 2.65 | Total Steps: 29\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 825/94000  | Episode Reward: 10  | Average Reward 9.22  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 826/94000  | Episode Reward: 10  | Average Reward 9.22  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 827/94000  | Episode Reward: 10  | Average Reward 9.22  | Actor loss: -0.02 | Critic loss: 1.00 | Entropy loss: -0.0013  | Total Loss: 0.97 | Total Steps: 35\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 828/94000  | Episode Reward: 10  | Average Reward 9.22  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 829/94000  | Episode Reward: 10  | Average Reward 9.22  | Actor loss: 0.11 | Critic loss: 0.69 | Entropy loss: -0.0013  | Total Loss: 0.80 | Total Steps: 13\n",
      "\n",
      "---black capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 830/94000  | Episode Reward: 5  | Average Reward 9.22  | Actor loss: -0.03 | Critic loss: 3.46 | Entropy loss: -0.0014  | Total Loss: 3.43 | Total Steps: 76\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 831/94000  | Episode Reward: 10  | Average Reward 9.22  | Actor loss: 0.00 | Critic loss: 1.55 | Entropy loss: -0.0001  | Total Loss: 1.55 | Total Steps: 31\n",
      "\n",
      "---yellow capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 832/94000  | Episode Reward: 10  | Average Reward 9.22  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 833/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 834/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.00 | Critic loss: 1.40 | Entropy loss: -0.0000  | Total Loss: 1.40 | Total Steps: 31\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 835/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0000  | Total Loss: 0.11 | Total Steps: 6\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 836/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.03 | Critic loss: 0.06 | Entropy loss: -0.0004  | Total Loss: 0.08 | Total Steps: 8\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 837/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.20 | Critic loss: 1.28 | Entropy loss: -0.0010  | Total Loss: 1.48 | Total Steps: 11\n",
      "\n",
      "---red cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 838/94000  | Episode Reward: 8  | Average Reward 9.28  | Actor loss: -0.00 | Critic loss: 2.93 | Entropy loss: -0.0023  | Total Loss: 2.93 | Total Steps: 53\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 839/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 840/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: -0.21 | Critic loss: 0.18 | Entropy loss: -0.0016  | Total Loss: -0.04 | Total Steps: 10\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 841/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.00 | Critic loss: 0.99 | Entropy loss: -0.0000  | Total Loss: 0.99 | Total Steps: 31\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 842/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: -0.03 | Critic loss: 0.11 | Entropy loss: -0.0006  | Total Loss: 0.09 | Total Steps: 9\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 843/94000  | Episode Reward: 8  | Average Reward 9.25  | Actor loss: -0.71 | Critic loss: 3.94 | Entropy loss: -0.0039  | Total Loss: 3.23 | Total Steps: 47\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 844/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 845/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: -0.01 | Critic loss: 0.01 | Entropy loss: -0.0008  | Total Loss: 0.00 | Total Steps: 9\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 846/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: -0.00 | Critic loss: 1.57 | Entropy loss: -0.0002  | Total Loss: 1.57 | Total Steps: 34\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 847/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: -0.01 | Critic loss: 0.66 | Entropy loss: -0.0003  | Total Loss: 0.65 | Total Steps: 50\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 848/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.01 | Critic loss: 4.52 | Entropy loss: -0.0001  | Total Loss: 4.53 | Total Steps: 29\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 849/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.00 | Critic loss: 1.54 | Entropy loss: -0.0014  | Total Loss: 1.54 | Total Steps: 56\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 850/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0000  | Total Loss: 0.12 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 9.425. Model has been saved-----\n",
      "Training  | Episode: 851/94000  | Episode Reward: 5  | Average Reward 9.43  | Actor loss: -0.04 | Critic loss: 2.58 | Entropy loss: -0.0018  | Total Loss: 2.53 | Total Steps: 136\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 852/94000  | Episode Reward: 10  | Average Reward 9.43  | Actor loss: 0.03 | Critic loss: 0.26 | Entropy loss: -0.0001  | Total Loss: 0.30 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 853/94000  | Episode Reward: 10  | Average Reward 9.43  | Actor loss: -0.77 | Critic loss: 5.67 | Entropy loss: -0.0064  | Total Loss: 4.89 | Total Steps: 61\n",
      "\n",
      "---red cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 854/94000  | Episode Reward: 8  | Average Reward 9.43  | Actor loss: -0.70 | Critic loss: 3.51 | Entropy loss: -0.0020  | Total Loss: 2.81 | Total Steps: 41\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 855/94000  | Episode Reward: 10  | Average Reward 9.43  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0000  | Total Loss: 0.00 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 856/94000  | Episode Reward: 8  | Average Reward 9.40  | Actor loss: -0.31 | Critic loss: 4.94 | Entropy loss: -0.0046  | Total Loss: 4.62 | Total Steps: 54\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 857/94000  | Episode Reward: 10  | Average Reward 9.40  | Actor loss: 0.09 | Critic loss: 0.72 | Entropy loss: -0.0002  | Total Loss: 0.81 | Total Steps: 8\n",
      "\n",
      "---yellow cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 858/94000  | Episode Reward: 8  | Average Reward 9.40  | Actor loss: -0.38 | Critic loss: 7.04 | Entropy loss: -0.0058  | Total Loss: 6.66 | Total Steps: 55\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 859/94000  | Episode Reward: 10  | Average Reward 9.40  | Actor loss: 0.07 | Critic loss: 0.45 | Entropy loss: -0.0002  | Total Loss: 0.52 | Total Steps: 8\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 860/94000  | Episode Reward: 10  | Average Reward 9.40  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 861/94000  | Episode Reward: 10  | Average Reward 9.40  | Actor loss: -0.15 | Critic loss: 5.01 | Entropy loss: -0.0025  | Total Loss: 4.86 | Total Steps: 48\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 862/94000  | Episode Reward: 8  | Average Reward 9.40  | Actor loss: -0.02 | Critic loss: 5.15 | Entropy loss: -0.0002  | Total Loss: 5.13 | Total Steps: 34\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 863/94000  | Episode Reward: 10  | Average Reward 9.40  | Actor loss: 0.07 | Critic loss: 0.33 | Entropy loss: -0.0003  | Total Loss: 0.39 | Total Steps: 9\n",
      "\n",
      "---red cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 864/94000  | Episode Reward: 10  | Average Reward 9.43  | Actor loss: 0.20 | Critic loss: 2.20 | Entropy loss: -0.0015  | Total Loss: 2.40 | Total Steps: 31\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 865/94000  | Episode Reward: 10  | Average Reward 9.43  | Actor loss: 0.01 | Critic loss: 0.19 | Entropy loss: -0.0000  | Total Loss: 0.20 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 866/94000  | Episode Reward: 10  | Average Reward 9.43  | Actor loss: -0.96 | Critic loss: 4.70 | Entropy loss: -0.0073  | Total Loss: 3.74 | Total Steps: 53\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 867/94000  | Episode Reward: 10  | Average Reward 9.43  | Actor loss: -0.31 | Critic loss: 0.24 | Entropy loss: -0.0038  | Total Loss: -0.07 | Total Steps: 11\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 868/94000  | Episode Reward: 10  | Average Reward 9.43  | Actor loss: -0.20 | Critic loss: 2.80 | Entropy loss: -0.0011  | Total Loss: 2.59 | Total Steps: 36\n",
      "\n",
      "---black cube---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 869/94000  | Episode Reward: -10  | Average Reward 9.25  | Actor loss: -0.00 | Critic loss: 4.49 | Entropy loss: -0.0002  | Total Loss: 4.48 | Total Steps: 500\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 870/94000  | Episode Reward: 10  | Average Reward 9.25  | Actor loss: 0.00 | Critic loss: 0.32 | Entropy loss: -0.0000  | Total Loss: 0.33 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 871/94000  | Episode Reward: 10  | Average Reward 9.25  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0000  | Total Loss: 0.18 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 872/94000  | Episode Reward: 8  | Average Reward 9.22  | Actor loss: -0.89 | Critic loss: 9.17 | Entropy loss: -0.0083  | Total Loss: 8.27 | Total Steps: 51\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 873/94000  | Episode Reward: 10  | Average Reward 9.22  | Actor loss: 0.18 | Critic loss: 0.81 | Entropy loss: -0.0006  | Total Loss: 0.99 | Total Steps: 11\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 874/94000  | Episode Reward: 5  | Average Reward 9.18  | Actor loss: -0.07 | Critic loss: 3.25 | Entropy loss: -0.0007  | Total Loss: 3.18 | Total Steps: 47\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 875/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.18 | Critic loss: 1.81 | Entropy loss: -0.0026  | Total Loss: 1.99 | Total Steps: 33\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 876/94000  | Episode Reward: 8  | Average Reward 9.15  | Actor loss: -0.55 | Critic loss: 7.73 | Entropy loss: -0.0050  | Total Loss: 7.18 | Total Steps: 91\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 877/94000  | Episode Reward: 10  | Average Reward 9.15  | Actor loss: 0.28 | Critic loss: 1.50 | Entropy loss: -0.0014  | Total Loss: 1.78 | Total Steps: 10\n",
      "\n",
      "---yellow sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 878/94000  | Episode Reward: 8  | Average Reward 9.12  | Actor loss: -0.75 | Critic loss: 4.49 | Entropy loss: -0.0032  | Total Loss: 3.74 | Total Steps: 16\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 879/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.14 | Critic loss: 0.12 | Entropy loss: -0.0007  | Total Loss: 0.26 | Total Steps: 8\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 880/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: 0.01 | Critic loss: 0.58 | Entropy loss: -0.0000  | Total Loss: 0.59 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 881/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 882/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: 0.02 | Critic loss: 2.45 | Entropy loss: -0.0003  | Total Loss: 2.46 | Total Steps: 31\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 883/94000  | Episode Reward: 10  | Average Reward 9.25  | Actor loss: -0.22 | Critic loss: 0.47 | Entropy loss: -0.0026  | Total Loss: 0.25 | Total Steps: 11\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 884/94000  | Episode Reward: 5  | Average Reward 9.22  | Actor loss: -0.19 | Critic loss: 9.16 | Entropy loss: -0.0024  | Total Loss: 8.96 | Total Steps: 54\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 885/94000  | Episode Reward: 8  | Average Reward 9.20  | Actor loss: -0.02 | Critic loss: 4.50 | Entropy loss: -0.0004  | Total Loss: 4.47 | Total Steps: 37\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 886/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: -0.23 | Critic loss: 0.20 | Entropy loss: -0.0014  | Total Loss: -0.04 | Total Steps: 11\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 887/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0000  | Total Loss: 0.11 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 888/94000  | Episode Reward: -10  | Average Reward 9.00  | Actor loss: -0.00 | Critic loss: 4.79 | Entropy loss: -0.0002  | Total Loss: 4.79 | Total Steps: 500\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 889/94000  | Episode Reward: 8  | Average Reward 8.97  | Actor loss: 0.12 | Critic loss: 1.41 | Entropy loss: -0.0015  | Total Loss: 1.53 | Total Steps: 97\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 890/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: -0.06 | Critic loss: 1.14 | Entropy loss: -0.0012  | Total Loss: 1.07 | Total Steps: 40\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 891/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.00 | Critic loss: 0.40 | Entropy loss: -0.0000  | Total Loss: 0.40 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 892/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 893/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 894/94000  | Episode Reward: 8  | Average Reward 9.03  | Actor loss: 0.03 | Critic loss: 0.95 | Entropy loss: -0.0003  | Total Loss: 0.98 | Total Steps: 38\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 895/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 896/94000  | Episode Reward: 8  | Average Reward 9.03  | Actor loss: -0.17 | Critic loss: 1.37 | Entropy loss: -0.0065  | Total Loss: 1.19 | Total Steps: 136\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 897/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 898/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.28 | Critic loss: 2.79 | Entropy loss: -0.0007  | Total Loss: 3.07 | Total Steps: 10\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 899/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.28 | Critic loss: 0.58 | Entropy loss: -0.0011  | Total Loss: 0.86 | Total Steps: 7\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 900/94000  | Episode Reward: 8  | Average Reward 9.00  | Actor loss: -0.12 | Critic loss: 1.77 | Entropy loss: -0.0033  | Total Loss: 1.65 | Total Steps: 231\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 901/94000  | Episode Reward: 10  | Average Reward 9.00  | Actor loss: 0.10 | Critic loss: 0.29 | Entropy loss: -0.0012  | Total Loss: 0.39 | Total Steps: 12\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0002  | Total Loss: 0.11 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 10  | Average Reward 8.20  | Actor loss: 0.00 | Critic loss: 0.22 | Entropy loss: -0.0673  | Total Loss: 0.16 | Total Steps: 9\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 3/100  | Episode Reward: -68  | Average Reward 7.47  | Actor loss: -0.27 | Critic loss: 97.30 | Entropy loss: -0.0450  | Total Loss: 96.99 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 10  | Average Reward 7.47  | Actor loss: 0.02 | Critic loss: 2.16 | Entropy loss: -0.0232  | Total Loss: 2.15 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 10  | Average Reward 7.47  | Actor loss: -0.00 | Critic loss: 0.09 | Entropy loss: -0.0194  | Total Loss: 0.07 | Total Steps: 51\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 10  | Average Reward 7.47  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0034  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: 10  | Average Reward 7.54  | Actor loss: 0.00 | Critic loss: 24.18 | Entropy loss: -0.0607  | Total Loss: 24.12 | Total Steps: 11\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 10  | Average Reward 7.54  | Actor loss: 0.00 | Critic loss: 0.39 | Entropy loss: -0.0025  | Total Loss: 0.39 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 8  | Average Reward 7.52  | Actor loss: 0.00 | Critic loss: 0.48 | Entropy loss: -0.0082  | Total Loss: 0.47 | Total Steps: 53\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 10  | Average Reward 7.57  | Actor loss: 0.01 | Critic loss: 9.94 | Entropy loss: -0.0078  | Total Loss: 9.94 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 8  | Average Reward 7.57  | Actor loss: 0.00 | Critic loss: 0.84 | Entropy loss: -0.0032  | Total Loss: 0.83 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 10  | Average Reward 7.57  | Actor loss: 0.00 | Critic loss: 1.06 | Entropy loss: -0.0654  | Total Loss: 1.00 | Total Steps: 9\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: -78  | Average Reward 6.70  | Actor loss: 0.12 | Critic loss: 5.81 | Entropy loss: -0.0391  | Total Loss: 5.89 | Total Steps: 382\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: 8  | Average Reward 6.67  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0012  | Total Loss: 0.09 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 8  | Average Reward 6.64  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0017  | Total Loss: 0.07 | Total Steps: 34\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 10  | Average Reward 6.64  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0005  | Total Loss: 0.06 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 10  | Average Reward 6.64  | Actor loss: 0.02 | Critic loss: 23.53 | Entropy loss: -0.0351  | Total Loss: 23.52 | Total Steps: 13\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 10  | Average Reward 6.66  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0072  | Total Loss: -0.01 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 10  | Average Reward 6.66  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0161  | Total Loss: -0.02 | Total Steps: 50\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: 10  | Average Reward 6.66  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0011  | Total Loss: 0.17 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 10  | Average Reward 6.86  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0694  | Total Loss: 0.03 | Total Steps: 9\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 22/100  | Episode Reward: 5  | Average Reward 6.80  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0042  | Total Loss: 0.23 | Total Steps: 49\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 10  | Average Reward 6.80  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0009  | Total Loss: 0.02 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 10  | Average Reward 7.00  | Actor loss: 0.02 | Critic loss: 4.24 | Entropy loss: -0.0040  | Total Loss: 4.25 | Total Steps: 247\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 5  | Average Reward 6.98  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0017  | Total Loss: 0.19 | Total Steps: 42\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 9  | Average Reward 7.00  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0190  | Total Loss: 0.21 | Total Steps: 26\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 10  | Average Reward 7.04  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0036  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 10  | Average Reward 7.07  | Actor loss: 0.00 | Critic loss: 0.33 | Entropy loss: -0.0155  | Total Loss: 0.31 | Total Steps: 60\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 10  | Average Reward 7.07  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0068  | Total Loss: 0.04 | Total Steps: 36\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 8  | Average Reward 7.04  | Actor loss: -0.00 | Critic loss: 0.06 | Entropy loss: -0.0024  | Total Loss: 0.06 | Total Steps: 39\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 5  | Average Reward 7.00  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0091  | Total Loss: 0.02 | Total Steps: 46\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 32/100  | Episode Reward: 5  | Average Reward 6.95  | Actor loss: 0.31 | Critic loss: 0.07 | Entropy loss: -0.0067  | Total Loss: 0.38 | Total Steps: 45\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 33/100  | Episode Reward: 10  | Average Reward 6.95  | Actor loss: 0.02 | Critic loss: 1.46 | Entropy loss: -0.0150  | Total Loss: 1.47 | Total Steps: 11\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 34/100  | Episode Reward: 10  | Average Reward 6.97  | Actor loss: 0.00 | Critic loss: 0.24 | Entropy loss: -0.0016  | Total Loss: 0.24 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 35/100  | Episode Reward: 8  | Average Reward 6.95  | Actor loss: 0.00 | Critic loss: 0.30 | Entropy loss: -0.0033  | Total Loss: 0.30 | Total Steps: 64\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 36/100  | Episode Reward: 10  | Average Reward 6.96  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0008  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 37/100  | Episode Reward: 5  | Average Reward 6.93  | Actor loss: 0.00 | Critic loss: 1.21 | Entropy loss: -0.0007  | Total Loss: 1.21 | Total Steps: 42\n",
      "TEST: ---yellow prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "TEST: Step: 300\n",
      "Testing  | Episode: 38/100  | Episode Reward: -40  | Average Reward 6.43  | Actor loss: 4.05 | Critic loss: 22.88 | Entropy loss: -0.0416  | Total Loss: 26.89 | Total Steps: 300\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 10  | Average Reward 6.43  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0074  | Total Loss: -0.01 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 8  | Average Reward 6.46  | Actor loss: 0.03 | Critic loss: 5.55 | Entropy loss: -0.0229  | Total Loss: 5.56 | Total Steps: 28\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 5  | Average Reward 6.43  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0011  | Total Loss: 0.17 | Total Steps: 49\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 5  | Average Reward 6.43  | Actor loss: 0.00 | Critic loss: 1.11 | Entropy loss: -0.0005  | Total Loss: 1.11 | Total Steps: 42\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 43/100  | Episode Reward: 8  | Average Reward 6.41  | Actor loss: 0.01 | Critic loss: 3.17 | Entropy loss: -0.0171  | Total Loss: 3.17 | Total Steps: 30\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 10  | Average Reward 6.41  | Actor loss: 0.00 | Critic loss: 2.79 | Entropy loss: -0.0007  | Total Loss: 2.79 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: 8  | Average Reward 6.41  | Actor loss: 0.01 | Critic loss: 0.36 | Entropy loss: -0.0081  | Total Loss: 0.36 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 10  | Average Reward 6.44  | Actor loss: 0.01 | Critic loss: 9.94 | Entropy loss: -0.0077  | Total Loss: 9.94 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 10  | Average Reward 6.46  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0092  | Total Loss: 0.02 | Total Steps: 62\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 10  | Average Reward 6.46  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0023  | Total Loss: 0.06 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 8  | Average Reward 6.44  | Actor loss: 0.00 | Critic loss: 0.92 | Entropy loss: -0.0004  | Total Loss: 0.92 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 8  | Average Reward 6.42  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0365  | Total Loss: 0.03 | Total Steps: 52\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 8  | Average Reward 6.42  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0014  | Total Loss: 0.05 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 10  | Average Reward 6.42  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0005  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 53/100  | Episode Reward: 8  | Average Reward 6.39  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0142  | Total Loss: -0.01 | Total Steps: 51\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 54/100  | Episode Reward: 8  | Average Reward 6.39  | Actor loss: 0.02 | Critic loss: 7.38 | Entropy loss: -0.0122  | Total Loss: 7.39 | Total Steps: 67\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 10  | Average Reward 6.39  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0125  | Total Loss: -0.00 | Total Steps: 63\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: -11  | Average Reward 6.18  | Actor loss: 0.18 | Critic loss: 25.07 | Entropy loss: -0.0396  | Total Loss: 25.22 | Total Steps: 130\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 10  | Average Reward 6.18  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0070  | Total Loss: 0.03 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 10  | Average Reward 6.21  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0169  | Total Loss: 0.00 | Total Steps: 42\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 10  | Average Reward 6.21  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0030  | Total Loss: 0.12 | Total Steps: 6\n",
      "TEST: ---green cube---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 60/100  | Episode Reward: 10  | Average Reward 6.41  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0163  | Total Loss: 0.00 | Total Steps: 8\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 61/100  | Episode Reward: -105  | Average Reward 5.25  | Actor loss: -9.93 | Critic loss: 85.36 | Entropy loss: -0.0463  | Total Loss: 75.38 | Total Steps: 500\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 10  | Average Reward 5.25  | Actor loss: -0.00 | Critic loss: 0.12 | Entropy loss: -0.0091  | Total Loss: 0.11 | Total Steps: 59\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: 5  | Average Reward 5.21  | Actor loss: 0.03 | Critic loss: 0.32 | Entropy loss: -0.0113  | Total Loss: 0.34 | Total Steps: 47\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 64/100  | Episode Reward: 10  | Average Reward 5.21  | Actor loss: 0.01 | Critic loss: 0.18 | Entropy loss: -0.0083  | Total Loss: 0.17 | Total Steps: 40\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 65/100  | Episode Reward: 9  | Average Reward 5.20  | Actor loss: 0.00 | Critic loss: 0.47 | Entropy loss: -0.0266  | Total Loss: 0.45 | Total Steps: 27\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 10  | Average Reward 5.20  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0563  | Total Loss: 0.01 | Total Steps: 12\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 8  | Average Reward 5.22  | Actor loss: 0.01 | Critic loss: 1.06 | Entropy loss: -0.0231  | Total Loss: 1.04 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 200\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 68/100  | Episode Reward: 8  | Average Reward 5.20  | Actor loss: 0.15 | Critic loss: 0.13 | Entropy loss: -0.0023  | Total Loss: 0.28 | Total Steps: 215\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 10  | Average Reward 5.20  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0009  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 70/100  | Episode Reward: 10  | Average Reward 5.20  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0003  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 10  | Average Reward 5.20  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0004  | Total Loss: 0.07 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 10  | Average Reward 5.20  | Actor loss: 0.01 | Critic loss: 0.45 | Entropy loss: -0.0026  | Total Loss: 0.46 | Total Steps: 156\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 5  | Average Reward 5.14  | Actor loss: 0.00 | Critic loss: 2.20 | Entropy loss: -0.0247  | Total Loss: 2.18 | Total Steps: 34\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: 10  | Average Reward 5.14  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0044  | Total Loss: 0.06 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 10  | Average Reward 5.14  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0107  | Total Loss: -0.01 | Total Steps: 39\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 8  | Average Reward 5.14  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0005  | Total Loss: 0.07 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 77/100  | Episode Reward: -26  | Average Reward 4.81  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0530  | Total Loss: 0.11 | Total Steps: 311\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 10  | Average Reward 4.81  | Actor loss: 0.02 | Critic loss: 3.00 | Entropy loss: -0.0048  | Total Loss: 3.01 | Total Steps: 219\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 79/100  | Episode Reward: -63  | Average Reward 4.11  | Actor loss: -3.02 | Critic loss: 98.04 | Entropy loss: -0.0465  | Total Loss: 94.97 | Total Steps: 500\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 10  | Average Reward 4.13  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0274  | Total Loss: 0.05 | Total Steps: 8\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 10  | Average Reward 4.13  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0048  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: 5  | Average Reward 4.08  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0010  | Total Loss: 0.20 | Total Steps: 42\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 5  | Average Reward 4.03  | Actor loss: 0.00 | Critic loss: 0.26 | Entropy loss: -0.0060  | Total Loss: 0.25 | Total Steps: 42\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 84/100  | Episode Reward: 10  | Average Reward 4.03  | Actor loss: 0.12 | Critic loss: 0.60 | Entropy loss: -0.0450  | Total Loss: 0.68 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 85/100  | Episode Reward: 10  | Average Reward 4.03  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0198  | Total Loss: -0.02 | Total Steps: 9\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: 10  | Average Reward 4.08  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0387  | Total Loss: 0.04 | Total Steps: 10\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 10  | Average Reward 4.08  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0348  | Total Loss: 0.07 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 10  | Average Reward 4.11  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0405  | Total Loss: -0.01 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 89/100  | Episode Reward: 10  | Average Reward 4.11  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0072  | Total Loss: 0.02 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 90/100  | Episode Reward: 8  | Average Reward 4.16  | Actor loss: 0.00 | Critic loss: 1.29 | Entropy loss: -0.0027  | Total Loss: 1.29 | Total Steps: 43\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 8  | Average Reward 4.13  | Actor loss: 0.39 | Critic loss: 0.69 | Entropy loss: -0.0119  | Total Loss: 1.06 | Total Steps: 67\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 92/100  | Episode Reward: -10  | Average Reward 3.93  | Actor loss: -0.00 | Critic loss: 56.32 | Entropy loss: -0.0001  | Total Loss: 56.32 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: 8  | Average Reward 3.91  | Actor loss: 0.03 | Critic loss: 2.45 | Entropy loss: -0.0561  | Total Loss: 2.43 | Total Steps: 26\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 8  | Average Reward 3.94  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0061  | Total Loss: 0.23 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: -32  | Average Reward 3.59  | Actor loss: 0.05 | Critic loss: 8.45 | Entropy loss: -0.0492  | Total Loss: 8.45 | Total Steps: 235\n",
      "TEST: ---green cube---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 96/100  | Episode Reward: -10  | Average Reward 3.44  | Actor loss: -0.01 | Critic loss: 70.79 | Entropy loss: -0.0002  | Total Loss: 70.79 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 10  | Average Reward 3.44  | Actor loss: 0.00 | Critic loss: 2.97 | Entropy loss: -0.0002  | Total Loss: 2.97 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: 5  | Average Reward 3.39  | Actor loss: 0.00 | Critic loss: 3.20 | Entropy loss: -0.0092  | Total Loss: 3.19 | Total Steps: 47\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 10  | Average Reward 3.44  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0018  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 10  | Average Reward 3.44  | Actor loss: 0.00 | Critic loss: 0.39 | Entropy loss: -0.0085  | Total Loss: 0.39 | Total Steps: 8\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 902/94000  | Episode Reward: 10  | Average Reward 9.00  | Actor loss: 0.02 | Critic loss: 4.36 | Entropy loss: -0.0003  | Total Loss: 4.38 | Total Steps: 45\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 903/94000  | Episode Reward: 10  | Average Reward 9.00  | Actor loss: 0.31 | Critic loss: 0.65 | Entropy loss: -0.0009  | Total Loss: 0.95 | Total Steps: 7\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 904/94000  | Episode Reward: 10  | Average Reward 9.00  | Actor loss: 0.33 | Critic loss: 0.57 | Entropy loss: -0.0009  | Total Loss: 0.90 | Total Steps: 8\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 905/94000  | Episode Reward: 10  | Average Reward 9.00  | Actor loss: 0.14 | Critic loss: 0.04 | Entropy loss: -0.0012  | Total Loss: 0.18 | Total Steps: 9\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 906/94000  | Episode Reward: 8  | Average Reward 8.97  | Actor loss: -0.13 | Critic loss: 5.15 | Entropy loss: -0.0012  | Total Loss: 5.02 | Total Steps: 53\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 907/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 908/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.04 | Critic loss: 5.28 | Entropy loss: -0.0005  | Total Loss: 5.31 | Total Steps: 31\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 909/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 910/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.04 | Critic loss: 0.06 | Entropy loss: -0.0004  | Total Loss: 0.10 | Total Steps: 8\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 911/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.00 | Critic loss: 1.83 | Entropy loss: -0.0000  | Total Loss: 1.83 | Total Steps: 31\n",
      "\n",
      "---red cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 912/94000  | Episode Reward: 8  | Average Reward 8.95  | Actor loss: -0.55 | Critic loss: 6.12 | Entropy loss: -0.0033  | Total Loss: 5.56 | Total Steps: 59\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 913/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: -0.12 | Critic loss: 1.65 | Entropy loss: -0.0026  | Total Loss: 1.53 | Total Steps: 93\n",
      "\n",
      "---yellow sphere---\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 914/94000  | Episode Reward: 8  | Average Reward 8.93  | Actor loss: -1.11 | Critic loss: 6.75 | Entropy loss: -0.0132  | Total Loss: 5.62 | Total Steps: 74\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 915/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: 0.01 | Critic loss: 2.86 | Entropy loss: -0.0001  | Total Loss: 2.87 | Total Steps: 31\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 916/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: 0.03 | Critic loss: 1.79 | Entropy loss: -0.0005  | Total Loss: 1.81 | Total Steps: 29\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 917/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: 0.11 | Critic loss: 1.83 | Entropy loss: -0.0009  | Total Loss: 1.94 | Total Steps: 29\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 918/94000  | Episode Reward: 8  | Average Reward 8.93  | Actor loss: 0.03 | Critic loss: 7.52 | Entropy loss: -0.0004  | Total Loss: 7.55 | Total Steps: 30\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 919/94000  | Episode Reward: 8  | Average Reward 8.90  | Actor loss: 0.07 | Critic loss: 2.95 | Entropy loss: -0.0017  | Total Loss: 3.01 | Total Steps: 41\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 920/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: -0.14 | Critic loss: 2.67 | Entropy loss: -0.0014  | Total Loss: 2.53 | Total Steps: 17\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 921/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: -0.02 | Critic loss: 0.57 | Entropy loss: -0.0005  | Total Loss: 0.56 | Total Steps: 50\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 922/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: 0.05 | Critic loss: 0.63 | Entropy loss: -0.0013  | Total Loss: 0.69 | Total Steps: 37\n",
      "\n",
      "---red cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 923/94000  | Episode Reward: 8  | Average Reward 8.90  | Actor loss: -0.35 | Critic loss: 2.96 | Entropy loss: -0.0018  | Total Loss: 2.61 | Total Steps: 43\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 924/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0000  | Total Loss: 0.18 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 925/94000  | Episode Reward: 8  | Average Reward 8.88  | Actor loss: -0.40 | Critic loss: 10.13 | Entropy loss: -0.0014  | Total Loss: 9.73 | Total Steps: 53\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 926/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 927/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.26 | Critic loss: 0.30 | Entropy loss: -0.0015  | Total Loss: 0.56 | Total Steps: 12\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 928/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.03 | Critic loss: 0.29 | Entropy loss: -0.0010  | Total Loss: 0.32 | Total Steps: 8\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 929/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.01 | Critic loss: 1.85 | Entropy loss: -0.0001  | Total Loss: 1.85 | Total Steps: 31\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 930/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: -0.01 | Critic loss: 0.93 | Entropy loss: -0.0024  | Total Loss: 0.91 | Total Steps: 51\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 931/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: 0.00 | Critic loss: 1.43 | Entropy loss: -0.0000  | Total Loss: 1.43 | Total Steps: 31\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 932/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: 0.01 | Critic loss: 0.30 | Entropy loss: -0.0000  | Total Loss: 0.31 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 933/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: -0.03 | Critic loss: 0.02 | Entropy loss: -0.0006  | Total Loss: -0.01 | Total Steps: 9\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 934/94000  | Episode Reward: 5  | Average Reward 8.88  | Actor loss: -1.03 | Critic loss: 7.23 | Entropy loss: -0.0041  | Total Loss: 6.19 | Total Steps: 44\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 935/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 936/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: -0.20 | Critic loss: 3.42 | Entropy loss: -0.0037  | Total Loss: 3.21 | Total Steps: 53\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 937/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.11 | Critic loss: 0.66 | Entropy loss: -0.0004  | Total Loss: 0.77 | Total Steps: 11\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 938/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0000  | Total Loss: 0.11 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 939/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.01 | Critic loss: 1.03 | Entropy loss: -0.0003  | Total Loss: 1.05 | Total Steps: 31\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 940/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 941/94000  | Episode Reward: 8  | Average Reward 8.88  | Actor loss: -0.00 | Critic loss: 1.32 | Entropy loss: -0.0001  | Total Loss: 1.32 | Total Steps: 46\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 942/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.00 | Critic loss: 1.78 | Entropy loss: -0.0000  | Total Loss: 1.78 | Total Steps: 31\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 943/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: -0.06 | Critic loss: 5.06 | Entropy loss: -0.0040  | Total Loss: 5.00 | Total Steps: 57\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 944/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0000  | Total Loss: 0.10 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 945/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.01 | Critic loss: 1.15 | Entropy loss: -0.0002  | Total Loss: 1.16 | Total Steps: 38\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 946/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.02 | Critic loss: 0.74 | Entropy loss: -0.0003  | Total Loss: 0.76 | Total Steps: 32\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 947/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: -0.58 | Critic loss: 3.06 | Entropy loss: -0.0017  | Total Loss: 2.47 | Total Steps: 22\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 948/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.11 | Critic loss: 4.17 | Entropy loss: -0.0008  | Total Loss: 4.28 | Total Steps: 20\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 949/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.00 | Critic loss: 1.02 | Entropy loss: -0.0000  | Total Loss: 1.02 | Total Steps: 31\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 950/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: -0.00 | Critic loss: 3.83 | Entropy loss: -0.0001  | Total Loss: 3.83 | Total Steps: 34\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 951/94000  | Episode Reward: 8  | Average Reward 8.93  | Actor loss: 0.00 | Critic loss: 3.65 | Entropy loss: -0.0001  | Total Loss: 3.65 | Total Steps: 30\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 952/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: -0.00 | Critic loss: 4.62 | Entropy loss: -0.0001  | Total Loss: 4.62 | Total Steps: 47\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 953/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: 0.01 | Critic loss: 1.53 | Entropy loss: -0.0000  | Total Loss: 1.54 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 954/94000  | Episode Reward: -10  | Average Reward 8.76  | Actor loss: -0.00 | Critic loss: 5.32 | Entropy loss: -0.0000  | Total Loss: 5.32 | Total Steps: 500\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 955/94000  | Episode Reward: 10  | Average Reward 8.76  | Actor loss: 0.08 | Critic loss: 0.92 | Entropy loss: -0.0001  | Total Loss: 1.00 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 956/94000  | Episode Reward: 8  | Average Reward 8.76  | Actor loss: 0.02 | Critic loss: 0.53 | Entropy loss: -0.0004  | Total Loss: 0.55 | Total Steps: 38\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 957/94000  | Episode Reward: 10  | Average Reward 8.76  | Actor loss: -0.23 | Critic loss: 3.73 | Entropy loss: -0.0014  | Total Loss: 3.50 | Total Steps: 58\n",
      "\n",
      "---yellow cube---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 958/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 959/94000  | Episode Reward: 8  | Average Reward 8.76  | Actor loss: 0.06 | Critic loss: 2.70 | Entropy loss: -0.0011  | Total Loss: 2.76 | Total Steps: 36\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 960/94000  | Episode Reward: 10  | Average Reward 8.76  | Actor loss: 0.00 | Critic loss: 0.39 | Entropy loss: -0.0000  | Total Loss: 0.40 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 961/94000  | Episode Reward: 10  | Average Reward 8.76  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 962/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: -0.18 | Critic loss: 6.21 | Entropy loss: -0.0040  | Total Loss: 6.03 | Total Steps: 57\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 963/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.08 | Critic loss: 0.83 | Entropy loss: -0.0004  | Total Loss: 0.90 | Total Steps: 12\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 964/94000  | Episode Reward: 5  | Average Reward 8.73  | Actor loss: -0.35 | Critic loss: 5.04 | Entropy loss: -0.0017  | Total Loss: 4.68 | Total Steps: 48\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 965/94000  | Episode Reward: 10  | Average Reward 8.73  | Actor loss: 0.09 | Critic loss: 4.03 | Entropy loss: -0.0011  | Total Loss: 4.12 | Total Steps: 36\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 966/94000  | Episode Reward: 8  | Average Reward 8.71  | Actor loss: -0.11 | Critic loss: 2.05 | Entropy loss: -0.0018  | Total Loss: 1.93 | Total Steps: 66\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 967/94000  | Episode Reward: 10  | Average Reward 8.71  | Actor loss: 0.07 | Critic loss: 1.15 | Entropy loss: -0.0002  | Total Loss: 1.22 | Total Steps: 11\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 968/94000  | Episode Reward: 10  | Average Reward 8.71  | Actor loss: -0.00 | Critic loss: 3.80 | Entropy loss: -0.0003  | Total Loss: 3.80 | Total Steps: 29\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 969/94000  | Episode Reward: 8  | Average Reward 8.88  | Actor loss: 0.00 | Critic loss: 1.51 | Entropy loss: -0.0005  | Total Loss: 1.51 | Total Steps: 30\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 970/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.07 | Critic loss: 0.33 | Entropy loss: -0.0008  | Total Loss: 0.39 | Total Steps: 10\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 971/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.00 | Critic loss: 1.36 | Entropy loss: -0.0000  | Total Loss: 1.36 | Total Steps: 31\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 972/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.07 | Critic loss: 0.46 | Entropy loss: -0.0002  | Total Loss: 0.53 | Total Steps: 8\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 973/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.00 | Critic loss: 1.56 | Entropy loss: -0.0000  | Total Loss: 1.56 | Total Steps: 31\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 974/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: -0.12 | Critic loss: 0.21 | Entropy loss: -0.0025  | Total Loss: 0.08 | Total Steps: 10\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 975/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 976/94000  | Episode Reward: 8  | Average Reward 8.96  | Actor loss: -0.15 | Critic loss: 4.31 | Entropy loss: -0.0010  | Total Loss: 4.16 | Total Steps: 52\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 977/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: -0.26 | Critic loss: 0.06 | Entropy loss: -0.0023  | Total Loss: -0.21 | Total Steps: 10\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 978/94000  | Episode Reward: 10  | Average Reward 8.98  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 979/94000  | Episode Reward: 8  | Average Reward 8.96  | Actor loss: -0.24 | Critic loss: 4.10 | Entropy loss: -0.0013  | Total Loss: 3.85 | Total Steps: 55\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 980/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 981/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: 0.04 | Critic loss: 4.14 | Entropy loss: -0.0044  | Total Loss: 4.17 | Total Steps: 58\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 982/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: 0.02 | Critic loss: 4.83 | Entropy loss: -0.0006  | Total Loss: 4.85 | Total Steps: 29\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 983/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 984/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 985/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0000  | Total Loss: 0.11 | Total Steps: 6\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 986/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.05 | Critic loss: 0.38 | Entropy loss: -0.0002  | Total Loss: 0.43 | Total Steps: 10\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 987/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.00 | Critic loss: 0.73 | Entropy loss: -0.0000  | Total Loss: 0.73 | Total Steps: 31\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 988/94000  | Episode Reward: 10  | Average Reward 9.23  | Actor loss: -0.01 | Critic loss: 1.77 | Entropy loss: -0.0009  | Total Loss: 1.75 | Total Steps: 30\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 989/94000  | Episode Reward: 10  | Average Reward 9.26  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 990/94000  | Episode Reward: 10  | Average Reward 9.26  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 991/94000  | Episode Reward: 8  | Average Reward 9.23  | Actor loss: -0.12 | Critic loss: 1.38 | Entropy loss: -0.0017  | Total Loss: 1.26 | Total Steps: 42\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 992/94000  | Episode Reward: 10  | Average Reward 9.23  | Actor loss: 0.00 | Critic loss: 1.04 | Entropy loss: -0.0000  | Total Loss: 1.04 | Total Steps: 31\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 993/94000  | Episode Reward: 8  | Average Reward 9.21  | Actor loss: -0.44 | Critic loss: 6.39 | Entropy loss: -0.0035  | Total Loss: 5.95 | Total Steps: 63\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 994/94000  | Episode Reward: 8  | Average Reward 9.21  | Actor loss: -0.07 | Critic loss: 0.94 | Entropy loss: -0.0016  | Total Loss: 0.87 | Total Steps: 35\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 995/94000  | Episode Reward: 8  | Average Reward 9.18  | Actor loss: -0.23 | Critic loss: 4.29 | Entropy loss: -0.0017  | Total Loss: 4.06 | Total Steps: 46\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 996/94000  | Episode Reward: 10  | Average Reward 9.21  | Actor loss: -0.07 | Critic loss: 1.18 | Entropy loss: -0.0018  | Total Loss: 1.11 | Total Steps: 50\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 997/94000  | Episode Reward: 10  | Average Reward 9.21  | Actor loss: -0.05 | Critic loss: 0.20 | Entropy loss: -0.0012  | Total Loss: 0.15 | Total Steps: 9\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 998/94000  | Episode Reward: 10  | Average Reward 9.21  | Actor loss: -0.12 | Critic loss: 0.12 | Entropy loss: -0.0028  | Total Loss: -0.01 | Total Steps: 12\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 999/94000  | Episode Reward: 10  | Average Reward 9.21  | Actor loss: -0.02 | Critic loss: 0.04 | Entropy loss: -0.0016  | Total Loss: 0.02 | Total Steps: 8\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1000/94000  | Episode Reward: 10  | Average Reward 9.23  | Actor loss: 0.00 | Critic loss: 0.89 | Entropy loss: -0.0000  | Total Loss: 0.89 | Total Steps: 31\n",
      "\n",
      "---red cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1001/94000  | Episode Reward: 8  | Average Reward 9.21  | Actor loss: -0.01 | Critic loss: 0.94 | Entropy loss: -0.0020  | Total Loss: 0.92 | Total Steps: 40\n",
      "Model has been saved\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 8  | Average Reward 3.42  | Actor loss: 0.00 | Critic loss: 0.42 | Entropy loss: -0.0092  | Total Loss: 0.41 | Total Steps: 43\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 8  | Average Reward 3.40  | Actor loss: 0.06 | Critic loss: 9.36 | Entropy loss: -0.0371  | Total Loss: 9.38 | Total Steps: 52\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 3/100  | Episode Reward: 8  | Average Reward 4.15  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0026  | Total Loss: 0.13 | Total Steps: 30\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 0  | Average Reward 4.05  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0037  | Total Loss: 0.13 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 10  | Average Reward 4.05  | Actor loss: 0.05 | Critic loss: 0.44 | Entropy loss: -0.0452  | Total Loss: 0.45 | Total Steps: 7\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 5  | Average Reward 4.00  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0021  | Total Loss: 0.09 | Total Steps: 47\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: 8  | Average Reward 3.98  | Actor loss: 0.00 | Critic loss: 0.38 | Entropy loss: -0.0003  | Total Loss: 0.38 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 8  | Average Reward 3.95  | Actor loss: 0.08 | Critic loss: 14.61 | Entropy loss: -0.0241  | Total Loss: 14.67 | Total Steps: 52\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 10  | Average Reward 3.98  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0229  | Total Loss: 0.03 | Total Steps: 10\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 8  | Average Reward 3.95  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0021  | Total Loss: 0.01 | Total Steps: 36\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 10  | Average Reward 3.98  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0005  | Total Loss: 0.06 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 8  | Average Reward 3.95  | Actor loss: 0.00 | Critic loss: 0.63 | Entropy loss: -0.0122  | Total Loss: 0.62 | Total Steps: 38\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 8  | Average Reward 4.80  | Actor loss: 0.01 | Critic loss: 0.04 | Entropy loss: -0.0082  | Total Loss: 0.05 | Total Steps: 67\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: 5  | Average Reward 4.78  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0052  | Total Loss: 0.06 | Total Steps: 59\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 10  | Average Reward 4.80  | Actor loss: 0.00 | Critic loss: 0.89 | Entropy loss: -0.0003  | Total Loss: 0.89 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 2  | Average Reward 4.72  | Actor loss: 0.00 | Critic loss: 0.53 | Entropy loss: -0.0128  | Total Loss: 0.52 | Total Steps: 43\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 10  | Average Reward 4.72  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0059  | Total Loss: 0.02 | Total Steps: 56\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 8  | Average Reward 4.70  | Actor loss: -0.00 | Critic loss: 0.05 | Entropy loss: -0.0239  | Total Loss: 0.02 | Total Steps: 45\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 10  | Average Reward 4.70  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0045  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---black sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: 10  | Average Reward 4.70  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0010  | Total Loss: 0.11 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 10  | Average Reward 4.70  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0003  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 22/100  | Episode Reward: 10  | Average Reward 4.75  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0163  | Total Loss: -0.01 | Total Steps: 35\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 10  | Average Reward 4.75  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0006  | Total Loss: 0.09 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 10  | Average Reward 4.75  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0006  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 10  | Average Reward 4.80  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0006  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 5  | Average Reward 4.76  | Actor loss: 0.00 | Critic loss: 0.49 | Entropy loss: -0.0073  | Total Loss: 0.48 | Total Steps: 46\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 10  | Average Reward 4.76  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0015  | Total Loss: 0.19 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 8  | Average Reward 4.74  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0121  | Total Loss: 0.00 | Total Steps: 53\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 5  | Average Reward 4.68  | Actor loss: 0.00 | Critic loss: 0.24 | Entropy loss: -0.0014  | Total Loss: 0.24 | Total Steps: 46\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 8  | Average Reward 4.68  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0003  | Total Loss: 0.07 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 8  | Average Reward 4.71  | Actor loss: 0.00 | Critic loss: 0.32 | Entropy loss: -0.0003  | Total Loss: 0.32 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 32/100  | Episode Reward: 8  | Average Reward 4.74  | Actor loss: 0.00 | Critic loss: 0.39 | Entropy loss: -0.0004  | Total Loss: 0.39 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 33/100  | Episode Reward: 8  | Average Reward 4.71  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0026  | Total Loss: 0.13 | Total Steps: 30\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 34/100  | Episode Reward: 10  | Average Reward 4.71  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0009  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 35/100  | Episode Reward: 8  | Average Reward 4.71  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0002  | Total Loss: 0.21 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 36/100  | Episode Reward: -10  | Average Reward 4.51  | Actor loss: -0.00 | Critic loss: 86.09 | Entropy loss: -0.0019  | Total Loss: 86.08 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 37/100  | Episode Reward: -10  | Average Reward 4.36  | Actor loss: -0.00 | Critic loss: 89.43 | Entropy loss: -0.0000  | Total Loss: 89.43 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: 10  | Average Reward 4.86  | Actor loss: 0.02 | Critic loss: 1.59 | Entropy loss: -0.0485  | Total Loss: 1.56 | Total Steps: 7\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 10  | Average Reward 4.86  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0082  | Total Loss: 0.05 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 10  | Average Reward 4.88  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0004  | Total Loss: 0.12 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 10  | Average Reward 4.93  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0144  | Total Loss: 0.19 | Total Steps: 9\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 8  | Average Reward 4.96  | Actor loss: 0.01 | Critic loss: 4.04 | Entropy loss: -0.0150  | Total Loss: 4.03 | Total Steps: 35\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 43/100  | Episode Reward: 10  | Average Reward 4.98  | Actor loss: 0.00 | Critic loss: 2.79 | Entropy loss: -0.0036  | Total Loss: 2.79 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 10  | Average Reward 4.98  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0065  | Total Loss: 0.05 | Total Steps: 44\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: -4  | Average Reward 4.87  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0482  | Total Loss: 0.07 | Total Steps: 244\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 7  | Average Reward 4.83  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0500  | Total Loss: 0.18 | Total Steps: 111\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 10  | Average Reward 4.83  | Actor loss: 0.00 | Critic loss: 1.61 | Entropy loss: -0.0091  | Total Loss: 1.61 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 10  | Average Reward 4.83  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0005  | Total Loss: 0.16 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 10  | Average Reward 4.86  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0002  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 10  | Average Reward 4.88  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0143  | Total Loss: 0.12 | Total Steps: 40\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 8  | Average Reward 4.88  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0045  | Total Loss: 0.12 | Total Steps: 96\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 9  | Average Reward 4.88  | Actor loss: 0.00 | Critic loss: 0.95 | Entropy loss: -0.0477  | Total Loss: 0.90 | Total Steps: 101\n",
      "TEST: ---red capsule---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 53/100  | Episode Reward: -10  | Average Reward 4.70  | Actor loss: -0.02 | Critic loss: 90.38 | Entropy loss: -0.0002  | Total Loss: 90.36 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 54/100  | Episode Reward: 9  | Average Reward 4.71  | Actor loss: 0.00 | Critic loss: 0.64 | Entropy loss: -0.0514  | Total Loss: 0.59 | Total Steps: 59\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 10  | Average Reward 4.71  | Actor loss: 0.04 | Critic loss: 4.53 | Entropy loss: -0.0077  | Total Loss: 4.57 | Total Steps: 49\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: 10  | Average Reward 4.92  | Actor loss: 0.00 | Critic loss: 0.26 | Entropy loss: -0.0007  | Total Loss: 0.26 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 10  | Average Reward 4.92  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0002  | Total Loss: 0.13 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 10  | Average Reward 4.92  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0085  | Total Loss: 0.13 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 5  | Average Reward 4.88  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0020  | Total Loss: 0.18 | Total Steps: 47\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 60/100  | Episode Reward: 5  | Average Reward 4.83  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0313  | Total Loss: 0.16 | Total Steps: 61\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 61/100  | Episode Reward: 10  | Average Reward 5.97  | Actor loss: 0.00 | Critic loss: 0.36 | Entropy loss: -0.0014  | Total Loss: 0.36 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 8  | Average Reward 5.95  | Actor loss: 0.00 | Critic loss: 0.44 | Entropy loss: -0.0005  | Total Loss: 0.44 | Total Steps: 34\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: 5  | Average Reward 5.95  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0142  | Total Loss: 0.12 | Total Steps: 55\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 64/100  | Episode Reward: 10  | Average Reward 5.95  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0025  | Total Loss: 0.12 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 65/100  | Episode Reward: 10  | Average Reward 5.96  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0275  | Total Loss: -0.03 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 10  | Average Reward 5.96  | Actor loss: 0.00 | Critic loss: 0.61 | Entropy loss: -0.0224  | Total Loss: 0.59 | Total Steps: 12\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 8  | Average Reward 5.96  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0034  | Total Loss: 0.13 | Total Steps: 30\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 68/100  | Episode Reward: -10  | Average Reward 5.79  | Actor loss: -0.00 | Critic loss: 88.48 | Entropy loss: -0.0001  | Total Loss: 88.48 | Total Steps: 500\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 5  | Average Reward 5.74  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0094  | Total Loss: 0.06 | Total Steps: 59\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 70/100  | Episode Reward: 10  | Average Reward 5.74  | Actor loss: 0.05 | Critic loss: 0.65 | Entropy loss: -0.0579  | Total Loss: 0.65 | Total Steps: 9\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 10  | Average Reward 5.74  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0141  | Total Loss: -0.01 | Total Steps: 11\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 10  | Average Reward 5.74  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0262  | Total Loss: -0.02 | Total Steps: 12\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 10  | Average Reward 5.79  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0097  | Total Loss: 0.02 | Total Steps: 47\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 74/100  | Episode Reward: -62  | Average Reward 5.07  | Actor loss: -0.63 | Critic loss: 102.75 | Entropy loss: -0.0464  | Total Loss: 102.07 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 5  | Average Reward 5.01  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0062  | Total Loss: -0.01 | Total Steps: 106\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 10  | Average Reward 5.04  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0081  | Total Loss: 0.09 | Total Steps: 9\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 77/100  | Episode Reward: 10  | Average Reward 5.40  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0005  | Total Loss: 0.12 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 10  | Average Reward 5.40  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0002  | Total Loss: 0.12 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 10  | Average Reward 6.13  | Actor loss: 0.00 | Critic loss: 0.61 | Entropy loss: -0.0351  | Total Loss: 0.57 | Total Steps: 10\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 10  | Average Reward 6.13  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0205  | Total Loss: 0.07 | Total Steps: 10\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 10  | Average Reward 6.13  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0036  | Total Loss: 0.02 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: 10  | Average Reward 6.18  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0007  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 8  | Average Reward 6.21  | Actor loss: 0.00 | Critic loss: 0.25 | Entropy loss: -0.0036  | Total Loss: 0.25 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 84/100  | Episode Reward: 8  | Average Reward 6.18  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0045  | Total Loss: 0.09 | Total Steps: 96\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 85/100  | Episode Reward: 10  | Average Reward 6.18  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0010  | Total Loss: 0.21 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: 8  | Average Reward 6.16  | Actor loss: 0.00 | Critic loss: 0.45 | Entropy loss: -0.0017  | Total Loss: 0.45 | Total Steps: 34\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 8  | Average Reward 6.13  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0050  | Total Loss: 0.05 | Total Steps: 98\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 8  | Average Reward 6.11  | Actor loss: 0.00 | Critic loss: 0.60 | Entropy loss: -0.0005  | Total Loss: 0.60 | Total Steps: 29\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 89/100  | Episode Reward: 9  | Average Reward 6.09  | Actor loss: 0.12 | Critic loss: 5.66 | Entropy loss: -0.0234  | Total Loss: 5.76 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 90/100  | Episode Reward: 8  | Average Reward 6.09  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0032  | Total Loss: 0.23 | Total Steps: 43\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 10  | Average Reward 6.12  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0181  | Total Loss: 0.01 | Total Steps: 12\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 10  | Average Reward 6.32  | Actor loss: 0.02 | Critic loss: 2.46 | Entropy loss: -0.0285  | Total Loss: 2.45 | Total Steps: 9\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: 10  | Average Reward 6.34  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0051  | Total Loss: 0.03 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 8  | Average Reward 6.34  | Actor loss: 0.05 | Critic loss: 7.38 | Entropy loss: -0.0049  | Total Loss: 7.42 | Total Steps: 59\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: 10  | Average Reward 6.76  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0199  | Total Loss: 0.15 | Total Steps: 40\n",
      "TEST: ---green cube---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 10  | Average Reward 6.96  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0015  | Total Loss: 0.09 | Total Steps: 366\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 5  | Average Reward 6.91  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0041  | Total Loss: 0.08 | Total Steps: 79\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: 10  | Average Reward 6.96  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0012  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 10  | Average Reward 6.96  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0002  | Total Loss: 0.12 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 8  | Average Reward 6.93  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0023  | Total Loss: 0.03 | Total Steps: 43\n",
      "\n",
      "---red prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1002/94000  | Episode Reward: 8  | Average Reward 9.18  | Actor loss: -0.39 | Critic loss: 4.52 | Entropy loss: -0.0020  | Total Loss: 4.13 | Total Steps: 41\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1003/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.00 | Critic loss: 0.75 | Entropy loss: -0.0000  | Total Loss: 0.75 | Total Steps: 31\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1004/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.02 | Critic loss: 0.68 | Entropy loss: -0.0004  | Total Loss: 0.70 | Total Steps: 31\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1005/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.06 | Critic loss: 0.39 | Entropy loss: -0.0002  | Total Loss: 0.45 | Total Steps: 8\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1006/94000  | Episode Reward: 10  | Average Reward 9.21  | Actor loss: -0.31 | Critic loss: 2.19 | Entropy loss: -0.0017  | Total Loss: 1.88 | Total Steps: 23\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1007/94000  | Episode Reward: 10  | Average Reward 9.21  | Actor loss: 0.00 | Critic loss: 0.77 | Entropy loss: -0.0001  | Total Loss: 0.77 | Total Steps: 31\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1008/94000  | Episode Reward: 10  | Average Reward 9.21  | Actor loss: -0.22 | Critic loss: 3.41 | Entropy loss: -0.0040  | Total Loss: 3.18 | Total Steps: 49\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1009/94000  | Episode Reward: 10  | Average Reward 9.21  | Actor loss: 0.00 | Critic loss: 0.86 | Entropy loss: -0.0001  | Total Loss: 0.86 | Total Steps: 31\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1010/94000  | Episode Reward: 10  | Average Reward 9.21  | Actor loss: -0.18 | Critic loss: 7.18 | Entropy loss: -0.0040  | Total Loss: 6.99 | Total Steps: 104\n",
      "\n",
      "---blue sphere---\n",
      "Step: 250\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1011/94000  | Episode Reward: 10  | Average Reward 9.21  | Actor loss: 0.00 | Critic loss: 1.83 | Entropy loss: -0.0027  | Total Loss: 1.83 | Total Steps: 486\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1012/94000  | Episode Reward: 10  | Average Reward 9.23  | Actor loss: 0.06 | Critic loss: 1.59 | Entropy loss: -0.0042  | Total Loss: 1.65 | Total Steps: 76\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1013/94000  | Episode Reward: 10  | Average Reward 9.23  | Actor loss: 0.00 | Critic loss: 0.88 | Entropy loss: -0.0000  | Total Loss: 0.88 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1014/94000  | Episode Reward: 10  | Average Reward 9.25  | Actor loss: 0.03 | Critic loss: 1.00 | Entropy loss: -0.0010  | Total Loss: 1.03 | Total Steps: 30\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1015/94000  | Episode Reward: 10  | Average Reward 9.25  | Actor loss: 0.01 | Critic loss: 4.76 | Entropy loss: -0.0002  | Total Loss: 4.77 | Total Steps: 29\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1016/94000  | Episode Reward: 10  | Average Reward 9.25  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0000  | Total Loss: 0.12 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1017/94000  | Episode Reward: 2  | Average Reward 9.18  | Actor loss: -0.02 | Critic loss: 11.04 | Entropy loss: -0.0007  | Total Loss: 11.02 | Total Steps: 51\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1018/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: 0.00 | Critic loss: 1.13 | Entropy loss: -0.0000  | Total Loss: 1.13 | Total Steps: 31\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1019/94000  | Episode Reward: 10  | Average Reward 9.22  | Actor loss: 0.00 | Critic loss: 1.16 | Entropy loss: -0.0000  | Total Loss: 1.16 | Total Steps: 31\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1020/94000  | Episode Reward: 10  | Average Reward 9.22  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1021/94000  | Episode Reward: 10  | Average Reward 9.22  | Actor loss: -0.04 | Critic loss: 2.60 | Entropy loss: -0.0010  | Total Loss: 2.55 | Total Steps: 34\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1022/94000  | Episode Reward: 10  | Average Reward 9.22  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0000  | Total Loss: 0.13 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1023/94000  | Episode Reward: 10  | Average Reward 9.25  | Actor loss: 0.00 | Critic loss: 0.86 | Entropy loss: -0.0000  | Total Loss: 0.86 | Total Steps: 31\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1024/94000  | Episode Reward: 10  | Average Reward 9.25  | Actor loss: 0.16 | Critic loss: 0.64 | Entropy loss: -0.0017  | Total Loss: 0.79 | Total Steps: 10\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1025/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.09 | Critic loss: 0.78 | Entropy loss: -0.0012  | Total Loss: 0.86 | Total Steps: 30\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1026/94000  | Episode Reward: 0  | Average Reward 9.18  | Actor loss: -0.75 | Critic loss: 12.41 | Entropy loss: -0.0027  | Total Loss: 11.66 | Total Steps: 53\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1027/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.04 | Critic loss: 0.02 | Entropy loss: -0.0011  | Total Loss: 0.06 | Total Steps: 9\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1028/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0000  | Total Loss: 0.16 | Total Steps: 6\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1029/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.00 | Critic loss: 0.89 | Entropy loss: -0.0001  | Total Loss: 0.89 | Total Steps: 31\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -1.0\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1030/94000  | Episode Reward: 9  | Average Reward 9.16  | Actor loss: -1.01 | Critic loss: 7.67 | Entropy loss: -0.0055  | Total Loss: 6.64 | Total Steps: 20\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1031/94000  | Episode Reward: 10  | Average Reward 9.16  | Actor loss: -0.01 | Critic loss: 3.47 | Entropy loss: -0.0009  | Total Loss: 3.46 | Total Steps: 29\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1032/94000  | Episode Reward: 5  | Average Reward 9.12  | Actor loss: 0.19 | Critic loss: 3.34 | Entropy loss: -0.0016  | Total Loss: 3.53 | Total Steps: 44\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1033/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.09 | Critic loss: 1.69 | Entropy loss: -0.0009  | Total Loss: 1.78 | Total Steps: 49\n",
      "\n",
      "---black cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1034/94000  | Episode Reward: 8  | Average Reward 9.14  | Actor loss: -0.16 | Critic loss: 2.80 | Entropy loss: -0.0040  | Total Loss: 2.64 | Total Steps: 79\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1035/94000  | Episode Reward: 10  | Average Reward 9.14  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1036/94000  | Episode Reward: 5  | Average Reward 9.09  | Actor loss: -0.81 | Critic loss: 9.06 | Entropy loss: -0.0055  | Total Loss: 8.24 | Total Steps: 62\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1037/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: 0.00 | Critic loss: 0.40 | Entropy loss: -0.0000  | Total Loss: 0.41 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1038/94000  | Episode Reward: 8  | Average Reward 9.06  | Actor loss: 0.00 | Critic loss: 1.18 | Entropy loss: -0.0002  | Total Loss: 1.18 | Total Steps: 46\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1039/94000  | Episode Reward: 8  | Average Reward 9.04  | Actor loss: -0.14 | Critic loss: 2.88 | Entropy loss: -0.0020  | Total Loss: 2.74 | Total Steps: 53\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1040/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.00 | Critic loss: 1.65 | Entropy loss: -0.0000  | Total Loss: 1.65 | Total Steps: 31\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1041/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: 0.05 | Critic loss: 4.95 | Entropy loss: -0.0004  | Total Loss: 5.01 | Total Steps: 31\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1042/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: -0.09 | Critic loss: 5.42 | Entropy loss: -0.0025  | Total Loss: 5.33 | Total Steps: 49\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1043/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: -0.22 | Critic loss: 4.75 | Entropy loss: -0.0039  | Total Loss: 4.52 | Total Steps: 50\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1044/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: 0.08 | Critic loss: 0.26 | Entropy loss: -0.0003  | Total Loss: 0.34 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1045/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1046/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: 0.00 | Critic loss: 0.26 | Entropy loss: -0.0000  | Total Loss: 0.26 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1047/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: -0.01 | Critic loss: 0.30 | Entropy loss: -0.0013  | Total Loss: 0.29 | Total Steps: 12\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1048/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: 0.00 | Critic loss: 3.67 | Entropy loss: -0.0000  | Total Loss: 3.67 | Total Steps: 29\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1049/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: 0.04 | Critic loss: 0.03 | Entropy loss: -0.0004  | Total Loss: 0.07 | Total Steps: 8\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1050/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: 0.02 | Critic loss: 3.52 | Entropy loss: -0.0000  | Total Loss: 3.54 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1051/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: 0.02 | Critic loss: 1.03 | Entropy loss: -0.0003  | Total Loss: 1.04 | Total Steps: 31\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1052/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: 0.07 | Critic loss: 1.49 | Entropy loss: -0.0005  | Total Loss: 1.57 | Total Steps: 12\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1053/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0000  | Total Loss: 0.10 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1054/94000  | Episode Reward: 8  | Average Reward 9.27  | Actor loss: -0.67 | Critic loss: 4.92 | Entropy loss: -0.0060  | Total Loss: 4.25 | Total Steps: 49\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1055/94000  | Episode Reward: 10  | Average Reward 9.27  | Actor loss: 0.24 | Critic loss: 0.24 | Entropy loss: -0.0009  | Total Loss: 0.48 | Total Steps: 7\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1056/94000  | Episode Reward: 10  | Average Reward 9.29  | Actor loss: 1.16 | Critic loss: 2.29 | Entropy loss: -0.0021  | Total Loss: 3.44 | Total Steps: 9\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1057/94000  | Episode Reward: 10  | Average Reward 9.29  | Actor loss: -0.27 | Critic loss: 6.30 | Entropy loss: -0.0031  | Total Loss: 6.02 | Total Steps: 98\n",
      "\n",
      "---black cylinder---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 1058/94000  | Episode Reward: -10  | Average Reward 9.09  | Actor loss: -0.00 | Critic loss: 3.93 | Entropy loss: -0.0001  | Total Loss: 3.93 | Total Steps: 500\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1059/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.00 | Critic loss: 0.33 | Entropy loss: -0.0000  | Total Loss: 0.34 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1060/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.13 | Critic loss: 1.28 | Entropy loss: -0.0007  | Total Loss: 1.40 | Total Steps: 12\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1061/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1062/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: -0.05 | Critic loss: 4.97 | Entropy loss: -0.0019  | Total Loss: 4.92 | Total Steps: 43\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1063/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1064/94000  | Episode Reward: 8  | Average Reward 9.14  | Actor loss: 0.08 | Critic loss: 1.82 | Entropy loss: -0.0020  | Total Loss: 1.90 | Total Steps: 29\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1065/94000  | Episode Reward: 10  | Average Reward 9.14  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1066/94000  | Episode Reward: 2  | Average Reward 9.09  | Actor loss: -0.45 | Critic loss: 9.86 | Entropy loss: -0.0016  | Total Loss: 9.41 | Total Steps: 50\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1067/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: -1.14 | Critic loss: 5.45 | Entropy loss: -0.0136  | Total Loss: 4.29 | Total Steps: 84\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1068/94000  | Episode Reward: 8  | Average Reward 9.06  | Actor loss: 0.02 | Critic loss: 6.47 | Entropy loss: -0.0015  | Total Loss: 6.48 | Total Steps: 45\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1069/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: 0.05 | Critic loss: 0.43 | Entropy loss: -0.0001  | Total Loss: 0.47 | Total Steps: 8\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1070/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: -0.03 | Critic loss: 2.16 | Entropy loss: -0.0026  | Total Loss: 2.13 | Total Steps: 52\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1071/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0000  | Total Loss: 0.10 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1072/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: 0.04 | Critic loss: 0.09 | Entropy loss: -0.0008  | Total Loss: 0.13 | Total Steps: 7\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1073/94000  | Episode Reward: 8  | Average Reward 9.06  | Actor loss: 0.01 | Critic loss: 6.06 | Entropy loss: -0.0004  | Total Loss: 6.07 | Total Steps: 45\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1074/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: 0.02 | Critic loss: 3.11 | Entropy loss: -0.0001  | Total Loss: 3.13 | Total Steps: 31\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1075/94000  | Episode Reward: 8  | Average Reward 9.04  | Actor loss: 0.02 | Critic loss: 0.85 | Entropy loss: -0.0002  | Total Loss: 0.87 | Total Steps: 38\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1076/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0000  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1077/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: 0.11 | Critic loss: 0.04 | Entropy loss: -0.0012  | Total Loss: 0.16 | Total Steps: 7\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1078/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: 0.00 | Critic loss: 1.64 | Entropy loss: -0.0000  | Total Loss: 1.64 | Total Steps: 31\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1079/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: 0.00 | Critic loss: 3.72 | Entropy loss: -0.0000  | Total Loss: 3.73 | Total Steps: 29\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1080/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: -0.64 | Critic loss: 2.06 | Entropy loss: -0.0020  | Total Loss: 1.41 | Total Steps: 36\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1081/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: 0.01 | Critic loss: 0.15 | Entropy loss: -0.0000  | Total Loss: 0.16 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1082/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1083/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: 0.00 | Critic loss: 0.51 | Entropy loss: -0.0000  | Total Loss: 0.51 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1084/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: 0.01 | Critic loss: 0.02 | Entropy loss: -0.0004  | Total Loss: 0.03 | Total Steps: 8\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1085/94000  | Episode Reward: 8  | Average Reward 9.06  | Actor loss: -0.40 | Critic loss: 4.05 | Entropy loss: -0.0021  | Total Loss: 3.65 | Total Steps: 53\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1086/94000  | Episode Reward: 8  | Average Reward 9.04  | Actor loss: -0.10 | Critic loss: 1.11 | Entropy loss: -0.0013  | Total Loss: 1.02 | Total Steps: 34\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1087/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 1088/94000  | Episode Reward: -10  | Average Reward 8.84  | Actor loss: -0.00 | Critic loss: 4.70 | Entropy loss: -0.0000  | Total Loss: 4.70 | Total Steps: 500\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1089/94000  | Episode Reward: 10  | Average Reward 8.84  | Actor loss: -0.05 | Critic loss: 0.61 | Entropy loss: -0.0010  | Total Loss: 0.57 | Total Steps: 50\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1090/94000  | Episode Reward: 10  | Average Reward 8.84  | Actor loss: 0.00 | Critic loss: 0.38 | Entropy loss: -0.0000  | Total Loss: 0.38 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1091/94000  | Episode Reward: 8  | Average Reward 8.84  | Actor loss: 0.00 | Critic loss: 0.46 | Entropy loss: -0.0000  | Total Loss: 0.46 | Total Steps: 38\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1092/94000  | Episode Reward: 8  | Average Reward 8.81  | Actor loss: -0.00 | Critic loss: 0.85 | Entropy loss: -0.0016  | Total Loss: 0.85 | Total Steps: 46\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1093/94000  | Episode Reward: 10  | Average Reward 8.84  | Actor loss: -0.19 | Critic loss: 5.04 | Entropy loss: -0.0038  | Total Loss: 4.85 | Total Steps: 65\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1094/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: -0.00 | Critic loss: 3.10 | Entropy loss: -0.0001  | Total Loss: 3.10 | Total Steps: 29\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1095/94000  | Episode Reward: 10  | Average Reward 8.89  | Actor loss: 0.00 | Critic loss: 0.35 | Entropy loss: -0.0000  | Total Loss: 0.35 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1096/94000  | Episode Reward: 8  | Average Reward 8.87  | Actor loss: 0.00 | Critic loss: 0.36 | Entropy loss: -0.0001  | Total Loss: 0.37 | Total Steps: 38\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1097/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: -0.11 | Critic loss: 0.26 | Entropy loss: -0.0033  | Total Loss: 0.14 | Total Steps: 9\n",
      "\n",
      "---black capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1098/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: 0.01 | Critic loss: 1.16 | Entropy loss: -0.0001  | Total Loss: 1.16 | Total Steps: 38\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1099/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0000  | Total Loss: 0.11 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1100/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1101/94000  | Episode Reward: 10  | Average Reward 8.89  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 10  | Average Reward 6.96  | Actor loss: 0.02 | Critic loss: 2.28 | Entropy loss: -0.0296  | Total Loss: 2.27 | Total Steps: 45\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 10  | Average Reward 6.98  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0053  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 3/100  | Episode Reward: 10  | Average Reward 7.00  | Actor loss: 0.30 | Critic loss: 2.37 | Entropy loss: -0.0247  | Total Loss: 2.65 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 5  | Average Reward 7.05  | Actor loss: -0.00 | Critic loss: 0.13 | Entropy loss: -0.0101  | Total Loss: 0.11 | Total Steps: 47\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 10  | Average Reward 7.05  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0251  | Total Loss: -0.02 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 5  | Average Reward 7.05  | Actor loss: 0.00 | Critic loss: 0.58 | Entropy loss: -0.0348  | Total Loss: 0.55 | Total Steps: 47\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: 10  | Average Reward 7.08  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0186  | Total Loss: 0.15 | Total Steps: 25\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 10  | Average Reward 7.11  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0008  | Total Loss: 0.15 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 8  | Average Reward 7.08  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0030  | Total Loss: 0.02 | Total Steps: 34\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 10  | Average Reward 7.11  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0463  | Total Loss: -0.01 | Total Steps: 12\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 5  | Average Reward 7.05  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0038  | Total Loss: 0.02 | Total Steps: 137\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 10  | Average Reward 7.08  | Actor loss: 0.00 | Critic loss: 0.63 | Entropy loss: -0.0311  | Total Loss: 0.60 | Total Steps: 26\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 10  | Average Reward 7.11  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0101  | Total Loss: -0.01 | Total Steps: 11\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: 10  | Average Reward 7.16  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0004  | Total Loss: 0.03 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 10  | Average Reward 7.16  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0116  | Total Loss: 0.07 | Total Steps: 10\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 10  | Average Reward 7.23  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0016  | Total Loss: 0.15 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 8  | Average Reward 7.21  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0115  | Total Loss: 0.19 | Total Steps: 43\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 5  | Average Reward 7.18  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0026  | Total Loss: 0.02 | Total Steps: 147\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 10  | Average Reward 7.18  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0011  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: 8  | Average Reward 7.16  | Actor loss: 0.00 | Critic loss: 0.49 | Entropy loss: -0.0005  | Total Loss: 0.49 | Total Steps: 29\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 10  | Average Reward 7.16  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0002  | Total Loss: 0.11 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 22/100  | Episode Reward: 8  | Average Reward 7.13  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0006  | Total Loss: 0.11 | Total Steps: 38\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 10  | Average Reward 7.13  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0073  | Total Loss: 0.02 | Total Steps: 14\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 8  | Average Reward 7.11  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0089  | Total Loss: -0.01 | Total Steps: 56\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 25/100  | Episode Reward: -10  | Average Reward 6.91  | Actor loss: -0.00 | Critic loss: 75.39 | Entropy loss: -0.0019  | Total Loss: 75.38 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 10  | Average Reward 6.96  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0294  | Total Loss: 0.08 | Total Steps: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 8  | Average Reward 6.93  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0013  | Total Loss: 0.23 | Total Steps: 34\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 6  | Average Reward 6.92  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0513  | Total Loss: 0.13 | Total Steps: 139\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 10  | Average Reward 6.96  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0092  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 10  | Average Reward 6.99  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0017  | Total Loss: 0.08 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 10  | Average Reward 7.01  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0004  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 32/100  | Episode Reward: 10  | Average Reward 7.04  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0002  | Total Loss: 0.10 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 33/100  | Episode Reward: -10  | Average Reward 6.87  | Actor loss: -0.00 | Critic loss: 82.00 | Entropy loss: -0.0003  | Total Loss: 82.00 | Total Steps: 500\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 34/100  | Episode Reward: 10  | Average Reward 6.87  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0002  | Total Loss: 0.10 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 35/100  | Episode Reward: 10  | Average Reward 6.89  | Actor loss: 0.01 | Critic loss: 6.82 | Entropy loss: -0.0478  | Total Loss: 6.77 | Total Steps: 7\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 36/100  | Episode Reward: 8  | Average Reward 7.07  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0017  | Total Loss: 0.00 | Total Steps: 38\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 37/100  | Episode Reward: 10  | Average Reward 7.26  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0452  | Total Loss: 0.01 | Total Steps: 9\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: 10  | Average Reward 7.26  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0590  | Total Loss: -0.03 | Total Steps: 14\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 10  | Average Reward 7.26  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0020  | Total Loss: 0.02 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 10  | Average Reward 7.26  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0005  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 10  | Average Reward 7.26  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0004  | Total Loss: 0.02 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 10  | Average Reward 7.29  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0354  | Total Loss: -0.03 | Total Steps: 7\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 43/100  | Episode Reward: 8  | Average Reward 7.26  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0014  | Total Loss: 0.00 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 8  | Average Reward 7.24  | Actor loss: 0.00 | Critic loss: 0.25 | Entropy loss: -0.0269  | Total Loss: 0.22 | Total Steps: 22\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: 10  | Average Reward 7.38  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0010  | Total Loss: 0.13 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 10  | Average Reward 7.41  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0003  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 10  | Average Reward 7.41  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0142  | Total Loss: -0.01 | Total Steps: 40\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 10  | Average Reward 7.41  | Actor loss: 0.01 | Critic loss: 0.01 | Entropy loss: -0.0239  | Total Loss: -0.01 | Total Steps: 11\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 10  | Average Reward 7.41  | Actor loss: 0.00 | Critic loss: 0.86 | Entropy loss: -0.0165  | Total Loss: 0.85 | Total Steps: 23\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 10  | Average Reward 7.41  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0029  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 10  | Average Reward 7.43  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0006  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 10  | Average Reward 7.45  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0182  | Total Loss: -0.02 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 53/100  | Episode Reward: 8  | Average Reward 7.62  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0075  | Total Loss: 0.12 | Total Steps: 68\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 54/100  | Episode Reward: 10  | Average Reward 7.63  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0003  | Total Loss: 0.01 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 10  | Average Reward 7.63  | Actor loss: 0.04 | Critic loss: 2.92 | Entropy loss: -0.0307  | Total Loss: 2.93 | Total Steps: 10\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: 10  | Average Reward 7.63  | Actor loss: 0.00 | Critic loss: 0.45 | Entropy loss: -0.0537  | Total Loss: 0.39 | Total Steps: 43\n",
      "TEST: ---yellow prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 10  | Average Reward 7.63  | Actor loss: 0.00 | Critic loss: 1.34 | Entropy loss: -0.0270  | Total Loss: 1.31 | Total Steps: 46\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 10  | Average Reward 7.63  | Actor loss: -0.00 | Critic loss: 0.18 | Entropy loss: -0.0149  | Total Loss: 0.17 | Total Steps: 12\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 10  | Average Reward 7.68  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0333  | Total Loss: -0.00 | Total Steps: 7\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 60/100  | Episode Reward: 10  | Average Reward 7.73  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0057  | Total Loss: -0.01 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 61/100  | Episode Reward: 10  | Average Reward 7.73  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0003  | Total Loss: 0.06 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 2  | Average Reward 7.68  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0209  | Total Loss: 0.01 | Total Steps: 58\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: 10  | Average Reward 7.73  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0008  | Total Loss: 0.06 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 64/100  | Episode Reward: 10  | Average Reward 7.73  | Actor loss: 3.72 | Critic loss: 10.25 | Entropy loss: -0.0234  | Total Loss: 13.94 | Total Steps: 14\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 65/100  | Episode Reward: 10  | Average Reward 7.73  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0009  | Total Loss: 0.04 | Total Steps: 36\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 8  | Average Reward 7.71  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0005  | Total Loss: 0.13 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 5  | Average Reward 7.68  | Actor loss: 0.00 | Critic loss: 0.43 | Entropy loss: -0.0008  | Total Loss: 0.43 | Total Steps: 42\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 68/100  | Episode Reward: 10  | Average Reward 7.88  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0379  | Total Loss: -0.01 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 10  | Average Reward 7.93  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0126  | Total Loss: 0.06 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 70/100  | Episode Reward: 10  | Average Reward 7.93  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0023  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 5  | Average Reward 7.88  | Actor loss: 0.00 | Critic loss: 0.42 | Entropy loss: -0.0069  | Total Loss: 0.41 | Total Steps: 106\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 10  | Average Reward 7.88  | Actor loss: 0.00 | Critic loss: 0.71 | Entropy loss: -0.0052  | Total Loss: 0.70 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 8  | Average Reward 7.86  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0075  | Total Loss: -0.01 | Total Steps: 51\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: 10  | Average Reward 8.57  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0018  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0005  | Total Loss: 0.03 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0001  | Total Loss: 0.03 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 77/100  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.38 | Critic loss: 10.37 | Entropy loss: -0.0331  | Total Loss: 10.72 | Total Steps: 66\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0246  | Total Loss: 0.00 | Total Steps: 10\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 8  | Average Reward 8.60  | Actor loss: 0.00 | Critic loss: 0.26 | Entropy loss: -0.0012  | Total Loss: 0.26 | Total Steps: 29\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0157  | Total Loss: 0.00 | Total Steps: 44\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0027  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0002  | Total Loss: 0.17 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0188  | Total Loss: -0.00 | Total Steps: 12\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 84/100  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 0.36 | Entropy loss: -0.0332  | Total Loss: 0.33 | Total Steps: 8\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 85/100  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0573  | Total Loss: 0.01 | Total Steps: 7\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: 5  | Average Reward 8.62  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0037  | Total Loss: -0.00 | Total Steps: 136\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 1.26 | Critic loss: 6.49 | Entropy loss: -0.0129  | Total Loss: 7.73 | Total Steps: 7\n",
      "TEST: ---black sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 5  | Average Reward 8.62  | Actor loss: 0.01 | Critic loss: 0.11 | Entropy loss: -0.0010  | Total Loss: 0.11 | Total Steps: 47\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 89/100  | Episode Reward: 10  | Average Reward 8.63  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0001  | Total Loss: 0.06 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 90/100  | Episode Reward: 10  | Average Reward 8.66  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0109  | Total Loss: -0.01 | Total Steps: 11\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 10  | Average Reward 8.66  | Actor loss: 0.02 | Critic loss: 0.10 | Entropy loss: -0.0144  | Total Loss: 0.10 | Total Steps: 55\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 8  | Average Reward 8.63  | Actor loss: -0.00 | Critic loss: 0.10 | Entropy loss: -0.0099  | Total Loss: 0.09 | Total Steps: 39\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: 10  | Average Reward 8.63  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0022  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 8  | Average Reward 8.63  | Actor loss: 0.00 | Critic loss: 0.26 | Entropy loss: -0.0010  | Total Loss: 0.26 | Total Steps: 29\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: 5  | Average Reward 8.59  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0207  | Total Loss: -0.01 | Total Steps: 51\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 10  | Average Reward 8.59  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0008  | Total Loss: 0.01 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 10  | Average Reward 8.63  | Actor loss: 0.29 | Critic loss: 2.34 | Entropy loss: -0.0240  | Total Loss: 2.61 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: 10  | Average Reward 8.63  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0042  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 99/100  | Episode Reward: -12  | Average Reward 8.41  | Actor loss: -0.00 | Critic loss: 102.33 | Entropy loss: -0.0006  | Total Loss: 102.32 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 10  | Average Reward 8.44  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0601  | Total Loss: -0.06 | Total Steps: 7\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1102/94000  | Episode Reward: 10  | Average Reward 8.91  | Actor loss: 0.05 | Critic loss: 0.40 | Entropy loss: -0.0005  | Total Loss: 0.45 | Total Steps: 40\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1103/94000  | Episode Reward: 5  | Average Reward 8.87  | Actor loss: -0.14 | Critic loss: 4.16 | Entropy loss: -0.0017  | Total Loss: 4.02 | Total Steps: 53\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1104/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: -0.15 | Critic loss: 2.90 | Entropy loss: -0.0004  | Total Loss: 2.76 | Total Steps: 31\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1105/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: 0.00 | Critic loss: 1.60 | Entropy loss: -0.0000  | Total Loss: 1.61 | Total Steps: 31\n",
      "\n",
      "---red cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1106/94000  | Episode Reward: 8  | Average Reward 8.84  | Actor loss: -0.70 | Critic loss: 6.20 | Entropy loss: -0.0029  | Total Loss: 5.51 | Total Steps: 57\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1107/94000  | Episode Reward: 10  | Average Reward 8.84  | Actor loss: -0.56 | Critic loss: 5.99 | Entropy loss: -0.0028  | Total Loss: 5.42 | Total Steps: 57\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1108/94000  | Episode Reward: 10  | Average Reward 8.84  | Actor loss: 0.22 | Critic loss: 0.44 | Entropy loss: -0.0013  | Total Loss: 0.66 | Total Steps: 12\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1109/94000  | Episode Reward: 10  | Average Reward 8.84  | Actor loss: 0.00 | Critic loss: 0.63 | Entropy loss: -0.0001  | Total Loss: 0.63 | Total Steps: 38\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1110/94000  | Episode Reward: 10  | Average Reward 8.84  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1111/94000  | Episode Reward: 10  | Average Reward 8.84  | Actor loss: -0.01 | Critic loss: 3.17 | Entropy loss: -0.0020  | Total Loss: 3.15 | Total Steps: 59\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1112/94000  | Episode Reward: 10  | Average Reward 8.84  | Actor loss: -0.04 | Critic loss: 3.07 | Entropy loss: -0.0008  | Total Loss: 3.03 | Total Steps: 42\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1113/94000  | Episode Reward: 8  | Average Reward 8.81  | Actor loss: -0.00 | Critic loss: 2.04 | Entropy loss: -0.0000  | Total Loss: 2.04 | Total Steps: 49\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1114/94000  | Episode Reward: 10  | Average Reward 8.81  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0000  | Total Loss: 0.11 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1115/94000  | Episode Reward: 10  | Average Reward 8.81  | Actor loss: -0.74 | Critic loss: 6.08 | Entropy loss: -0.0136  | Total Loss: 5.33 | Total Steps: 93\n",
      "\n",
      "---blue sphere---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 1116/94000  | Episode Reward: -10  | Average Reward 8.62  | Actor loss: -0.00 | Critic loss: 3.57 | Entropy loss: -0.0001  | Total Loss: 3.56 | Total Steps: 500\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1117/94000  | Episode Reward: 10  | Average Reward 8.69  | Actor loss: -0.18 | Critic loss: 2.41 | Entropy loss: -0.0007  | Total Loss: 2.23 | Total Steps: 41\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1118/94000  | Episode Reward: 10  | Average Reward 8.69  | Actor loss: 0.20 | Critic loss: 0.82 | Entropy loss: -0.0004  | Total Loss: 1.02 | Total Steps: 8\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1119/94000  | Episode Reward: 6  | Average Reward 8.65  | Actor loss: -0.69 | Critic loss: 3.16 | Entropy loss: -0.0049  | Total Loss: 2.47 | Total Steps: 49\n",
      "\n",
      "---green sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1120/94000  | Episode Reward: 8  | Average Reward 8.63  | Actor loss: 0.00 | Critic loss: 0.49 | Entropy loss: -0.0001  | Total Loss: 0.49 | Total Steps: 38\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1121/94000  | Episode Reward: 10  | Average Reward 8.63  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0000  | Total Loss: 0.11 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1122/94000  | Episode Reward: 10  | Average Reward 8.63  | Actor loss: -1.26 | Critic loss: 5.04 | Entropy loss: -0.0048  | Total Loss: 3.78 | Total Steps: 28\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1123/94000  | Episode Reward: 10  | Average Reward 8.63  | Actor loss: 0.01 | Critic loss: 0.08 | Entropy loss: -0.0001  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1124/94000  | Episode Reward: 10  | Average Reward 8.63  | Actor loss: -0.33 | Critic loss: 3.87 | Entropy loss: -0.0100  | Total Loss: 3.54 | Total Steps: 89\n",
      "\n",
      "---green capsule---\n",
      "Step: 250\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1125/94000  | Episode Reward: 6  | Average Reward 8.60  | Actor loss: 0.03 | Critic loss: 0.79 | Entropy loss: -0.0071  | Total Loss: 0.81 | Total Steps: 429\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1126/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0000  | Total Loss: 0.19 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1127/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.05 | Critic loss: 0.73 | Entropy loss: -0.0003  | Total Loss: 0.78 | Total Steps: 40\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1128/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.10 | Critic loss: 0.38 | Entropy loss: -0.0003  | Total Loss: 0.48 | Total Steps: 8\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1129/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.21 | Critic loss: 0.56 | Entropy loss: -0.0006  | Total Loss: 0.77 | Total Steps: 9\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1130/94000  | Episode Reward: 10  | Average Reward 8.71  | Actor loss: -0.04 | Critic loss: 0.07 | Entropy loss: -0.0026  | Total Loss: 0.03 | Total Steps: 8\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1131/94000  | Episode Reward: 10  | Average Reward 8.71  | Actor loss: -0.01 | Critic loss: 2.11 | Entropy loss: -0.0008  | Total Loss: 2.09 | Total Steps: 48\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1132/94000  | Episode Reward: 8  | Average Reward 8.73  | Actor loss: 0.01 | Critic loss: 0.60 | Entropy loss: -0.0001  | Total Loss: 0.60 | Total Steps: 38\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1133/94000  | Episode Reward: 10  | Average Reward 8.73  | Actor loss: 0.00 | Critic loss: 0.24 | Entropy loss: -0.0000  | Total Loss: 0.25 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1134/94000  | Episode Reward: 10  | Average Reward 8.76  | Actor loss: 0.11 | Critic loss: 0.92 | Entropy loss: -0.0012  | Total Loss: 1.03 | Total Steps: 40\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1135/94000  | Episode Reward: 10  | Average Reward 8.76  | Actor loss: 0.00 | Critic loss: 1.79 | Entropy loss: -0.0000  | Total Loss: 1.79 | Total Steps: 31\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1136/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: 0.44 | Critic loss: 0.53 | Entropy loss: -0.0012  | Total Loss: 0.97 | Total Steps: 8\n",
      "\n",
      "---black prism---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 1137/94000  | Episode Reward: -10  | Average Reward 8.61  | Actor loss: -0.00 | Critic loss: 3.01 | Entropy loss: -0.0001  | Total Loss: 3.01 | Total Steps: 500\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1138/94000  | Episode Reward: 10  | Average Reward 8.63  | Actor loss: 0.09 | Critic loss: 0.03 | Entropy loss: -0.0005  | Total Loss: 0.12 | Total Steps: 8\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1139/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.03 | Critic loss: 3.38 | Entropy loss: -0.0011  | Total Loss: 3.41 | Total Steps: 29\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -1.0\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1140/94000  | Episode Reward: 9  | Average Reward 8.64  | Actor loss: 0.64 | Critic loss: 3.91 | Entropy loss: -0.0037  | Total Loss: 4.55 | Total Steps: 31\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1141/94000  | Episode Reward: 10  | Average Reward 8.64  | Actor loss: 0.12 | Critic loss: 0.15 | Entropy loss: -0.0018  | Total Loss: 0.26 | Total Steps: 8\n",
      "\n",
      "---red cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1142/94000  | Episode Reward: 8  | Average Reward 8.62  | Actor loss: -0.26 | Critic loss: 0.51 | Entropy loss: -0.0039  | Total Loss: 0.25 | Total Steps: 40\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1143/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.08 | Critic loss: 1.91 | Entropy loss: -0.0002  | Total Loss: 1.99 | Total Steps: 12\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1144/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: -0.03 | Critic loss: 3.61 | Entropy loss: -0.0004  | Total Loss: 3.57 | Total Steps: 44\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1145/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: -0.00 | Critic loss: 2.80 | Entropy loss: -0.0009  | Total Loss: 2.80 | Total Steps: 45\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1146/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: -0.12 | Critic loss: 0.64 | Entropy loss: -0.0012  | Total Loss: 0.52 | Total Steps: 11\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1147/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.06 | Critic loss: 2.34 | Entropy loss: -0.0030  | Total Loss: 2.39 | Total Steps: 53\n",
      "\n",
      "---red sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1148/94000  | Episode Reward: 8  | Average Reward 8.60  | Actor loss: 0.04 | Critic loss: 6.61 | Entropy loss: -0.0005  | Total Loss: 6.65 | Total Steps: 32\n",
      "\n",
      "---black capsule---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 1149/94000  | Episode Reward: -10  | Average Reward 8.39  | Actor loss: -0.02 | Critic loss: 2.67 | Entropy loss: -0.0034  | Total Loss: 2.64 | Total Steps: 500\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1150/94000  | Episode Reward: 8  | Average Reward 8.37  | Actor loss: 0.17 | Critic loss: 2.64 | Entropy loss: -0.0028  | Total Loss: 2.80 | Total Steps: 47\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1151/94000  | Episode Reward: 5  | Average Reward 8.32  | Actor loss: 0.00 | Critic loss: 4.93 | Entropy loss: -0.0003  | Total Loss: 4.93 | Total Steps: 49\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1152/94000  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: 0.01 | Critic loss: 1.08 | Entropy loss: -0.0000  | Total Loss: 1.09 | Total Steps: 6\n",
      "\n",
      "---black cube---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1153/94000  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: -0.12 | Critic loss: 1.43 | Entropy loss: -0.0024  | Total Loss: 1.30 | Total Steps: 49\n",
      "\n",
      "---yellow sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1154/94000  | Episode Reward: 8  | Average Reward 8.32  | Actor loss: -1.47 | Critic loss: 6.97 | Entropy loss: -0.0185  | Total Loss: 5.49 | Total Steps: 110\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1155/94000  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: -0.03 | Critic loss: 1.45 | Entropy loss: -0.0033  | Total Loss: 1.41 | Total Steps: 41\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1156/94000  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: -0.08 | Critic loss: 0.97 | Entropy loss: -0.0010  | Total Loss: 0.89 | Total Steps: 22\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1157/94000  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: 0.00 | Critic loss: 3.59 | Entropy loss: -0.0000  | Total Loss: 3.59 | Total Steps: 31\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1158/94000  | Episode Reward: 10  | Average Reward 8.52  | Actor loss: 0.29 | Critic loss: 0.69 | Entropy loss: -0.0015  | Total Loss: 0.98 | Total Steps: 12\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1159/94000  | Episode Reward: 10  | Average Reward 8.52  | Actor loss: 0.06 | Critic loss: 0.26 | Entropy loss: -0.0013  | Total Loss: 0.32 | Total Steps: 14\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1160/94000  | Episode Reward: 10  | Average Reward 8.52  | Actor loss: 0.00 | Critic loss: 0.49 | Entropy loss: -0.0030  | Total Loss: 0.49 | Total Steps: 246\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1161/94000  | Episode Reward: 10  | Average Reward 8.52  | Actor loss: -0.26 | Critic loss: 3.74 | Entropy loss: -0.0048  | Total Loss: 3.48 | Total Steps: 68\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1162/94000  | Episode Reward: 10  | Average Reward 8.52  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0000  | Total Loss: 0.15 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1163/94000  | Episode Reward: 10  | Average Reward 8.52  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0000  | Total Loss: 0.23 | Total Steps: 6\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1164/94000  | Episode Reward: 10  | Average Reward 8.54  | Actor loss: 0.11 | Critic loss: 0.17 | Entropy loss: -0.0005  | Total Loss: 0.28 | Total Steps: 8\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1165/94000  | Episode Reward: 5  | Average Reward 8.49  | Actor loss: -0.05 | Critic loss: 2.46 | Entropy loss: -0.0008  | Total Loss: 2.40 | Total Steps: 43\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1166/94000  | Episode Reward: 8  | Average Reward 8.54  | Actor loss: 0.01 | Critic loss: 0.71 | Entropy loss: -0.0001  | Total Loss: 0.72 | Total Steps: 38\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1167/94000  | Episode Reward: 10  | Average Reward 8.54  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0000  | Total Loss: 0.12 | Total Steps: 6\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1168/94000  | Episode Reward: 10  | Average Reward 8.57  | Actor loss: 0.02 | Critic loss: 0.20 | Entropy loss: -0.0011  | Total Loss: 0.22 | Total Steps: 12\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1169/94000  | Episode Reward: 10  | Average Reward 8.57  | Actor loss: -0.64 | Critic loss: 4.53 | Entropy loss: -0.0050  | Total Loss: 3.88 | Total Steps: 34\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1170/94000  | Episode Reward: 10  | Average Reward 8.57  | Actor loss: 0.01 | Critic loss: 0.01 | Entropy loss: -0.0004  | Total Loss: 0.02 | Total Steps: 8\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1171/94000  | Episode Reward: 10  | Average Reward 8.57  | Actor loss: 0.00 | Critic loss: 4.12 | Entropy loss: -0.0000  | Total Loss: 4.13 | Total Steps: 31\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1172/94000  | Episode Reward: 10  | Average Reward 8.57  | Actor loss: -0.07 | Critic loss: 0.19 | Entropy loss: -0.0009  | Total Loss: 0.13 | Total Steps: 14\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1173/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.00 | Critic loss: 2.61 | Entropy loss: -0.0000  | Total Loss: 2.61 | Total Steps: 31\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1174/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: -0.52 | Critic loss: 5.59 | Entropy loss: -0.0032  | Total Loss: 5.06 | Total Steps: 55\n",
      "\n",
      "---black cube---\n",
      "Step: 250\n",
      "Decision Step reward: -2.5\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 1175/94000  | Episode Reward: -12  | Average Reward 8.39  | Actor loss: -0.11 | Critic loss: 5.46 | Entropy loss: -0.0016  | Total Loss: 5.35 | Total Steps: 500\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1176/94000  | Episode Reward: 10  | Average Reward 8.39  | Actor loss: 0.01 | Critic loss: 1.49 | Entropy loss: -0.0001  | Total Loss: 1.50 | Total Steps: 31\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1177/94000  | Episode Reward: 10  | Average Reward 8.39  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0000  | Total Loss: 0.18 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1178/94000  | Episode Reward: 10  | Average Reward 8.39  | Actor loss: 0.00 | Critic loss: 0.35 | Entropy loss: -0.0000  | Total Loss: 0.35 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1179/94000  | Episode Reward: 10  | Average Reward 8.39  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1180/94000  | Episode Reward: 10  | Average Reward 8.39  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1181/94000  | Episode Reward: 8  | Average Reward 8.37  | Actor loss: -0.18 | Critic loss: 5.22 | Entropy loss: -0.0021  | Total Loss: 5.04 | Total Steps: 56\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1182/94000  | Episode Reward: 10  | Average Reward 8.37  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1183/94000  | Episode Reward: 10  | Average Reward 8.37  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1184/94000  | Episode Reward: 10  | Average Reward 8.37  | Actor loss: 0.07 | Critic loss: 1.21 | Entropy loss: -0.0046  | Total Loss: 1.27 | Total Steps: 84\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1185/94000  | Episode Reward: 10  | Average Reward 8.39  | Actor loss: 0.00 | Critic loss: 2.65 | Entropy loss: -0.0000  | Total Loss: 2.65 | Total Steps: 31\n",
      "\n",
      "---yellow cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1186/94000  | Episode Reward: 10  | Average Reward 8.42  | Actor loss: -0.12 | Critic loss: 1.67 | Entropy loss: -0.0024  | Total Loss: 1.55 | Total Steps: 33\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1187/94000  | Episode Reward: 8  | Average Reward 8.39  | Actor loss: -0.08 | Critic loss: 2.31 | Entropy loss: -0.0034  | Total Loss: 2.22 | Total Steps: 216\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1188/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: -0.68 | Critic loss: 5.46 | Entropy loss: -0.0050  | Total Loss: 4.77 | Total Steps: 42\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1189/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: -0.46 | Critic loss: 4.68 | Entropy loss: -0.0033  | Total Loss: 4.22 | Total Steps: 64\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1190/94000  | Episode Reward: 8  | Average Reward 8.57  | Actor loss: -0.54 | Critic loss: 2.37 | Entropy loss: -0.0057  | Total Loss: 1.82 | Total Steps: 57\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1191/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.12 | Critic loss: 1.08 | Entropy loss: -0.0038  | Total Loss: 1.20 | Total Steps: 40\n",
      "\n",
      "---yellow cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1192/94000  | Episode Reward: 8  | Average Reward 8.60  | Actor loss: -0.51 | Critic loss: 5.23 | Entropy loss: -0.0022  | Total Loss: 4.72 | Total Steps: 42\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1193/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: -0.79 | Critic loss: 3.60 | Entropy loss: -0.0096  | Total Loss: 2.80 | Total Steps: 62\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1194/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.03 | Critic loss: 1.66 | Entropy loss: -0.0022  | Total Loss: 1.69 | Total Steps: 216\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1195/94000  | Episode Reward: 8  | Average Reward 8.57  | Actor loss: -0.21 | Critic loss: 2.58 | Entropy loss: -0.0012  | Total Loss: 2.37 | Total Steps: 38\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1196/94000  | Episode Reward: 8  | Average Reward 8.57  | Actor loss: -0.07 | Critic loss: 3.03 | Entropy loss: -0.0025  | Total Loss: 2.95 | Total Steps: 59\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1197/94000  | Episode Reward: 10  | Average Reward 8.57  | Actor loss: 0.05 | Critic loss: 0.14 | Entropy loss: -0.0007  | Total Loss: 0.19 | Total Steps: 9\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1198/94000  | Episode Reward: 10  | Average Reward 8.57  | Actor loss: 0.08 | Critic loss: 0.67 | Entropy loss: -0.0010  | Total Loss: 0.75 | Total Steps: 42\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1199/94000  | Episode Reward: 10  | Average Reward 8.57  | Actor loss: 0.07 | Critic loss: 1.62 | Entropy loss: -0.0011  | Total Loss: 1.69 | Total Steps: 7\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1200/94000  | Episode Reward: 10  | Average Reward 8.57  | Actor loss: -0.33 | Critic loss: 5.70 | Entropy loss: -0.0064  | Total Loss: 5.36 | Total Steps: 53\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1201/94000  | Episode Reward: 10  | Average Reward 8.57  | Actor loss: -0.52 | Critic loss: 3.73 | Entropy loss: -0.0137  | Total Loss: 3.20 | Total Steps: 72\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 10  | Average Reward 8.44  | Actor loss: 0.00 | Critic loss: 0.44 | Entropy loss: -0.0394  | Total Loss: 0.40 | Total Steps: 36\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 10  | Average Reward 8.44  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0263  | Total Loss: -0.00 | Total Steps: 11\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 3/100  | Episode Reward: 8  | Average Reward 8.41  | Actor loss: 0.00 | Critic loss: 1.51 | Entropy loss: -0.0008  | Total Loss: 1.51 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: 0.03 | Critic loss: 2.23 | Entropy loss: -0.0679  | Total Loss: 2.19 | Total Steps: 21\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: 0.02 | Critic loss: 0.65 | Entropy loss: -0.0118  | Total Loss: 0.66 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 10  | Average Reward 8.51  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0006  | Total Loss: 0.16 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: 5  | Average Reward 8.46  | Actor loss: 0.00 | Critic loss: 0.66 | Entropy loss: -0.0014  | Total Loss: 0.66 | Total Steps: 49\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: 3.74 | Critic loss: 4.13 | Entropy loss: -0.0359  | Total Loss: 7.84 | Total Steps: 7\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 10  | Average Reward 8.48  | Actor loss: 0.00 | Critic loss: 0.24 | Entropy loss: -0.0302  | Total Loss: 0.21 | Total Steps: 12\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 9  | Average Reward 8.47  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0173  | Total Loss: 0.13 | Total Steps: 59\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 8  | Average Reward 8.51  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0465  | Total Loss: 0.16 | Total Steps: 114\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 10  | Average Reward 8.51  | Actor loss: 0.12 | Critic loss: 1.26 | Entropy loss: -0.0102  | Total Loss: 1.36 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 10  | Average Reward 8.51  | Actor loss: 0.02 | Critic loss: 1.46 | Entropy loss: -0.0029  | Total Loss: 1.48 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 14/100  | Episode Reward: -10  | Average Reward 8.30  | Actor loss: -0.00 | Critic loss: 85.86 | Entropy loss: -0.0019  | Total Loss: 85.86 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 8  | Average Reward 8.28  | Actor loss: 0.00 | Critic loss: 1.45 | Entropy loss: -0.0039  | Total Loss: 1.45 | Total Steps: 38\n",
      "TEST: ---red capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 8  | Average Reward 8.26  | Actor loss: 0.01 | Critic loss: 0.11 | Entropy loss: -0.0178  | Total Loss: 0.10 | Total Steps: 45\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 10  | Average Reward 8.28  | Actor loss: 0.00 | Critic loss: 0.54 | Entropy loss: -0.0008  | Total Loss: 0.55 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 5  | Average Reward 8.28  | Actor loss: 0.02 | Critic loss: 2.33 | Entropy loss: -0.0273  | Total Loss: 2.33 | Total Steps: 50\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 10  | Average Reward 8.28  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0337  | Total Loss: 0.05 | Total Steps: 7\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: 10  | Average Reward 8.30  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0149  | Total Loss: -0.01 | Total Steps: 44\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 10  | Average Reward 8.30  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0333  | Total Loss: 0.14 | Total Steps: 28\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 22/100  | Episode Reward: 5  | Average Reward 8.28  | Actor loss: 0.07 | Critic loss: 15.43 | Entropy loss: -0.0126  | Total Loss: 15.49 | Total Steps: 49\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 10  | Average Reward 8.28  | Actor loss: 1.11 | Critic loss: 1.80 | Entropy loss: -0.0271  | Total Loss: 2.89 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 10  | Average Reward 8.30  | Actor loss: 0.12 | Critic loss: 2.44 | Entropy loss: -0.0106  | Total Loss: 2.54 | Total Steps: 50\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 10  | Average Reward 8.51  | Actor loss: 0.00 | Critic loss: 0.39 | Entropy loss: -0.0139  | Total Loss: 0.37 | Total Steps: 41\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 8  | Average Reward 8.48  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0090  | Total Loss: 0.03 | Total Steps: 44\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 8  | Average Reward 8.48  | Actor loss: 0.01 | Critic loss: 1.22 | Entropy loss: -0.0032  | Total Loss: 1.23 | Total Steps: 48\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 10  | Average Reward 8.52  | Actor loss: 0.00 | Critic loss: 0.31 | Entropy loss: -0.0072  | Total Loss: 0.30 | Total Steps: 9\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 10  | Average Reward 8.52  | Actor loss: 0.07 | Critic loss: 2.66 | Entropy loss: -0.0069  | Total Loss: 2.73 | Total Steps: 54\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 5  | Average Reward 8.47  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0043  | Total Loss: 0.11 | Total Steps: 46\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 5  | Average Reward 8.42  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0245  | Total Loss: -0.02 | Total Steps: 43\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 32/100  | Episode Reward: 8  | Average Reward 8.39  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0039  | Total Loss: 0.03 | Total Steps: 43\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 33/100  | Episode Reward: 5  | Average Reward 8.54  | Actor loss: 0.38 | Critic loss: 1.67 | Entropy loss: -0.0088  | Total Loss: 2.05 | Total Steps: 46\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 34/100  | Episode Reward: 10  | Average Reward 8.54  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0003  | Total Loss: 0.16 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 35/100  | Episode Reward: 10  | Average Reward 8.54  | Actor loss: 0.00 | Critic loss: 0.50 | Entropy loss: -0.0003  | Total Loss: 0.50 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 200\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 36/100  | Episode Reward: 8  | Average Reward 8.54  | Actor loss: 0.00 | Critic loss: 1.66 | Entropy loss: -0.0020  | Total Loss: 1.67 | Total Steps: 215\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 37/100  | Episode Reward: 10  | Average Reward 8.54  | Actor loss: 0.03 | Critic loss: 1.53 | Entropy loss: -0.0057  | Total Loss: 1.56 | Total Steps: 46\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: 8  | Average Reward 8.52  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0025  | Total Loss: 0.12 | Total Steps: 30\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 4  | Average Reward 8.46  | Actor loss: 0.00 | Critic loss: 0.61 | Entropy loss: -0.0557  | Total Loss: 0.55 | Total Steps: 103\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: 0.01 | Critic loss: 0.68 | Entropy loss: -0.0095  | Total Loss: 0.68 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: 0.00 | Critic loss: 0.27 | Entropy loss: -0.0515  | Total Loss: 0.22 | Total Steps: 30\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 5  | Average Reward 8.41  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0018  | Total Loss: 0.01 | Total Steps: 46\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 43/100  | Episode Reward: -11  | Average Reward 8.22  | Actor loss: -0.01 | Critic loss: 62.00 | Entropy loss: -0.0031  | Total Loss: 61.99 | Total Steps: 500\n",
      "TEST: ---blue cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 10  | Average Reward 8.25  | Actor loss: 0.00 | Critic loss: 0.42 | Entropy loss: -0.0013  | Total Loss: 0.42 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: 10  | Average Reward 8.25  | Actor loss: 0.00 | Critic loss: 0.64 | Entropy loss: -0.0004  | Total Loss: 0.64 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 10  | Average Reward 8.25  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0132  | Total Loss: 0.22 | Total Steps: 51\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 10  | Average Reward 8.25  | Actor loss: 0.00 | Critic loss: 0.55 | Entropy loss: -0.1144  | Total Loss: 0.44 | Total Steps: 12\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 8  | Average Reward 8.22  | Actor loss: 0.01 | Critic loss: 1.22 | Entropy loss: -0.0054  | Total Loss: 1.23 | Total Steps: 48\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 5  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0173  | Total Loss: 0.03 | Total Steps: 49\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.01 | Critic loss: 0.95 | Entropy loss: -0.0035  | Total Loss: 0.96 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 0.68 | Entropy loss: -0.0358  | Total Loss: 0.65 | Total Steps: 9\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 5  | Average Reward 8.12  | Actor loss: 0.00 | Critic loss: 0.32 | Entropy loss: -0.0035  | Total Loss: 0.32 | Total Steps: 51\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 53/100  | Episode Reward: 10  | Average Reward 8.15  | Actor loss: 0.01 | Critic loss: 0.67 | Entropy loss: -0.0008  | Total Loss: 0.67 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 54/100  | Episode Reward: -10  | Average Reward 7.95  | Actor loss: -0.00 | Critic loss: 63.82 | Entropy loss: -0.0001  | Total Loss: 63.82 | Total Steps: 500\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 0  | Average Reward 7.85  | Actor loss: 0.01 | Critic loss: 1.95 | Entropy loss: -0.0250  | Total Loss: 1.93 | Total Steps: 77\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: 10  | Average Reward 7.85  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0010  | Total Loss: 0.23 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 10  | Average Reward 7.85  | Actor loss: 1.11 | Critic loss: 1.80 | Entropy loss: -0.0252  | Total Loss: 2.89 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 10  | Average Reward 7.85  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0168  | Total Loss: 0.15 | Total Steps: 49\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 10  | Average Reward 7.85  | Actor loss: 0.27 | Critic loss: 6.25 | Entropy loss: -0.0777  | Total Loss: 6.44 | Total Steps: 23\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 60/100  | Episode Reward: 2  | Average Reward 7.78  | Actor loss: 0.00 | Critic loss: 0.96 | Entropy loss: -0.0092  | Total Loss: 0.96 | Total Steps: 51\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 61/100  | Episode Reward: 10  | Average Reward 7.78  | Actor loss: 0.29 | Critic loss: 5.97 | Entropy loss: -0.0526  | Total Loss: 6.21 | Total Steps: 37\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 10  | Average Reward 7.85  | Actor loss: 0.16 | Critic loss: 2.89 | Entropy loss: -0.0029  | Total Loss: 3.05 | Total Steps: 50\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: 10  | Average Reward 7.85  | Actor loss: 0.00 | Critic loss: 0.36 | Entropy loss: -0.0014  | Total Loss: 0.36 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 64/100  | Episode Reward: 10  | Average Reward 7.85  | Actor loss: 0.09 | Critic loss: 1.48 | Entropy loss: -0.0786  | Total Loss: 1.49 | Total Steps: 10\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 65/100  | Episode Reward: -10  | Average Reward 7.65  | Actor loss: -0.00 | Critic loss: 70.98 | Entropy loss: -0.0002  | Total Loss: 70.98 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 10  | Average Reward 7.67  | Actor loss: 0.00 | Critic loss: 0.25 | Entropy loss: -0.0001  | Total Loss: 0.25 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 8  | Average Reward 7.70  | Actor loss: 0.11 | Critic loss: 6.00 | Entropy loss: -0.0120  | Total Loss: 6.10 | Total Steps: 54\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 68/100  | Episode Reward: 10  | Average Reward 7.70  | Actor loss: 0.00 | Critic loss: 0.88 | Entropy loss: -0.0124  | Total Loss: 0.87 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 8  | Average Reward 7.67  | Actor loss: 0.03 | Critic loss: 1.62 | Entropy loss: -0.0076  | Total Loss: 1.64 | Total Steps: 46\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 70/100  | Episode Reward: 10  | Average Reward 7.67  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0004  | Total Loss: 0.07 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 10  | Average Reward 7.72  | Actor loss: 0.10 | Critic loss: 2.36 | Entropy loss: -0.0125  | Total Loss: 2.44 | Total Steps: 51\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 10  | Average Reward 7.72  | Actor loss: 0.00 | Critic loss: 0.32 | Entropy loss: -0.0021  | Total Loss: 0.33 | Total Steps: 186\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 10  | Average Reward 7.75  | Actor loss: 0.41 | Critic loss: 1.68 | Entropy loss: -0.0229  | Total Loss: 2.07 | Total Steps: 34\n",
      "TEST: ---yellow prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: 10  | Average Reward 7.75  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0505  | Total Loss: 0.15 | Total Steps: 141\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 10  | Average Reward 7.75  | Actor loss: 10.32 | Critic loss: 12.84 | Entropy loss: -0.0887  | Total Loss: 23.07 | Total Steps: 7\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 5  | Average Reward 7.70  | Actor loss: 0.23 | Critic loss: 0.93 | Entropy loss: -0.0092  | Total Loss: 1.14 | Total Steps: 80\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 77/100  | Episode Reward: 8  | Average Reward 7.67  | Actor loss: 0.64 | Critic loss: 8.45 | Entropy loss: -0.0196  | Total Loss: 9.07 | Total Steps: 28\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 10  | Average Reward 7.67  | Actor loss: 0.01 | Critic loss: 0.66 | Entropy loss: -0.0035  | Total Loss: 0.66 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 10  | Average Reward 7.70  | Actor loss: 0.02 | Critic loss: 1.15 | Entropy loss: -0.0019  | Total Loss: 1.17 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 5  | Average Reward 7.65  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0049  | Total Loss: 0.21 | Total Steps: 52\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 8  | Average Reward 7.62  | Actor loss: 0.02 | Critic loss: 2.79 | Entropy loss: -0.0005  | Total Loss: 2.81 | Total Steps: 34\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: 10  | Average Reward 7.62  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0187  | Total Loss: 0.18 | Total Steps: 9\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 10  | Average Reward 7.62  | Actor loss: 0.18 | Critic loss: 4.08 | Entropy loss: -0.0354  | Total Loss: 4.22 | Total Steps: 26\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 84/100  | Episode Reward: 10  | Average Reward 7.62  | Actor loss: 0.01 | Critic loss: 1.31 | Entropy loss: -0.0379  | Total Loss: 1.28 | Total Steps: 9\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 85/100  | Episode Reward: 9  | Average Reward 7.62  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0342  | Total Loss: 0.15 | Total Steps: 46\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: 5  | Average Reward 7.62  | Actor loss: 0.00 | Critic loss: 0.36 | Entropy loss: -0.0060  | Total Loss: 0.36 | Total Steps: 42\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 10  | Average Reward 7.62  | Actor loss: 0.00 | Critic loss: 0.28 | Entropy loss: -0.0469  | Total Loss: 0.24 | Total Steps: 30\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 10  | Average Reward 7.67  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0258  | Total Loss: 0.14 | Total Steps: 12\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 89/100  | Episode Reward: 10  | Average Reward 7.67  | Actor loss: 0.00 | Critic loss: 0.25 | Entropy loss: -0.0127  | Total Loss: 0.24 | Total Steps: 10\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 90/100  | Episode Reward: 10  | Average Reward 7.67  | Actor loss: 0.06 | Critic loss: 0.85 | Entropy loss: -0.0383  | Total Loss: 0.87 | Total Steps: 20\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 10  | Average Reward 7.67  | Actor loss: 0.21 | Critic loss: 4.23 | Entropy loss: -0.0339  | Total Loss: 4.40 | Total Steps: 23\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 8  | Average Reward 7.67  | Actor loss: 0.00 | Critic loss: 0.75 | Entropy loss: -0.0012  | Total Loss: 0.75 | Total Steps: 38\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: 10  | Average Reward 7.67  | Actor loss: 0.00 | Critic loss: 0.64 | Entropy loss: -0.0004  | Total Loss: 0.64 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 10  | Average Reward 7.69  | Actor loss: 0.02 | Critic loss: 1.62 | Entropy loss: -0.0019  | Total Loss: 1.63 | Total Steps: 40\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: 10  | Average Reward 7.74  | Actor loss: 0.01 | Critic loss: 0.68 | Entropy loss: -0.0006  | Total Loss: 0.68 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 8  | Average Reward 7.71  | Actor loss: 0.12 | Critic loss: 4.92 | Entropy loss: -0.0182  | Total Loss: 5.02 | Total Steps: 61\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 8  | Average Reward 7.69  | Actor loss: 0.00 | Critic loss: 1.38 | Entropy loss: -0.0006  | Total Loss: 1.39 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: 10  | Average Reward 7.69  | Actor loss: 0.03 | Critic loss: 1.48 | Entropy loss: -0.0016  | Total Loss: 1.51 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 10  | Average Reward 7.92  | Actor loss: 0.00 | Critic loss: 0.28 | Entropy loss: -0.0083  | Total Loss: 0.28 | Total Steps: 9\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 9  | Average Reward 7.91  | Actor loss: 0.00 | Critic loss: 1.59 | Entropy loss: -0.0489  | Total Loss: 1.55 | Total Steps: 58\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1202/94000  | Episode Reward: 8  | Average Reward 8.54  | Actor loss: -0.57 | Critic loss: 6.82 | Entropy loss: -0.0035  | Total Loss: 6.25 | Total Steps: 64\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1203/94000  | Episode Reward: 8  | Average Reward 8.57  | Actor loss: -0.43 | Critic loss: 6.12 | Entropy loss: -0.0059  | Total Loss: 5.69 | Total Steps: 52\n",
      "\n",
      "---red cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1204/94000  | Episode Reward: 8  | Average Reward 8.54  | Actor loss: 0.00 | Critic loss: 1.60 | Entropy loss: -0.0003  | Total Loss: 1.60 | Total Steps: 50\n",
      "\n",
      "---green capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1205/94000  | Episode Reward: 5  | Average Reward 8.49  | Actor loss: -0.11 | Critic loss: 4.82 | Entropy loss: -0.0009  | Total Loss: 4.71 | Total Steps: 47\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1206/94000  | Episode Reward: 10  | Average Reward 8.52  | Actor loss: 0.02 | Critic loss: 0.36 | Entropy loss: -0.0001  | Total Loss: 0.38 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1207/94000  | Episode Reward: 5  | Average Reward 8.47  | Actor loss: -0.04 | Critic loss: 8.54 | Entropy loss: -0.0002  | Total Loss: 8.50 | Total Steps: 49\n",
      "\n",
      "---blue cube---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 1208/94000  | Episode Reward: -10  | Average Reward 8.27  | Actor loss: -0.11 | Critic loss: 2.89 | Entropy loss: -0.0068  | Total Loss: 2.77 | Total Steps: 500\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1209/94000  | Episode Reward: 8  | Average Reward 8.24  | Actor loss: 0.00 | Critic loss: 0.91 | Entropy loss: -0.0000  | Total Loss: 0.91 | Total Steps: 38\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1210/94000  | Episode Reward: 5  | Average Reward 8.20  | Actor loss: 0.03 | Critic loss: 3.85 | Entropy loss: -0.0052  | Total Loss: 3.88 | Total Steps: 67\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1211/94000  | Episode Reward: 10  | Average Reward 8.20  | Actor loss: 0.21 | Critic loss: 1.70 | Entropy loss: -0.0006  | Total Loss: 1.91 | Total Steps: 7\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1212/94000  | Episode Reward: 10  | Average Reward 8.20  | Actor loss: 0.00 | Critic loss: 0.28 | Entropy loss: -0.0000  | Total Loss: 0.28 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1213/94000  | Episode Reward: 10  | Average Reward 8.22  | Actor loss: 0.02 | Critic loss: 0.19 | Entropy loss: -0.0001  | Total Loss: 0.20 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1214/94000  | Episode Reward: 10  | Average Reward 8.22  | Actor loss: 0.31 | Critic loss: 1.03 | Entropy loss: -0.0017  | Total Loss: 1.33 | Total Steps: 12\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1215/94000  | Episode Reward: 10  | Average Reward 8.22  | Actor loss: 0.00 | Critic loss: 6.06 | Entropy loss: -0.0000  | Total Loss: 6.07 | Total Steps: 31\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1216/94000  | Episode Reward: 10  | Average Reward 8.42  | Actor loss: 0.00 | Critic loss: 0.24 | Entropy loss: -0.0000  | Total Loss: 0.24 | Total Steps: 6\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1217/94000  | Episode Reward: 8  | Average Reward 8.39  | Actor loss: -0.32 | Critic loss: 5.25 | Entropy loss: -0.0017  | Total Loss: 4.93 | Total Steps: 63\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1218/94000  | Episode Reward: 10  | Average Reward 8.39  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0000  | Total Loss: 0.13 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1219/94000  | Episode Reward: 10  | Average Reward 8.43  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0000  | Total Loss: 0.12 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1220/94000  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: 0.00 | Critic loss: 4.62 | Entropy loss: -0.0000  | Total Loss: 4.62 | Total Steps: 31\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1221/94000  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: 0.22 | Critic loss: 0.39 | Entropy loss: -0.0006  | Total Loss: 0.61 | Total Steps: 8\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1222/94000  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: 0.05 | Critic loss: 2.35 | Entropy loss: -0.0002  | Total Loss: 2.39 | Total Steps: 38\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1223/94000  | Episode Reward: 5  | Average Reward 8.40  | Actor loss: -0.07 | Critic loss: 5.42 | Entropy loss: -0.0004  | Total Loss: 5.34 | Total Steps: 49\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1224/94000  | Episode Reward: 10  | Average Reward 8.40  | Actor loss: 0.49 | Critic loss: 1.29 | Entropy loss: -0.0020  | Total Loss: 1.78 | Total Steps: 10\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1225/94000  | Episode Reward: 10  | Average Reward 8.44  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1226/94000  | Episode Reward: 10  | Average Reward 8.44  | Actor loss: 0.01 | Critic loss: 5.77 | Entropy loss: -0.0000  | Total Loss: 5.78 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 1227/94000  | Episode Reward: -10  | Average Reward 8.24  | Actor loss: -0.00 | Critic loss: 2.83 | Entropy loss: -0.0000  | Total Loss: 2.83 | Total Steps: 500\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1228/94000  | Episode Reward: 10  | Average Reward 8.24  | Actor loss: -0.24 | Critic loss: 5.69 | Entropy loss: -0.0009  | Total Loss: 5.45 | Total Steps: 27\n",
      "\n",
      "---red sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1229/94000  | Episode Reward: 8  | Average Reward 8.21  | Actor loss: -0.32 | Critic loss: 9.49 | Entropy loss: -0.0020  | Total Loss: 9.17 | Total Steps: 48\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1230/94000  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.99 | Critic loss: 7.66 | Entropy loss: -0.0038  | Total Loss: 8.65 | Total Steps: 16\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1231/94000  | Episode Reward: 8  | Average Reward 8.19  | Actor loss: -0.21 | Critic loss: 7.32 | Entropy loss: -0.0006  | Total Loss: 7.11 | Total Steps: 39\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1232/94000  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0000  | Total Loss: 0.20 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Decision Step reward: -1.0\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1233/94000  | Episode Reward: 9  | Average Reward 8.21  | Actor loss: -0.85 | Critic loss: 2.58 | Entropy loss: -0.0048  | Total Loss: 1.72 | Total Steps: 38\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1234/94000  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.31 | Critic loss: 1.17 | Entropy loss: -0.0003  | Total Loss: 1.48 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1235/94000  | Episode Reward: 5  | Average Reward 8.15  | Actor loss: -0.35 | Critic loss: 8.18 | Entropy loss: -0.0016  | Total Loss: 7.83 | Total Steps: 60\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1236/94000  | Episode Reward: 10  | Average Reward 8.15  | Actor loss: -0.10 | Critic loss: 3.25 | Entropy loss: -0.0027  | Total Loss: 3.14 | Total Steps: 47\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1237/94000  | Episode Reward: 10  | Average Reward 8.36  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1238/94000  | Episode Reward: 10  | Average Reward 8.36  | Actor loss: 0.01 | Critic loss: 0.24 | Entropy loss: -0.0000  | Total Loss: 0.25 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1239/94000  | Episode Reward: 8  | Average Reward 8.33  | Actor loss: 0.04 | Critic loss: 1.82 | Entropy loss: -0.0004  | Total Loss: 1.87 | Total Steps: 41\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1240/94000  | Episode Reward: 10  | Average Reward 8.34  | Actor loss: 0.15 | Critic loss: 0.71 | Entropy loss: -0.0044  | Total Loss: 0.86 | Total Steps: 42\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1241/94000  | Episode Reward: 10  | Average Reward 8.34  | Actor loss: 0.20 | Critic loss: 0.10 | Entropy loss: -0.0012  | Total Loss: 0.29 | Total Steps: 7\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1242/94000  | Episode Reward: 10  | Average Reward 8.37  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1243/94000  | Episode Reward: 10  | Average Reward 8.37  | Actor loss: -0.54 | Critic loss: 4.55 | Entropy loss: -0.0066  | Total Loss: 4.01 | Total Steps: 66\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1244/94000  | Episode Reward: 10  | Average Reward 8.37  | Actor loss: 0.06 | Critic loss: 1.09 | Entropy loss: -0.0016  | Total Loss: 1.14 | Total Steps: 77\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1245/94000  | Episode Reward: 10  | Average Reward 8.37  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0000  | Total Loss: 0.12 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1246/94000  | Episode Reward: 8  | Average Reward 8.34  | Actor loss: -0.01 | Critic loss: 6.63 | Entropy loss: -0.0011  | Total Loss: 6.62 | Total Steps: 44\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1247/94000  | Episode Reward: 8  | Average Reward 8.31  | Actor loss: -0.04 | Critic loss: 1.16 | Entropy loss: -0.0010  | Total Loss: 1.12 | Total Steps: 50\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1248/94000  | Episode Reward: 10  | Average Reward 8.34  | Actor loss: 0.27 | Critic loss: 0.87 | Entropy loss: -0.0004  | Total Loss: 1.14 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1249/94000  | Episode Reward: 10  | Average Reward 8.54  | Actor loss: -0.09 | Critic loss: 0.07 | Entropy loss: -0.0009  | Total Loss: -0.02 | Total Steps: 9\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1250/94000  | Episode Reward: 10  | Average Reward 8.56  | Actor loss: -0.01 | Critic loss: 0.18 | Entropy loss: -0.0021  | Total Loss: 0.16 | Total Steps: 11\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1251/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.01 | Critic loss: 0.22 | Entropy loss: -0.0000  | Total Loss: 0.24 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1252/94000  | Episode Reward: 2  | Average Reward 8.54  | Actor loss: -1.08 | Critic loss: 12.01 | Entropy loss: -0.0179  | Total Loss: 10.92 | Total Steps: 152\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1253/94000  | Episode Reward: 8  | Average Reward 8.52  | Actor loss: -0.05 | Critic loss: 1.17 | Entropy loss: -0.0013  | Total Loss: 1.13 | Total Steps: 96\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1254/94000  | Episode Reward: 8  | Average Reward 8.52  | Actor loss: 0.00 | Critic loss: 0.41 | Entropy loss: -0.0001  | Total Loss: 0.41 | Total Steps: 38\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1255/94000  | Episode Reward: 10  | Average Reward 8.52  | Actor loss: 0.01 | Critic loss: 0.08 | Entropy loss: -0.0005  | Total Loss: 0.09 | Total Steps: 8\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1256/94000  | Episode Reward: 10  | Average Reward 8.52  | Actor loss: 0.17 | Critic loss: 0.41 | Entropy loss: -0.0007  | Total Loss: 0.58 | Total Steps: 10\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1257/94000  | Episode Reward: 8  | Average Reward 8.49  | Actor loss: 0.06 | Critic loss: 0.50 | Entropy loss: -0.0009  | Total Loss: 0.57 | Total Steps: 38\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1258/94000  | Episode Reward: 10  | Average Reward 8.49  | Actor loss: 0.01 | Critic loss: 0.10 | Entropy loss: -0.0001  | Total Loss: 0.11 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1259/94000  | Episode Reward: 8  | Average Reward 8.46  | Actor loss: -0.16 | Critic loss: 7.35 | Entropy loss: -0.0009  | Total Loss: 7.19 | Total Steps: 46\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1260/94000  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: 0.00 | Critic loss: 0.30 | Entropy loss: -0.0000  | Total Loss: 0.30 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1261/94000  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: -0.16 | Critic loss: 3.47 | Entropy loss: -0.0027  | Total Loss: 3.31 | Total Steps: 56\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1262/94000  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: 0.19 | Critic loss: 2.00 | Entropy loss: -0.0015  | Total Loss: 2.18 | Total Steps: 12\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1263/94000  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0000  | Total Loss: 0.10 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1264/94000  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0000  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1265/94000  | Episode Reward: 10  | Average Reward 8.52  | Actor loss: 0.34 | Critic loss: 2.05 | Entropy loss: -0.0011  | Total Loss: 2.39 | Total Steps: 36\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1266/94000  | Episode Reward: 10  | Average Reward 8.54  | Actor loss: 0.14 | Critic loss: 0.44 | Entropy loss: -0.0003  | Total Loss: 0.58 | Total Steps: 8\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1267/94000  | Episode Reward: 10  | Average Reward 8.54  | Actor loss: -0.13 | Critic loss: 0.05 | Entropy loss: -0.0015  | Total Loss: -0.09 | Total Steps: 7\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1268/94000  | Episode Reward: 10  | Average Reward 8.54  | Actor loss: 0.00 | Critic loss: 2.54 | Entropy loss: -0.0000  | Total Loss: 2.54 | Total Steps: 31\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1269/94000  | Episode Reward: 10  | Average Reward 8.54  | Actor loss: 0.04 | Critic loss: 2.42 | Entropy loss: -0.0005  | Total Loss: 2.45 | Total Steps: 31\n",
      "\n",
      "---red cube---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1270/94000  | Episode Reward: 10  | Average Reward 8.54  | Actor loss: 0.12 | Critic loss: 0.74 | Entropy loss: -0.0011  | Total Loss: 0.86 | Total Steps: 40\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1271/94000  | Episode Reward: 8  | Average Reward 8.52  | Actor loss: 0.01 | Critic loss: 0.33 | Entropy loss: -0.0002  | Total Loss: 0.34 | Total Steps: 38\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1272/94000  | Episode Reward: 10  | Average Reward 8.52  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1273/94000  | Episode Reward: 10  | Average Reward 8.52  | Actor loss: 0.14 | Critic loss: 3.25 | Entropy loss: -0.0005  | Total Loss: 3.39 | Total Steps: 12\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1274/94000  | Episode Reward: 10  | Average Reward 8.52  | Actor loss: -0.03 | Critic loss: 4.98 | Entropy loss: -0.0018  | Total Loss: 4.95 | Total Steps: 34\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1275/94000  | Episode Reward: 8  | Average Reward 8.71  | Actor loss: -0.60 | Critic loss: 6.00 | Entropy loss: -0.0035  | Total Loss: 5.40 | Total Steps: 54\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1276/94000  | Episode Reward: 10  | Average Reward 8.71  | Actor loss: 0.06 | Critic loss: 0.19 | Entropy loss: -0.0006  | Total Loss: 0.25 | Total Steps: 10\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1277/94000  | Episode Reward: 10  | Average Reward 8.71  | Actor loss: 0.06 | Critic loss: 1.39 | Entropy loss: -0.0009  | Total Loss: 1.45 | Total Steps: 30\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1278/94000  | Episode Reward: 10  | Average Reward 8.71  | Actor loss: 0.02 | Critic loss: 0.35 | Entropy loss: -0.0003  | Total Loss: 0.37 | Total Steps: 40\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1279/94000  | Episode Reward: 10  | Average Reward 8.71  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0000  | Total Loss: 0.13 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1280/94000  | Episode Reward: 10  | Average Reward 8.71  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1281/94000  | Episode Reward: 10  | Average Reward 8.74  | Actor loss: -0.10 | Critic loss: 1.95 | Entropy loss: -0.0025  | Total Loss: 1.85 | Total Steps: 51\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1282/94000  | Episode Reward: 10  | Average Reward 8.74  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1283/94000  | Episode Reward: 10  | Average Reward 8.74  | Actor loss: -0.07 | Critic loss: 0.33 | Entropy loss: -0.0008  | Total Loss: 0.25 | Total Steps: 14\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1284/94000  | Episode Reward: 10  | Average Reward 8.74  | Actor loss: 0.00 | Critic loss: 1.14 | Entropy loss: -0.0000  | Total Loss: 1.14 | Total Steps: 31\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1285/94000  | Episode Reward: 10  | Average Reward 8.74  | Actor loss: -0.03 | Critic loss: 0.16 | Entropy loss: -0.0027  | Total Loss: 0.13 | Total Steps: 14\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1286/94000  | Episode Reward: 10  | Average Reward 8.74  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0000  | Total Loss: 0.08 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1287/94000  | Episode Reward: 10  | Average Reward 8.77  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1288/94000  | Episode Reward: 10  | Average Reward 8.77  | Actor loss: -0.01 | Critic loss: 4.95 | Entropy loss: -0.0000  | Total Loss: 4.94 | Total Steps: 42\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1289/94000  | Episode Reward: 10  | Average Reward 8.77  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1290/94000  | Episode Reward: 10  | Average Reward 8.79  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1291/94000  | Episode Reward: 5  | Average Reward 8.74  | Actor loss: -0.36 | Critic loss: 5.29 | Entropy loss: -0.0031  | Total Loss: 4.93 | Total Steps: 60\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1292/94000  | Episode Reward: 10  | Average Reward 8.77  | Actor loss: 0.03 | Critic loss: 4.42 | Entropy loss: -0.0003  | Total Loss: 4.45 | Total Steps: 29\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1293/94000  | Episode Reward: 10  | Average Reward 8.77  | Actor loss: -1.36 | Critic loss: 4.27 | Entropy loss: -0.0086  | Total Loss: 2.91 | Total Steps: 57\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1294/94000  | Episode Reward: 10  | Average Reward 8.77  | Actor loss: 0.00 | Critic loss: 1.80 | Entropy loss: -0.0001  | Total Loss: 1.80 | Total Steps: 31\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1295/94000  | Episode Reward: 8  | Average Reward 8.77  | Actor loss: -0.11 | Critic loss: 2.66 | Entropy loss: -0.0017  | Total Loss: 2.55 | Total Steps: 65\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1296/94000  | Episode Reward: 10  | Average Reward 8.79  | Actor loss: 0.02 | Critic loss: 1.78 | Entropy loss: -0.0001  | Total Loss: 1.80 | Total Steps: 31\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1297/94000  | Episode Reward: 10  | Average Reward 8.79  | Actor loss: -0.27 | Critic loss: 1.43 | Entropy loss: -0.0028  | Total Loss: 1.16 | Total Steps: 42\n",
      "\n",
      "---red sphere---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1298/94000  | Episode Reward: 5  | Average Reward 8.74  | Actor loss: -0.38 | Critic loss: 7.82 | Entropy loss: -0.0021  | Total Loss: 7.44 | Total Steps: 27\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1299/94000  | Episode Reward: 10  | Average Reward 8.74  | Actor loss: 0.56 | Critic loss: 0.29 | Entropy loss: -0.0035  | Total Loss: 0.84 | Total Steps: 10\n",
      "\n",
      "---black capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1300/94000  | Episode Reward: 8  | Average Reward 8.71  | Actor loss: 0.04 | Critic loss: 1.75 | Entropy loss: -0.0021  | Total Loss: 1.78 | Total Steps: 187\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1301/94000  | Episode Reward: 10  | Average Reward 8.71  | Actor loss: -0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 10  | Average Reward 7.91  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0586  | Total Loss: 0.05 | Total Steps: 13\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 10  | Average Reward 7.91  | Actor loss: 0.96 | Critic loss: 3.62 | Entropy loss: -0.0505  | Total Loss: 4.53 | Total Steps: 9\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 3/100  | Episode Reward: 10  | Average Reward 7.93  | Actor loss: 0.00 | Critic loss: 0.27 | Entropy loss: -0.0054  | Total Loss: 0.26 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 8  | Average Reward 7.91  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0007  | Total Loss: 0.07 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 10  | Average Reward 7.91  | Actor loss: 0.01 | Critic loss: 7.50 | Entropy loss: -0.0085  | Total Loss: 7.51 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 10  | Average Reward 7.91  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0342  | Total Loss: -0.02 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 7/100  | Episode Reward: -10  | Average Reward 7.75  | Actor loss: -0.01 | Critic loss: 85.57 | Entropy loss: -0.0001  | Total Loss: 85.56 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: -3  | Average Reward 7.62  | Actor loss: 0.00 | Critic loss: 1.69 | Entropy loss: -0.0565  | Total Loss: 1.64 | Total Steps: 114\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 10  | Average Reward 7.62  | Actor loss: 0.01 | Critic loss: 5.75 | Entropy loss: -0.0232  | Total Loss: 5.73 | Total Steps: 12\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 10  | Average Reward 7.63  | Actor loss: 0.00 | Critic loss: 0.87 | Entropy loss: -0.0146  | Total Loss: 0.86 | Total Steps: 22\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 11/100  | Episode Reward: -10  | Average Reward 7.46  | Actor loss: -0.00 | Critic loss: 77.22 | Entropy loss: -0.0001  | Total Loss: 77.21 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 10  | Average Reward 7.46  | Actor loss: 0.01 | Critic loss: 6.54 | Entropy loss: -0.0523  | Total Loss: 6.49 | Total Steps: 7\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 8  | Average Reward 7.43  | Actor loss: 0.00 | Critic loss: 0.61 | Entropy loss: -0.0136  | Total Loss: 0.60 | Total Steps: 37\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: 5  | Average Reward 7.58  | Actor loss: 0.03 | Critic loss: 0.05 | Entropy loss: -0.0039  | Total Loss: 0.08 | Total Steps: 106\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 0  | Average Reward 7.50  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0061  | Total Loss: 0.01 | Total Steps: 50\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 10  | Average Reward 7.53  | Actor loss: 0.01 | Critic loss: 0.81 | Entropy loss: -0.0674  | Total Loss: 0.75 | Total Steps: 9\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 8  | Average Reward 7.50  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0030  | Total Loss: 0.18 | Total Steps: 34\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 10  | Average Reward 7.55  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0127  | Total Loss: 0.08 | Total Steps: 10\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 8  | Average Reward 7.53  | Actor loss: 0.00 | Critic loss: 2.18 | Entropy loss: -0.0152  | Total Loss: 2.16 | Total Steps: 37\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: 9  | Average Reward 7.52  | Actor loss: 0.08 | Critic loss: 5.73 | Entropy loss: -0.0257  | Total Loss: 5.78 | Total Steps: 40\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 8  | Average Reward 7.50  | Actor loss: 0.03 | Critic loss: 0.15 | Entropy loss: -0.0070  | Total Loss: 0.18 | Total Steps: 35\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 22/100  | Episode Reward: 10  | Average Reward 7.54  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0334  | Total Loss: 0.05 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 5  | Average Reward 7.50  | Actor loss: 0.01 | Critic loss: 0.40 | Entropy loss: -0.0192  | Total Loss: 0.39 | Total Steps: 37\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 5  | Average Reward 7.45  | Actor loss: 0.01 | Critic loss: 0.57 | Entropy loss: -0.0178  | Total Loss: 0.56 | Total Steps: 37\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 10  | Average Reward 7.45  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0031  | Total Loss: 0.15 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 10  | Average Reward 7.47  | Actor loss: 0.01 | Critic loss: 1.26 | Entropy loss: -0.0031  | Total Loss: 1.27 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 5  | Average Reward 7.45  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0136  | Total Loss: -0.01 | Total Steps: 49\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 8  | Average Reward 7.42  | Actor loss: 0.01 | Critic loss: 0.25 | Entropy loss: -0.0088  | Total Loss: 0.24 | Total Steps: 35\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 5  | Average Reward 7.37  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0024  | Total Loss: 0.04 | Total Steps: 226\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 10  | Average Reward 7.42  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0123  | Total Loss: -0.01 | Total Steps: 64\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 8  | Average Reward 7.45  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0008  | Total Loss: 0.04 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 32/100  | Episode Reward: 10  | Average Reward 7.47  | Actor loss: 0.07 | Critic loss: 3.21 | Entropy loss: -0.0364  | Total Loss: 3.24 | Total Steps: 27\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 33/100  | Episode Reward: 10  | Average Reward 7.52  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0146  | Total Loss: 0.14 | Total Steps: 10\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 34/100  | Episode Reward: 10  | Average Reward 7.52  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0241  | Total Loss: -0.02 | Total Steps: 17\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 35/100  | Episode Reward: 10  | Average Reward 7.52  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0049  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 36/100  | Episode Reward: 8  | Average Reward 7.52  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0097  | Total Loss: -0.01 | Total Steps: 67\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 37/100  | Episode Reward: 10  | Average Reward 7.52  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0004  | Total Loss: 0.18 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: 10  | Average Reward 7.54  | Actor loss: 0.00 | Critic loss: 0.26 | Entropy loss: -0.0123  | Total Loss: 0.25 | Total Steps: 12\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 10  | Average Reward 7.61  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0027  | Total Loss: 0.03 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 10  | Average Reward 7.61  | Actor loss: 0.09 | Critic loss: 1.54 | Entropy loss: -0.0308  | Total Loss: 1.60 | Total Steps: 67\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 8  | Average Reward 7.58  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0062  | Total Loss: 0.03 | Total Steps: 30\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 10  | Average Reward 7.63  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0004  | Total Loss: 0.06 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 43/100  | Episode Reward: 8  | Average Reward 7.82  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0004  | Total Loss: 0.16 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 5  | Average Reward 7.76  | Actor loss: 0.01 | Critic loss: 0.03 | Entropy loss: -0.0024  | Total Loss: 0.04 | Total Steps: 46\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: 10  | Average Reward 7.76  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0281  | Total Loss: 0.15 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 8  | Average Reward 7.74  | Actor loss: 0.21 | Critic loss: 0.06 | Entropy loss: -0.0171  | Total Loss: 0.25 | Total Steps: 48\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 10  | Average Reward 7.74  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0034  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 10  | Average Reward 7.76  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0011  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 10  | Average Reward 7.82  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0001  | Total Loss: 0.05 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 10  | Average Reward 7.82  | Actor loss: 0.00 | Critic loss: 1.73 | Entropy loss: -0.0874  | Total Loss: 1.64 | Total Steps: 14\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 10  | Average Reward 7.82  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0548  | Total Loss: 0.04 | Total Steps: 11\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 5  | Average Reward 7.82  | Actor loss: 0.02 | Critic loss: 0.04 | Entropy loss: -0.0054  | Total Loss: 0.06 | Total Steps: 106\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 53/100  | Episode Reward: 10  | Average Reward 7.82  | Actor loss: 0.00 | Critic loss: 0.35 | Entropy loss: -0.0010  | Total Loss: 0.35 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 54/100  | Episode Reward: 8  | Average Reward 7.99  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0032  | Total Loss: 0.00 | Total Steps: 231\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 10  | Average Reward 8.09  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0003  | Total Loss: 0.04 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: 10  | Average Reward 8.09  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0333  | Total Loss: -0.03 | Total Steps: 14\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 10  | Average Reward 8.09  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0013  | Total Loss: 0.00 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 10  | Average Reward 8.09  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0003  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 8  | Average Reward 8.06  | Actor loss: 0.32 | Critic loss: 0.74 | Entropy loss: -0.0124  | Total Loss: 1.05 | Total Steps: 57\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 60/100  | Episode Reward: 10  | Average Reward 8.14  | Actor loss: 0.03 | Critic loss: 3.85 | Entropy loss: -0.0142  | Total Loss: 3.87 | Total Steps: 24\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 61/100  | Episode Reward: 10  | Average Reward 8.14  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0213  | Total Loss: 0.05 | Total Steps: 56\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 8  | Average Reward 8.12  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0018  | Total Loss: 0.18 | Total Steps: 36\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: 2  | Average Reward 8.04  | Actor loss: 0.01 | Critic loss: 0.91 | Entropy loss: -0.0101  | Total Loss: 0.91 | Total Steps: 57\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 64/100  | Episode Reward: 10  | Average Reward 8.04  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0004  | Total Loss: 0.18 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 65/100  | Episode Reward: 10  | Average Reward 8.24  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0003  | Total Loss: 0.02 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 10  | Average Reward 8.24  | Actor loss: 0.01 | Critic loss: 1.94 | Entropy loss: -0.0032  | Total Loss: 1.95 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 5  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.25 | Entropy loss: -0.0006  | Total Loss: 0.25 | Total Steps: 42\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 68/100  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0080  | Total Loss: 0.10 | Total Steps: 9\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 9  | Average Reward 8.23  | Actor loss: 0.01 | Critic loss: 0.24 | Entropy loss: -0.0042  | Total Loss: 0.24 | Total Steps: 275\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 70/100  | Episode Reward: 10  | Average Reward 8.23  | Actor loss: 0.00 | Critic loss: 0.25 | Entropy loss: -0.0167  | Total Loss: 0.23 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 8  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0102  | Total Loss: 0.05 | Total Steps: 46\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0019  | Total Loss: 0.07 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 8  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0048  | Total Loss: 0.00 | Total Steps: 54\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.11 | Critic loss: 3.95 | Entropy loss: -0.0175  | Total Loss: 4.04 | Total Steps: 9\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 0.43 | Entropy loss: -0.0008  | Total Loss: 0.43 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 10  | Average Reward 8.23  | Actor loss: 0.00 | Critic loss: 0.89 | Entropy loss: -0.0647  | Total Loss: 0.83 | Total Steps: 8\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 77/100  | Episode Reward: 10  | Average Reward 8.26  | Actor loss: 0.00 | Critic loss: 0.88 | Entropy loss: -0.0456  | Total Loss: 0.84 | Total Steps: 10\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 10  | Average Reward 8.26  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0562  | Total Loss: -0.01 | Total Steps: 7\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 5  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0089  | Total Loss: 0.09 | Total Steps: 45\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 10  | Average Reward 8.26  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0863  | Total Loss: -0.07 | Total Steps: 7\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 8  | Average Reward 8.26  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0025  | Total Loss: 0.08 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: 5  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.31 | Entropy loss: -0.0032  | Total Loss: 0.31 | Total Steps: 49\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 8  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 0.63 | Entropy loss: -0.0050  | Total Loss: 0.63 | Total Steps: 29\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 84/100  | Episode Reward: 8  | Average Reward 8.15  | Actor loss: 0.05 | Critic loss: 0.68 | Entropy loss: -0.0108  | Total Loss: 0.72 | Total Steps: 86\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 85/100  | Episode Reward: 10  | Average Reward 8.16  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0117  | Total Loss: 0.00 | Total Steps: 34\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: 5  | Average Reward 8.16  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0028  | Total Loss: 0.18 | Total Steps: 42\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 10  | Average Reward 8.16  | Actor loss: 0.00 | Critic loss: 0.34 | Entropy loss: -0.0006  | Total Loss: 0.34 | Total Steps: 6\n",
      "TEST: ---black sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 8  | Average Reward 8.14  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0092  | Total Loss: 0.02 | Total Steps: 30\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 89/100  | Episode Reward: 8  | Average Reward 8.12  | Actor loss: 0.00 | Critic loss: 0.33 | Entropy loss: -0.0007  | Total Loss: 0.33 | Total Steps: 29\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 90/100  | Episode Reward: 9  | Average Reward 8.11  | Actor loss: 0.01 | Critic loss: 1.41 | Entropy loss: -0.0230  | Total Loss: 1.39 | Total Steps: 25\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 10  | Average Reward 8.11  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0043  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 5  | Average Reward 8.08  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0066  | Total Loss: -0.01 | Total Steps: 43\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: 10  | Average Reward 8.08  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0012  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 9  | Average Reward 8.07  | Actor loss: 0.04 | Critic loss: 3.00 | Entropy loss: -0.0256  | Total Loss: 3.02 | Total Steps: 23\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: 10  | Average Reward 8.07  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0044  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 8  | Average Reward 8.07  | Actor loss: 0.03 | Critic loss: 0.11 | Entropy loss: -0.0166  | Total Loss: 0.12 | Total Steps: 30\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 10  | Average Reward 8.10  | Actor loss: 0.10 | Critic loss: 3.73 | Entropy loss: -0.0227  | Total Loss: 3.81 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: 10  | Average Reward 8.10  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0043  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 10  | Average Reward 8.10  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0009  | Total Loss: 0.07 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 10  | Average Reward 8.11  | Actor loss: 0.14 | Critic loss: 0.47 | Entropy loss: -0.0508  | Total Loss: 0.56 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1302/94000  | Episode Reward: 10  | Average Reward 8.74  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0000  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1303/94000  | Episode Reward: 10  | Average Reward 8.77  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1304/94000  | Episode Reward: 8  | Average Reward 8.77  | Actor loss: -1.15 | Critic loss: 4.43 | Entropy loss: -0.0102  | Total Loss: 3.28 | Total Steps: 71\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1305/94000  | Episode Reward: 10  | Average Reward 8.81  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0000  | Total Loss: 0.19 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1306/94000  | Episode Reward: 8  | Average Reward 8.79  | Actor loss: -0.24 | Critic loss: 5.96 | Entropy loss: -0.0005  | Total Loss: 5.72 | Total Steps: 29\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1307/94000  | Episode Reward: 10  | Average Reward 8.84  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0000  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1308/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0000  | Total Loss: 0.13 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1309/94000  | Episode Reward: 8  | Average Reward 9.04  | Actor loss: -0.02 | Critic loss: 6.42 | Entropy loss: -0.0001  | Total Loss: 6.40 | Total Steps: 30\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1310/94000  | Episode Reward: 8  | Average Reward 9.06  | Actor loss: 0.26 | Critic loss: 9.09 | Entropy loss: -0.0009  | Total Loss: 9.35 | Total Steps: 40\n",
      "\n",
      "---yellow capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1311/94000  | Episode Reward: 8  | Average Reward 9.04  | Actor loss: -0.31 | Critic loss: 8.69 | Entropy loss: -0.0014  | Total Loss: 8.38 | Total Steps: 55\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1312/94000  | Episode Reward: 8  | Average Reward 9.02  | Actor loss: -0.27 | Critic loss: 3.00 | Entropy loss: -0.0020  | Total Loss: 2.73 | Total Steps: 50\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1313/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: -0.24 | Critic loss: 3.49 | Entropy loss: -0.0029  | Total Loss: 3.24 | Total Steps: 49\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1314/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: -0.01 | Critic loss: 2.40 | Entropy loss: -0.0050  | Total Loss: 2.39 | Total Steps: 58\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1315/94000  | Episode Reward: 8  | Average Reward 8.99  | Actor loss: -0.17 | Critic loss: 3.84 | Entropy loss: -0.0018  | Total Loss: 3.66 | Total Steps: 43\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1316/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.00 | Critic loss: 0.42 | Entropy loss: -0.0000  | Total Loss: 0.42 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1317/94000  | Episode Reward: 8  | Average Reward 8.99  | Actor loss: 0.05 | Critic loss: 1.04 | Entropy loss: -0.0018  | Total Loss: 1.08 | Total Steps: 44\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1318/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.01 | Critic loss: 1.14 | Entropy loss: -0.0000  | Total Loss: 1.14 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1319/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: -0.20 | Critic loss: 1.77 | Entropy loss: -0.0022  | Total Loss: 1.56 | Total Steps: 37\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1320/94000  | Episode Reward: 8  | Average Reward 8.96  | Actor loss: -0.05 | Critic loss: 1.44 | Entropy loss: -0.0009  | Total Loss: 1.39 | Total Steps: 34\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1321/94000  | Episode Reward: 5  | Average Reward 8.91  | Actor loss: -0.44 | Critic loss: 4.72 | Entropy loss: -0.0022  | Total Loss: 4.28 | Total Steps: 74\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1322/94000  | Episode Reward: 10  | Average Reward 8.91  | Actor loss: 0.29 | Critic loss: 0.76 | Entropy loss: -0.0016  | Total Loss: 1.05 | Total Steps: 10\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1323/94000  | Episode Reward: 8  | Average Reward 8.94  | Actor loss: -0.23 | Critic loss: 1.28 | Entropy loss: -0.0024  | Total Loss: 1.05 | Total Steps: 54\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1324/94000  | Episode Reward: 10  | Average Reward 8.94  | Actor loss: 0.49 | Critic loss: 1.70 | Entropy loss: -0.0011  | Total Loss: 2.18 | Total Steps: 12\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1325/94000  | Episode Reward: 10  | Average Reward 8.94  | Actor loss: -0.02 | Critic loss: 0.99 | Entropy loss: -0.0009  | Total Loss: 0.97 | Total Steps: 12\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1326/94000  | Episode Reward: 8  | Average Reward 8.91  | Actor loss: -0.66 | Critic loss: 4.35 | Entropy loss: -0.0046  | Total Loss: 3.68 | Total Steps: 58\n",
      "\n",
      "---red sphere---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1327/94000  | Episode Reward: 2  | Average Reward 9.04  | Actor loss: -0.85 | Critic loss: 9.61 | Entropy loss: -0.0056  | Total Loss: 8.76 | Total Steps: 56\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1328/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.30 | Critic loss: 1.34 | Entropy loss: -0.0010  | Total Loss: 1.64 | Total Steps: 8\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1329/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: 0.00 | Critic loss: 5.06 | Entropy loss: -0.0000  | Total Loss: 5.06 | Total Steps: 29\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1330/94000  | Episode Reward: 8  | Average Reward 9.04  | Actor loss: -0.39 | Critic loss: 2.27 | Entropy loss: -0.0034  | Total Loss: 1.87 | Total Steps: 55\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1331/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0000  | Total Loss: 0.13 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1332/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: 0.03 | Critic loss: 0.43 | Entropy loss: -0.0001  | Total Loss: 0.46 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1333/94000  | Episode Reward: 8  | Average Reward 9.05  | Actor loss: -0.00 | Critic loss: 0.49 | Entropy loss: -0.0000  | Total Loss: 0.49 | Total Steps: 38\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1334/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: -0.20 | Critic loss: 0.13 | Entropy loss: -0.0019  | Total Loss: -0.07 | Total Steps: 11\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1335/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: 0.27 | Critic loss: 0.93 | Entropy loss: -0.0008  | Total Loss: 1.20 | Total Steps: 13\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1336/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: -0.00 | Critic loss: 4.73 | Entropy loss: -0.0004  | Total Loss: 4.73 | Total Steps: 31\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1337/94000  | Episode Reward: 8  | Average Reward 9.07  | Actor loss: -0.14 | Critic loss: 1.99 | Entropy loss: -0.0040  | Total Loss: 1.84 | Total Steps: 66\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1338/94000  | Episode Reward: 10  | Average Reward 9.07  | Actor loss: 0.00 | Critic loss: 4.52 | Entropy loss: -0.0001  | Total Loss: 4.52 | Total Steps: 31\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1339/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0000  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1340/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1341/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: -0.78 | Critic loss: 4.94 | Entropy loss: -0.0098  | Total Loss: 4.14 | Total Steps: 80\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1342/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: 0.01 | Critic loss: 0.42 | Entropy loss: -0.0001  | Total Loss: 0.43 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1343/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: -0.02 | Critic loss: 1.51 | Entropy loss: -0.0003  | Total Loss: 1.49 | Total Steps: 31\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1344/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: 0.26 | Critic loss: 2.26 | Entropy loss: -0.0019  | Total Loss: 2.51 | Total Steps: 96\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1345/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: -1.77 | Critic loss: 4.79 | Entropy loss: -0.0160  | Total Loss: 3.01 | Total Steps: 77\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1346/94000  | Episode Reward: 8  | Average Reward 9.10  | Actor loss: -0.06 | Critic loss: 6.57 | Entropy loss: -0.0002  | Total Loss: 6.51 | Total Steps: 30\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1347/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.26 | Critic loss: 0.18 | Entropy loss: -0.0024  | Total Loss: 0.43 | Total Steps: 9\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1348/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.01 | Critic loss: 1.40 | Entropy loss: -0.0012  | Total Loss: 1.41 | Total Steps: 36\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1349/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.16 | Critic loss: 0.28 | Entropy loss: -0.0010  | Total Loss: 0.44 | Total Steps: 13\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1350/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.07 | Critic loss: 1.07 | Entropy loss: -0.0010  | Total Loss: 1.15 | Total Steps: 30\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1351/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.27 | Critic loss: 1.10 | Entropy loss: -0.0018  | Total Loss: 1.37 | Total Steps: 12\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1352/94000  | Episode Reward: 5  | Average Reward 9.15  | Actor loss: -0.04 | Critic loss: 10.40 | Entropy loss: -0.0002  | Total Loss: 10.36 | Total Steps: 50\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1353/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: -0.22 | Critic loss: 1.90 | Entropy loss: -0.0056  | Total Loss: 1.67 | Total Steps: 43\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1354/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: -0.39 | Critic loss: 3.94 | Entropy loss: -0.0022  | Total Loss: 3.54 | Total Steps: 57\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1355/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0000  | Total Loss: 0.17 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1356/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: 0.00 | Critic loss: 2.18 | Entropy loss: -0.0000  | Total Loss: 2.19 | Total Steps: 31\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1357/94000  | Episode Reward: 8  | Average Reward 9.20  | Actor loss: 0.00 | Critic loss: 0.38 | Entropy loss: -0.0000  | Total Loss: 0.38 | Total Steps: 38\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1358/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: 0.00 | Critic loss: 1.19 | Entropy loss: -0.0001  | Total Loss: 1.19 | Total Steps: 31\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1359/94000  | Episode Reward: 8  | Average Reward 9.20  | Actor loss: 0.08 | Critic loss: 0.49 | Entropy loss: -0.0011  | Total Loss: 0.56 | Total Steps: 37\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1360/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0000  | Total Loss: 0.13 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1361/94000  | Episode Reward: 8  | Average Reward 9.18  | Actor loss: -0.09 | Critic loss: 1.91 | Entropy loss: -0.0073  | Total Loss: 1.81 | Total Steps: 167\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1362/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0001  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1363/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: -0.29 | Critic loss: 1.60 | Entropy loss: -0.0014  | Total Loss: 1.31 | Total Steps: 34\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1364/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.34 | Critic loss: 1.47 | Entropy loss: -0.0019  | Total Loss: 1.81 | Total Steps: 9\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1365/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1366/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.34 | Critic loss: 0.52 | Entropy loss: -0.0011  | Total Loss: 0.86 | Total Steps: 9\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1367/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.18 | Critic loss: 2.42 | Entropy loss: -0.0029  | Total Loss: 2.60 | Total Steps: 246\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1368/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.00 | Critic loss: 1.95 | Entropy loss: -0.0000  | Total Loss: 1.95 | Total Steps: 31\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1369/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.19 | Critic loss: 0.43 | Entropy loss: -0.0009  | Total Loss: 0.62 | Total Steps: 8\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1370/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0000  | Total Loss: 0.08 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1371/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: -0.02 | Critic loss: 0.96 | Entropy loss: -0.0003  | Total Loss: 0.94 | Total Steps: 30\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1372/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: 0.00 | Critic loss: 1.18 | Entropy loss: -0.0000  | Total Loss: 1.18 | Total Steps: 31\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1373/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: 0.00 | Critic loss: 0.90 | Entropy loss: -0.0001  | Total Loss: 0.90 | Total Steps: 31\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1374/94000  | Episode Reward: 8  | Average Reward 9.18  | Actor loss: -0.12 | Critic loss: 4.44 | Entropy loss: -0.0004  | Total Loss: 4.32 | Total Steps: 49\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1375/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: 0.00 | Critic loss: 1.18 | Entropy loss: -0.0000  | Total Loss: 1.18 | Total Steps: 31\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1376/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: -0.10 | Critic loss: 0.11 | Entropy loss: -0.0010  | Total Loss: 0.01 | Total Steps: 9\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1377/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: 0.06 | Critic loss: 0.27 | Entropy loss: -0.0002  | Total Loss: 0.33 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1378/94000  | Episode Reward: 5  | Average Reward 9.15  | Actor loss: -0.20 | Critic loss: 4.49 | Entropy loss: -0.0035  | Total Loss: 4.28 | Total Steps: 138\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1379/94000  | Episode Reward: 10  | Average Reward 9.15  | Actor loss: -0.52 | Critic loss: 2.77 | Entropy loss: -0.0043  | Total Loss: 2.24 | Total Steps: 39\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1380/94000  | Episode Reward: 8  | Average Reward 9.12  | Actor loss: -0.06 | Critic loss: 0.67 | Entropy loss: -0.0025  | Total Loss: 0.62 | Total Steps: 36\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1381/94000  | Episode Reward: 5  | Average Reward 9.07  | Actor loss: -0.31 | Critic loss: 11.28 | Entropy loss: -0.0011  | Total Loss: 10.96 | Total Steps: 51\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1382/94000  | Episode Reward: 10  | Average Reward 9.07  | Actor loss: -0.55 | Critic loss: 5.28 | Entropy loss: -0.0019  | Total Loss: 4.73 | Total Steps: 30\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1383/94000  | Episode Reward: 8  | Average Reward 9.05  | Actor loss: 0.04 | Critic loss: 0.45 | Entropy loss: -0.0007  | Total Loss: 0.49 | Total Steps: 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1384/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.22 | Critic loss: 0.87 | Entropy loss: -0.0015  | Total Loss: 1.08 | Total Steps: 36\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1385/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.00 | Critic loss: 1.54 | Entropy loss: -0.0000  | Total Loss: 1.54 | Total Steps: 31\n",
      "\n",
      "---blue cube---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 1386/94000  | Episode Reward: -10  | Average Reward 8.85  | Actor loss: -0.00 | Critic loss: 6.43 | Entropy loss: -0.0000  | Total Loss: 6.42 | Total Steps: 500\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1387/94000  | Episode Reward: 8  | Average Reward 8.82  | Actor loss: -0.36 | Critic loss: 3.51 | Entropy loss: -0.0028  | Total Loss: 3.16 | Total Steps: 44\n",
      "\n",
      "---black cylinder---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 1388/94000  | Episode Reward: -10  | Average Reward 8.62  | Actor loss: -0.00 | Critic loss: 2.91 | Entropy loss: -0.0001  | Total Loss: 2.91 | Total Steps: 500\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1389/94000  | Episode Reward: 8  | Average Reward 8.60  | Actor loss: 0.06 | Critic loss: 1.09 | Entropy loss: -0.0014  | Total Loss: 1.15 | Total Steps: 98\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1390/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.18 | Critic loss: 0.07 | Entropy loss: -0.0012  | Total Loss: 0.25 | Total Steps: 7\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1391/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: -0.04 | Critic loss: 0.42 | Entropy loss: -0.0016  | Total Loss: 0.38 | Total Steps: 50\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1392/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.35 | Critic loss: 2.13 | Entropy loss: -0.0015  | Total Loss: 2.47 | Total Steps: 38\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1393/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 0.80 | Entropy loss: -0.0000  | Total Loss: 0.80 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1394/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.02 | Critic loss: 2.35 | Entropy loss: -0.0001  | Total Loss: 2.37 | Total Steps: 31\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1395/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.00 | Critic loss: 2.17 | Entropy loss: -0.0018  | Total Loss: 2.17 | Total Steps: 45\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1396/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: -0.66 | Critic loss: 3.61 | Entropy loss: -0.0081  | Total Loss: 2.94 | Total Steps: 51\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1397/94000  | Episode Reward: 2  | Average Reward 8.60  | Actor loss: -1.35 | Critic loss: 15.28 | Entropy loss: -0.0044  | Total Loss: 13.93 | Total Steps: 52\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1398/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: -0.47 | Critic loss: 5.89 | Entropy loss: -0.0061  | Total Loss: 5.41 | Total Steps: 58\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1399/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: -0.18 | Critic loss: 2.23 | Entropy loss: -0.0083  | Total Loss: 2.05 | Total Steps: 57\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1400/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.11 | Critic loss: 2.58 | Entropy loss: -0.0008  | Total Loss: 2.69 | Total Steps: 31\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1401/94000  | Episode Reward: 8  | Average Reward 8.65  | Actor loss: 0.16 | Critic loss: 0.63 | Entropy loss: -0.0028  | Total Loss: 0.79 | Total Steps: 39\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 10  | Average Reward 8.11  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0213  | Total Loss: 0.15 | Total Steps: 7\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 8  | Average Reward 8.08  | Actor loss: 0.00 | Critic loss: 0.35 | Entropy loss: -0.0015  | Total Loss: 0.35 | Total Steps: 29\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 3/100  | Episode Reward: 8  | Average Reward 8.05  | Actor loss: 0.00 | Critic loss: 0.64 | Entropy loss: -0.0116  | Total Loss: 0.63 | Total Steps: 65\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: -2  | Average Reward 7.96  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0087  | Total Loss: 0.14 | Total Steps: 50\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 10  | Average Reward 7.96  | Actor loss: 0.00 | Critic loss: 0.29 | Entropy loss: -0.0083  | Total Loss: 0.28 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 10  | Average Reward 7.96  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0005  | Total Loss: 0.02 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: 10  | Average Reward 8.15  | Actor loss: 0.01 | Critic loss: 0.88 | Entropy loss: -0.0403  | Total Loss: 0.85 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 10  | Average Reward 8.29  | Actor loss: 0.00 | Critic loss: 0.37 | Entropy loss: -0.0060  | Total Loss: 0.37 | Total Steps: 29\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 10  | Average Reward 8.29  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0015  | Total Loss: 0.06 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 8  | Average Reward 8.26  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0093  | Total Loss: -0.01 | Total Steps: 30\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 5  | Average Reward 8.41  | Actor loss: 0.04 | Critic loss: 0.17 | Entropy loss: -0.0120  | Total Loss: 0.20 | Total Steps: 46\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 8  | Average Reward 8.38  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0220  | Total Loss: -0.02 | Total Steps: 47\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 10  | Average Reward 8.41  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0038  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---black sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0011  | Total Loss: 0.06 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 2  | Average Reward 8.48  | Actor loss: 0.13 | Critic loss: 5.35 | Entropy loss: -0.0074  | Total Loss: 5.47 | Total Steps: 65\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 10  | Average Reward 8.48  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0027  | Total Loss: 0.20 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 6  | Average Reward 8.47  | Actor loss: 1.07 | Critic loss: 0.62 | Entropy loss: -0.0452  | Total Loss: 1.65 | Total Steps: 52\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 10  | Average Reward 8.47  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0077  | Total Loss: 0.22 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 10  | Average Reward 8.50  | Actor loss: 0.00 | Critic loss: 0.57 | Entropy loss: -0.0014  | Total Loss: 0.57 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: 8  | Average Reward 8.48  | Actor loss: 0.00 | Critic loss: 0.82 | Entropy loss: -0.0027  | Total Loss: 0.81 | Total Steps: 29\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 10  | Average Reward 8.51  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0349  | Total Loss: 0.13 | Total Steps: 10\n",
      "TEST: ---green cube---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 22/100  | Episode Reward: -10  | Average Reward 8.31  | Actor loss: -0.01 | Critic loss: 83.61 | Entropy loss: -0.0001  | Total Loss: 83.60 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 8  | Average Reward 8.34  | Actor loss: 0.02 | Critic loss: 2.49 | Entropy loss: -0.0242  | Total Loss: 2.49 | Total Steps: 23\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0043  | Total Loss: 0.10 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 9  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0347  | Total Loss: 0.01 | Total Steps: 111\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 0.72 | Entropy loss: -0.0081  | Total Loss: 0.71 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 10  | Average Reward 8.43  | Actor loss: 0.01 | Critic loss: 0.07 | Entropy loss: -0.0093  | Total Loss: 0.07 | Total Steps: 39\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 10  | Average Reward 8.45  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0189  | Total Loss: 0.07 | Total Steps: 40\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 10  | Average Reward 8.50  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0009  | Total Loss: 0.02 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 10  | Average Reward 8.50  | Actor loss: 0.00 | Critic loss: 0.22 | Entropy loss: -0.0344  | Total Loss: 0.19 | Total Steps: 7\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 10  | Average Reward 8.53  | Actor loss: 0.00 | Critic loss: 0.61 | Entropy loss: -0.0031  | Total Loss: 0.61 | Total Steps: 50\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 32/100  | Episode Reward: -12  | Average Reward 8.30  | Actor loss: -0.00 | Critic loss: 98.69 | Entropy loss: -0.0001  | Total Loss: 98.68 | Total Steps: 500\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 33/100  | Episode Reward: 10  | Average Reward 8.30  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0003  | Total Loss: 0.06 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 34/100  | Episode Reward: 10  | Average Reward 8.30  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0002  | Total Loss: 0.13 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 35/100  | Episode Reward: 10  | Average Reward 8.30  | Actor loss: 0.00 | Critic loss: 0.27 | Entropy loss: -0.0339  | Total Loss: 0.24 | Total Steps: 9\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 36/100  | Episode Reward: 5  | Average Reward 8.28  | Actor loss: 0.00 | Critic loss: 0.44 | Entropy loss: -0.0112  | Total Loss: 0.43 | Total Steps: 47\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 37/100  | Episode Reward: 10  | Average Reward 8.28  | Actor loss: 0.00 | Critic loss: 26.45 | Entropy loss: -0.1074  | Total Loss: 26.34 | Total Steps: 9\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: 10  | Average Reward 8.28  | Actor loss: 0.00 | Critic loss: 0.78 | Entropy loss: -0.0547  | Total Loss: 0.73 | Total Steps: 8\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 8  | Average Reward 8.25  | Actor loss: 0.00 | Critic loss: 0.91 | Entropy loss: -0.0083  | Total Loss: 0.90 | Total Steps: 36\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 10  | Average Reward 8.25  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0299  | Total Loss: 0.01 | Total Steps: 9\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 10  | Average Reward 8.28  | Actor loss: 0.03 | Critic loss: 3.73 | Entropy loss: -0.0161  | Total Loss: 3.75 | Total Steps: 9\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 10  | Average Reward 8.28  | Actor loss: 0.01 | Critic loss: 1.02 | Entropy loss: -0.0052  | Total Loss: 1.03 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 43/100  | Episode Reward: 0  | Average Reward 8.20  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0190  | Total Loss: 0.05 | Total Steps: 38\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 8  | Average Reward 8.22  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0110  | Total Loss: 0.11 | Total Steps: 53\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: 10  | Average Reward 8.22  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0014  | Total Loss: 0.14 | Total Steps: 36\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 10  | Average Reward 8.25  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0002  | Total Loss: 0.13 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 10  | Average Reward 8.25  | Actor loss: 0.01 | Critic loss: 0.66 | Entropy loss: -0.0329  | Total Loss: 0.63 | Total Steps: 7\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 8  | Average Reward 8.22  | Actor loss: 0.00 | Critic loss: 0.44 | Entropy loss: -0.0115  | Total Loss: 0.43 | Total Steps: 29\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 10  | Average Reward 8.22  | Actor loss: 0.00 | Critic loss: 0.40 | Entropy loss: -0.0153  | Total Loss: 0.39 | Total Steps: 57\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: -4  | Average Reward 8.09  | Actor loss: 0.13 | Critic loss: 6.82 | Entropy loss: -0.0486  | Total Loss: 6.90 | Total Steps: 191\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 10  | Average Reward 8.09  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0082  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 8  | Average Reward 8.11  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0008  | Total Loss: 0.15 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 53/100  | Episode Reward: 5  | Average Reward 8.06  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0106  | Total Loss: 0.00 | Total Steps: 50\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 54/100  | Episode Reward: 10  | Average Reward 8.09  | Actor loss: 0.31 | Critic loss: 0.95 | Entropy loss: -0.0086  | Total Loss: 1.25 | Total Steps: 37\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 10  | Average Reward 8.09  | Actor loss: 0.01 | Critic loss: 0.34 | Entropy loss: -0.0026  | Total Loss: 0.36 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: 10  | Average Reward 8.09  | Actor loss: 0.01 | Critic loss: 4.50 | Entropy loss: -0.0225  | Total Loss: 4.49 | Total Steps: 13\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 8  | Average Reward 8.06  | Actor loss: 0.00 | Critic loss: 0.27 | Entropy loss: -0.0008  | Total Loss: 0.27 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 8  | Average Reward 8.04  | Actor loss: 0.02 | Critic loss: 4.93 | Entropy loss: -0.0526  | Total Loss: 4.89 | Total Steps: 54\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 2  | Average Reward 7.99  | Actor loss: 0.13 | Critic loss: 5.35 | Entropy loss: -0.0082  | Total Loss: 5.47 | Total Steps: 65\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 60/100  | Episode Reward: 10  | Average Reward 7.99  | Actor loss: 0.00 | Critic loss: 0.57 | Entropy loss: -0.0015  | Total Loss: 0.57 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 61/100  | Episode Reward: 10  | Average Reward 7.99  | Actor loss: 0.01 | Critic loss: 2.49 | Entropy loss: -0.0035  | Total Loss: 2.50 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 10  | Average Reward 8.02  | Actor loss: 0.11 | Critic loss: 3.89 | Entropy loss: -0.0446  | Total Loss: 3.95 | Total Steps: 27\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: 10  | Average Reward 8.09  | Actor loss: 2.30 | Critic loss: 9.40 | Entropy loss: -0.0377  | Total Loss: 11.66 | Total Steps: 7\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 64/100  | Episode Reward: 8  | Average Reward 8.06  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0166  | Total Loss: -0.02 | Total Steps: 57\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 65/100  | Episode Reward: 10  | Average Reward 8.06  | Actor loss: 0.04 | Critic loss: 0.91 | Entropy loss: -0.0528  | Total Loss: 0.89 | Total Steps: 8\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 8  | Average Reward 8.04  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0016  | Total Loss: 0.21 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 10  | Average Reward 8.09  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0002  | Total Loss: 0.16 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 68/100  | Episode Reward: -10  | Average Reward 7.89  | Actor loss: -0.01 | Critic loss: 82.07 | Entropy loss: -0.0001  | Total Loss: 82.06 | Total Steps: 500\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 10  | Average Reward 7.90  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0221  | Total Loss: -0.02 | Total Steps: 46\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 70/100  | Episode Reward: 10  | Average Reward 7.90  | Actor loss: 0.01 | Critic loss: 0.84 | Entropy loss: -0.0493  | Total Loss: 0.80 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 10  | Average Reward 7.92  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0018  | Total Loss: 0.12 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 10  | Average Reward 7.92  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0008  | Total Loss: 0.12 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 10  | Average Reward 7.95  | Actor loss: 0.00 | Critic loss: 0.87 | Entropy loss: -0.0508  | Total Loss: 0.82 | Total Steps: 32\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: 10  | Average Reward 7.95  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0111  | Total Loss: 0.08 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 10  | Average Reward 7.95  | Actor loss: 0.00 | Critic loss: 1.12 | Entropy loss: -0.0563  | Total Loss: 1.07 | Total Steps: 11\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 10  | Average Reward 7.95  | Actor loss: 0.01 | Critic loss: 2.70 | Entropy loss: -0.0129  | Total Loss: 2.69 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 77/100  | Episode Reward: 8  | Average Reward 7.92  | Actor loss: 0.00 | Critic loss: 0.55 | Entropy loss: -0.0021  | Total Loss: 0.54 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 8  | Average Reward 7.90  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0094  | Total Loss: -0.01 | Total Steps: 30\n",
      "TEST: ---red capsule---\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 10  | Average Reward 7.95  | Actor loss: 0.01 | Critic loss: 0.12 | Entropy loss: -0.0024  | Total Loss: 0.12 | Total Steps: 186\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 10  | Average Reward 7.95  | Actor loss: 0.02 | Critic loss: 1.80 | Entropy loss: -0.0299  | Total Loss: 1.79 | Total Steps: 14\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 10  | Average Reward 7.97  | Actor loss: 0.00 | Critic loss: 0.55 | Entropy loss: -0.0052  | Total Loss: 0.54 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: 8  | Average Reward 8.00  | Actor loss: 0.00 | Critic loss: 0.65 | Entropy loss: -0.0136  | Total Loss: 0.64 | Total Steps: 35\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 5  | Average Reward 7.97  | Actor loss: 0.01 | Critic loss: 1.88 | Entropy loss: -0.0069  | Total Loss: 1.88 | Total Steps: 47\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 84/100  | Episode Reward: 10  | Average Reward 8.00  | Actor loss: 0.01 | Critic loss: 1.03 | Entropy loss: -0.0037  | Total Loss: 1.03 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 85/100  | Episode Reward: 8  | Average Reward 7.97  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0003  | Total Loss: 0.21 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: -11  | Average Reward 7.82  | Actor loss: 0.01 | Critic loss: 2.11 | Entropy loss: -0.0494  | Total Loss: 2.06 | Total Steps: 211\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 5  | Average Reward 7.76  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0085  | Total Loss: 0.07 | Total Steps: 47\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 10  | Average Reward 7.79  | Actor loss: 0.09 | Critic loss: 4.86 | Entropy loss: -0.0197  | Total Loss: 4.93 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 89/100  | Episode Reward: -10  | Average Reward 7.62  | Actor loss: -0.01 | Critic loss: 79.37 | Entropy loss: -0.0001  | Total Loss: 79.37 | Total Steps: 500\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 90/100  | Episode Reward: 10  | Average Reward 7.62  | Actor loss: 2.21 | Critic loss: 2.99 | Entropy loss: -0.0121  | Total Loss: 5.19 | Total Steps: 39\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 8  | Average Reward 7.60  | Actor loss: 0.00 | Critic loss: 0.29 | Entropy loss: -0.0006  | Total Loss: 0.29 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 8  | Average Reward 7.62  | Actor loss: 0.00 | Critic loss: 0.80 | Entropy loss: -0.0010  | Total Loss: 0.80 | Total Steps: 29\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: 8  | Average Reward 7.60  | Actor loss: 0.01 | Critic loss: 0.61 | Entropy loss: -0.0028  | Total Loss: 0.62 | Total Steps: 335\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 10  | Average Reward 7.61  | Actor loss: 0.00 | Critic loss: 0.33 | Entropy loss: -0.0293  | Total Loss: 0.30 | Total Steps: 35\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: 10  | Average Reward 7.61  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0030  | Total Loss: 0.14 | Total Steps: 40\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 9  | Average Reward 7.62  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0345  | Total Loss: 0.03 | Total Steps: 27\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 8  | Average Reward 7.60  | Actor loss: 0.04 | Critic loss: 2.61 | Entropy loss: -0.0146  | Total Loss: 2.64 | Total Steps: 34\n",
      "TEST: ---blue cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: 8  | Average Reward 7.58  | Actor loss: 0.00 | Critic loss: 0.50 | Entropy loss: -0.0017  | Total Loss: 0.50 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 10  | Average Reward 7.58  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0006  | Total Loss: 0.09 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 100/100  | Episode Reward: -10  | Average Reward 7.38  | Actor loss: -0.00 | Critic loss: 85.87 | Entropy loss: -0.0000  | Total Loss: 85.86 | Total Steps: 500\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1402/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0000  | Total Loss: 0.10 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1403/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.02 | Critic loss: 0.59 | Entropy loss: -0.0004  | Total Loss: 0.61 | Total Steps: 40\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1404/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: -1.21 | Critic loss: 5.86 | Entropy loss: -0.0073  | Total Loss: 4.65 | Total Steps: 53\n",
      "\n",
      "---black cube---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 1405/94000  | Episode Reward: -10  | Average Reward 8.47  | Actor loss: -0.00 | Critic loss: 4.84 | Entropy loss: -0.0001  | Total Loss: 4.84 | Total Steps: 500\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1406/94000  | Episode Reward: 10  | Average Reward 8.50  | Actor loss: 0.00 | Critic loss: 3.13 | Entropy loss: -0.0000  | Total Loss: 3.14 | Total Steps: 31\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1407/94000  | Episode Reward: 5  | Average Reward 8.45  | Actor loss: -0.55 | Critic loss: 6.48 | Entropy loss: -0.0050  | Total Loss: 5.93 | Total Steps: 47\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1408/94000  | Episode Reward: 10  | Average Reward 8.45  | Actor loss: 0.00 | Critic loss: 0.22 | Entropy loss: -0.0000  | Total Loss: 0.22 | Total Steps: 6\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1409/94000  | Episode Reward: 8  | Average Reward 8.45  | Actor loss: -0.12 | Critic loss: 5.59 | Entropy loss: -0.0014  | Total Loss: 5.47 | Total Steps: 39\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1410/94000  | Episode Reward: 10  | Average Reward 8.47  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0000  | Total Loss: 0.18 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1411/94000  | Episode Reward: 10  | Average Reward 8.50  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0000  | Total Loss: 0.15 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1412/94000  | Episode Reward: 5  | Average Reward 8.47  | Actor loss: -0.15 | Critic loss: 1.72 | Entropy loss: -0.0018  | Total Loss: 1.57 | Total Steps: 77\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1413/94000  | Episode Reward: 10  | Average Reward 8.47  | Actor loss: 0.14 | Critic loss: 0.48 | Entropy loss: -0.0004  | Total Loss: 0.61 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1414/94000  | Episode Reward: 10  | Average Reward 8.47  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1415/94000  | Episode Reward: 8  | Average Reward 8.47  | Actor loss: -0.04 | Critic loss: 1.96 | Entropy loss: -0.0004  | Total Loss: 1.92 | Total Steps: 30\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1416/94000  | Episode Reward: 10  | Average Reward 8.47  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1417/94000  | Episode Reward: 8  | Average Reward 8.47  | Actor loss: -0.16 | Critic loss: 5.75 | Entropy loss: -0.0011  | Total Loss: 5.59 | Total Steps: 43\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1418/94000  | Episode Reward: 10  | Average Reward 8.47  | Actor loss: 0.06 | Critic loss: 4.55 | Entropy loss: -0.0006  | Total Loss: 4.62 | Total Steps: 31\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1419/94000  | Episode Reward: 10  | Average Reward 8.47  | Actor loss: 0.25 | Critic loss: 1.03 | Entropy loss: -0.0005  | Total Loss: 1.28 | Total Steps: 11\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1420/94000  | Episode Reward: 10  | Average Reward 8.50  | Actor loss: 0.00 | Critic loss: 2.54 | Entropy loss: -0.0000  | Total Loss: 2.54 | Total Steps: 31\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1421/94000  | Episode Reward: 10  | Average Reward 8.55  | Actor loss: 0.15 | Critic loss: 4.80 | Entropy loss: -0.0009  | Total Loss: 4.95 | Total Steps: 29\n",
      "\n",
      "---red cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1422/94000  | Episode Reward: 8  | Average Reward 8.53  | Actor loss: -0.01 | Critic loss: 2.15 | Entropy loss: -0.0001  | Total Loss: 2.14 | Total Steps: 39\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1423/94000  | Episode Reward: 8  | Average Reward 8.53  | Actor loss: 0.00 | Critic loss: 2.38 | Entropy loss: -0.0016  | Total Loss: 2.38 | Total Steps: 55\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1424/94000  | Episode Reward: 10  | Average Reward 8.53  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0000  | Total Loss: 0.15 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1425/94000  | Episode Reward: 10  | Average Reward 8.53  | Actor loss: -0.17 | Critic loss: 6.17 | Entropy loss: -0.0018  | Total Loss: 5.99 | Total Steps: 48\n",
      "\n",
      "---red sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1426/94000  | Episode Reward: 8  | Average Reward 8.53  | Actor loss: -0.05 | Critic loss: 1.25 | Entropy loss: -0.0009  | Total Loss: 1.20 | Total Steps: 67\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1427/94000  | Episode Reward: 8  | Average Reward 8.57  | Actor loss: 0.22 | Critic loss: 1.33 | Entropy loss: -0.0091  | Total Loss: 1.54 | Total Steps: 97\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1428/94000  | Episode Reward: 10  | Average Reward 8.57  | Actor loss: 0.02 | Critic loss: 1.57 | Entropy loss: -0.0001  | Total Loss: 1.60 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1429/94000  | Episode Reward: 10  | Average Reward 8.57  | Actor loss: -0.13 | Critic loss: 0.02 | Entropy loss: -0.0020  | Total Loss: -0.11 | Total Steps: 7\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1430/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.01 | Critic loss: 0.66 | Entropy loss: -0.0004  | Total Loss: 0.68 | Total Steps: 40\n",
      "\n",
      "---black cube---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1431/94000  | Episode Reward: 8  | Average Reward 8.57  | Actor loss: 0.03 | Critic loss: 1.00 | Entropy loss: -0.0026  | Total Loss: 1.03 | Total Steps: 125\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1432/94000  | Episode Reward: 10  | Average Reward 8.57  | Actor loss: 0.24 | Critic loss: 0.23 | Entropy loss: -0.0015  | Total Loss: 0.48 | Total Steps: 8\n",
      "\n",
      "---black capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1433/94000  | Episode Reward: 8  | Average Reward 8.57  | Actor loss: -0.06 | Critic loss: 2.56 | Entropy loss: -0.0010  | Total Loss: 2.50 | Total Steps: 36\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1434/94000  | Episode Reward: 10  | Average Reward 8.57  | Actor loss: 0.03 | Critic loss: 0.68 | Entropy loss: -0.0002  | Total Loss: 0.71 | Total Steps: 12\n",
      "\n",
      "---black cylinder---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 1435/94000  | Episode Reward: -10  | Average Reward 8.38  | Actor loss: -0.00 | Critic loss: 3.36 | Entropy loss: -0.0001  | Total Loss: 3.35 | Total Steps: 500\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1436/94000  | Episode Reward: 5  | Average Reward 8.32  | Actor loss: -0.25 | Critic loss: 4.02 | Entropy loss: -0.0038  | Total Loss: 3.76 | Total Steps: 59\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1437/94000  | Episode Reward: 10  | Average Reward 8.35  | Actor loss: 0.00 | Critic loss: 0.27 | Entropy loss: -0.0000  | Total Loss: 0.27 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1438/94000  | Episode Reward: 10  | Average Reward 8.35  | Actor loss: 0.32 | Critic loss: 0.12 | Entropy loss: -0.0015  | Total Loss: 0.44 | Total Steps: 7\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1439/94000  | Episode Reward: 10  | Average Reward 8.35  | Actor loss: 0.09 | Critic loss: 0.36 | Entropy loss: -0.0018  | Total Loss: 0.44 | Total Steps: 9\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1440/94000  | Episode Reward: 10  | Average Reward 8.35  | Actor loss: 0.09 | Critic loss: 0.50 | Entropy loss: -0.0002  | Total Loss: 0.59 | Total Steps: 8\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1441/94000  | Episode Reward: 10  | Average Reward 8.35  | Actor loss: -0.00 | Critic loss: 0.12 | Entropy loss: -0.0005  | Total Loss: 0.12 | Total Steps: 9\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1442/94000  | Episode Reward: 10  | Average Reward 8.35  | Actor loss: 0.00 | Critic loss: 4.78 | Entropy loss: -0.0000  | Total Loss: 4.78 | Total Steps: 31\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1443/94000  | Episode Reward: 10  | Average Reward 8.35  | Actor loss: -0.31 | Critic loss: 2.10 | Entropy loss: -0.0018  | Total Loss: 1.79 | Total Steps: 38\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1444/94000  | Episode Reward: 8  | Average Reward 8.32  | Actor loss: -0.11 | Critic loss: 0.51 | Entropy loss: -0.0014  | Total Loss: 0.41 | Total Steps: 46\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1445/94000  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0000  | Total Loss: 0.11 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1446/94000  | Episode Reward: 8  | Average Reward 8.32  | Actor loss: -0.16 | Critic loss: 1.06 | Entropy loss: -0.0010  | Total Loss: 0.90 | Total Steps: 38\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1447/94000  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1448/94000  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0000  | Total Loss: 0.08 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1449/94000  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: -0.01 | Critic loss: 2.46 | Entropy loss: -0.0021  | Total Loss: 2.45 | Total Steps: 37\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1450/94000  | Episode Reward: 10  | Average Reward 8.32  | Actor loss: 0.00 | Critic loss: 3.03 | Entropy loss: -0.0000  | Total Loss: 3.03 | Total Steps: 31\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1451/94000  | Episode Reward: 8  | Average Reward 8.30  | Actor loss: -0.26 | Critic loss: 3.93 | Entropy loss: -0.0009  | Total Loss: 3.67 | Total Steps: 37\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1452/94000  | Episode Reward: 10  | Average Reward 8.35  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0000  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1453/94000  | Episode Reward: 8  | Average Reward 8.32  | Actor loss: 0.38 | Critic loss: 1.75 | Entropy loss: -0.0052  | Total Loss: 2.13 | Total Steps: 37\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1454/94000  | Episode Reward: 5  | Average Reward 8.28  | Actor loss: -0.01 | Critic loss: 1.26 | Entropy loss: -0.0019  | Total Loss: 1.25 | Total Steps: 224\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1455/94000  | Episode Reward: 10  | Average Reward 8.28  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0004  | Total Loss: 0.02 | Total Steps: 10\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1456/94000  | Episode Reward: 5  | Average Reward 8.22  | Actor loss: -0.65 | Critic loss: 10.15 | Entropy loss: -0.0031  | Total Loss: 9.50 | Total Steps: 47\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1457/94000  | Episode Reward: 10  | Average Reward 8.25  | Actor loss: 0.00 | Critic loss: 0.81 | Entropy loss: -0.0000  | Total Loss: 0.82 | Total Steps: 6\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1458/94000  | Episode Reward: 10  | Average Reward 8.25  | Actor loss: -0.36 | Critic loss: 1.52 | Entropy loss: -0.0013  | Total Loss: 1.15 | Total Steps: 36\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1459/94000  | Episode Reward: 10  | Average Reward 8.28  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0000  | Total Loss: 0.10 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1460/94000  | Episode Reward: 10  | Average Reward 8.28  | Actor loss: 0.15 | Critic loss: 0.10 | Entropy loss: -0.0010  | Total Loss: 0.26 | Total Steps: 7\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1461/94000  | Episode Reward: 10  | Average Reward 8.30  | Actor loss: -0.16 | Critic loss: 2.69 | Entropy loss: -0.0026  | Total Loss: 2.53 | Total Steps: 97\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1462/94000  | Episode Reward: 10  | Average Reward 8.30  | Actor loss: -0.01 | Critic loss: 2.06 | Entropy loss: -0.0001  | Total Loss: 2.04 | Total Steps: 29\n",
      "\n",
      "---blue capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1463/94000  | Episode Reward: 5  | Average Reward 8.25  | Actor loss: -0.07 | Critic loss: 3.50 | Entropy loss: -0.0004  | Total Loss: 3.43 | Total Steps: 49\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1464/94000  | Episode Reward: 10  | Average Reward 8.25  | Actor loss: -0.17 | Critic loss: 1.35 | Entropy loss: -0.0007  | Total Loss: 1.18 | Total Steps: 36\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1465/94000  | Episode Reward: 10  | Average Reward 8.25  | Actor loss: 0.01 | Critic loss: 1.91 | Entropy loss: -0.0001  | Total Loss: 1.92 | Total Steps: 31\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1466/94000  | Episode Reward: 10  | Average Reward 8.25  | Actor loss: -0.03 | Critic loss: 1.24 | Entropy loss: -0.0010  | Total Loss: 1.21 | Total Steps: 34\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1467/94000  | Episode Reward: 8  | Average Reward 8.22  | Actor loss: -0.04 | Critic loss: 1.55 | Entropy loss: -0.0008  | Total Loss: 1.51 | Total Steps: 48\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1468/94000  | Episode Reward: 10  | Average Reward 8.22  | Actor loss: 0.03 | Critic loss: 0.76 | Entropy loss: -0.0010  | Total Loss: 0.79 | Total Steps: 46\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1469/94000  | Episode Reward: 8  | Average Reward 8.20  | Actor loss: -0.18 | Critic loss: 2.27 | Entropy loss: -0.0010  | Total Loss: 2.10 | Total Steps: 43\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1470/94000  | Episode Reward: 10  | Average Reward 8.20  | Actor loss: 0.92 | Critic loss: 0.33 | Entropy loss: -0.0026  | Total Loss: 1.25 | Total Steps: 7\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1471/94000  | Episode Reward: 10  | Average Reward 8.20  | Actor loss: -0.47 | Critic loss: 5.54 | Entropy loss: -0.0023  | Total Loss: 5.08 | Total Steps: 41\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1472/94000  | Episode Reward: 8  | Average Reward 8.18  | Actor loss: -0.17 | Critic loss: 1.43 | Entropy loss: -0.0016  | Total Loss: 1.25 | Total Steps: 49\n",
      "\n",
      "---black capsule---\n",
      "Decision Step reward: -1.0\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1473/94000  | Episode Reward: 9  | Average Reward 8.16  | Actor loss: 0.07 | Critic loss: 3.71 | Entropy loss: -0.0038  | Total Loss: 3.77 | Total Steps: 32\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1474/94000  | Episode Reward: 8  | Average Reward 8.16  | Actor loss: -0.01 | Critic loss: 7.46 | Entropy loss: -0.0001  | Total Loss: 7.45 | Total Steps: 47\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1475/94000  | Episode Reward: 10  | Average Reward 8.16  | Actor loss: 0.12 | Critic loss: 1.74 | Entropy loss: -0.0011  | Total Loss: 1.86 | Total Steps: 10\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1476/94000  | Episode Reward: 10  | Average Reward 8.16  | Actor loss: 0.09 | Critic loss: 0.69 | Entropy loss: -0.0002  | Total Loss: 0.78 | Total Steps: 8\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1477/94000  | Episode Reward: 10  | Average Reward 8.16  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0000  | Total Loss: 0.10 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1478/94000  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0000  | Total Loss: 0.20 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1479/94000  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.02 | Critic loss: 0.17 | Entropy loss: -0.0001  | Total Loss: 0.19 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1480/94000  | Episode Reward: 10  | Average Reward 8.24  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0000  | Total Loss: 0.14 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1481/94000  | Episode Reward: 10  | Average Reward 8.29  | Actor loss: -0.39 | Critic loss: 1.05 | Entropy loss: -0.0016  | Total Loss: 0.66 | Total Steps: 22\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1482/94000  | Episode Reward: 10  | Average Reward 8.29  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0000  | Total Loss: 0.21 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1483/94000  | Episode Reward: 10  | Average Reward 8.31  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1484/94000  | Episode Reward: 10  | Average Reward 8.31  | Actor loss: -0.01 | Critic loss: 1.71 | Entropy loss: -0.0003  | Total Loss: 1.69 | Total Steps: 49\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1485/94000  | Episode Reward: 10  | Average Reward 8.31  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1486/94000  | Episode Reward: 8  | Average Reward 8.49  | Actor loss: 0.12 | Critic loss: 0.74 | Entropy loss: -0.0010  | Total Loss: 0.86 | Total Steps: 37\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1487/94000  | Episode Reward: 10  | Average Reward 8.52  | Actor loss: 0.37 | Critic loss: 0.33 | Entropy loss: -0.0010  | Total Loss: 0.71 | Total Steps: 7\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1488/94000  | Episode Reward: 10  | Average Reward 8.71  | Actor loss: -0.01 | Critic loss: 0.10 | Entropy loss: -0.0003  | Total Loss: 0.08 | Total Steps: 11\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1489/94000  | Episode Reward: 10  | Average Reward 8.74  | Actor loss: 0.02 | Critic loss: 1.64 | Entropy loss: -0.0002  | Total Loss: 1.66 | Total Steps: 31\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1490/94000  | Episode Reward: 10  | Average Reward 8.74  | Actor loss: 0.08 | Critic loss: 0.20 | Entropy loss: -0.0004  | Total Loss: 0.28 | Total Steps: 8\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1491/94000  | Episode Reward: 10  | Average Reward 8.74  | Actor loss: -0.00 | Critic loss: 0.65 | Entropy loss: -0.0011  | Total Loss: 0.65 | Total Steps: 44\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1492/94000  | Episode Reward: 10  | Average Reward 8.74  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1493/94000  | Episode Reward: 10  | Average Reward 8.74  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0000  | Total Loss: 0.00 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1494/94000  | Episode Reward: 10  | Average Reward 8.74  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0000  | Total Loss: 0.12 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1495/94000  | Episode Reward: 8  | Average Reward 8.71  | Actor loss: -0.13 | Critic loss: 1.50 | Entropy loss: -0.0016  | Total Loss: 1.36 | Total Steps: 30\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1496/94000  | Episode Reward: 8  | Average Reward 8.69  | Actor loss: -0.71 | Critic loss: 6.84 | Entropy loss: -0.0028  | Total Loss: 6.13 | Total Steps: 45\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1497/94000  | Episode Reward: 10  | Average Reward 8.77  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0000  | Total Loss: 0.13 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 1498/94000  | Episode Reward: -10  | Average Reward 8.56  | Actor loss: -0.00 | Critic loss: 4.16 | Entropy loss: -0.0001  | Total Loss: 4.16 | Total Steps: 500\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1499/94000  | Episode Reward: 10  | Average Reward 8.56  | Actor loss: 0.00 | Critic loss: 3.19 | Entropy loss: -0.0000  | Total Loss: 3.19 | Total Steps: 31\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1500/94000  | Episode Reward: 8  | Average Reward 8.54  | Actor loss: -0.44 | Critic loss: 2.35 | Entropy loss: -0.0032  | Total Loss: 1.90 | Total Steps: 51\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1501/94000  | Episode Reward: 10  | Average Reward 8.56  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "Model has been saved\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 10  | Average Reward 7.38  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0349  | Total Loss: 0.12 | Total Steps: 48\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 10  | Average Reward 7.40  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0231  | Total Loss: 0.09 | Total Steps: 12\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 3/100  | Episode Reward: 8  | Average Reward 7.40  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0208  | Total Loss: -0.02 | Total Steps: 54\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 10  | Average Reward 7.53  | Actor loss: -0.00 | Critic loss: 0.07 | Entropy loss: -0.0241  | Total Loss: 0.04 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 10  | Average Reward 7.53  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0053  | Total Loss: 0.10 | Total Steps: 36\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 8  | Average Reward 7.50  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0010  | Total Loss: 0.02 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: 10  | Average Reward 7.50  | Actor loss: 0.00 | Critic loss: 0.69 | Entropy loss: -0.0023  | Total Loss: 0.69 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 10  | Average Reward 7.50  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0006  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 9  | Average Reward 7.49  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0318  | Total Loss: 0.09 | Total Steps: 22\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 10  | Average Reward 7.51  | Actor loss: 0.06 | Critic loss: 0.45 | Entropy loss: -0.0089  | Total Loss: 0.50 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 10  | Average Reward 7.57  | Actor loss: 0.03 | Critic loss: 2.36 | Entropy loss: -0.0352  | Total Loss: 2.36 | Total Steps: 10\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 5  | Average Reward 7.54  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0016  | Total Loss: 0.16 | Total Steps: 49\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 5  | Average Reward 7.49  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0223  | Total Loss: 0.04 | Total Steps: 48\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: 10  | Average Reward 7.49  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0147  | Total Loss: -0.00 | Total Steps: 50\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 10  | Average Reward 7.57  | Actor loss: 0.06 | Critic loss: 10.09 | Entropy loss: -0.0440  | Total Loss: 10.11 | Total Steps: 9\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 10  | Average Reward 7.57  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0409  | Total Loss: 0.06 | Total Steps: 11\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 0  | Average Reward 7.50  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0047  | Total Loss: 0.03 | Total Steps: 44\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 8  | Average Reward 7.48  | Actor loss: 0.01 | Critic loss: 2.41 | Entropy loss: -0.0412  | Total Loss: 2.38 | Total Steps: 26\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 19/100  | Episode Reward: -10  | Average Reward 7.28  | Actor loss: -0.00 | Critic loss: 65.68 | Entropy loss: -0.0001  | Total Loss: 65.68 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: 10  | Average Reward 7.30  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0004  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 10  | Average Reward 7.30  | Actor loss: -0.00 | Critic loss: 0.06 | Entropy loss: -0.0196  | Total Loss: 0.04 | Total Steps: 40\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 22/100  | Episode Reward: 10  | Average Reward 7.50  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0698  | Total Loss: -0.04 | Total Steps: 8\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 5  | Average Reward 7.48  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0395  | Total Loss: 0.00 | Total Steps: 24\n",
      "TEST: ---yellow prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 10  | Average Reward 7.48  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0349  | Total Loss: -0.02 | Total Steps: 8\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 10  | Average Reward 7.49  | Actor loss: 0.01 | Critic loss: 0.55 | Entropy loss: -0.0393  | Total Loss: 0.51 | Total Steps: 7\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 10  | Average Reward 7.49  | Actor loss: 0.15 | Critic loss: 1.97 | Entropy loss: -0.0356  | Total Loss: 2.09 | Total Steps: 8\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 5  | Average Reward 7.44  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0084  | Total Loss: 0.02 | Total Steps: 48\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 10  | Average Reward 7.44  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0133  | Total Loss: 0.11 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 10  | Average Reward 7.44  | Actor loss: 0.09 | Critic loss: 2.94 | Entropy loss: -0.0447  | Total Loss: 2.99 | Total Steps: 8\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 10  | Average Reward 7.44  | Actor loss: 0.02 | Critic loss: 2.27 | Entropy loss: -0.0161  | Total Loss: 2.28 | Total Steps: 9\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 8  | Average Reward 7.42  | Actor loss: -0.00 | Critic loss: 0.10 | Entropy loss: -0.0103  | Total Loss: 0.09 | Total Steps: 41\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 32/100  | Episode Reward: 5  | Average Reward 7.59  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0011  | Total Loss: 0.12 | Total Steps: 49\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 33/100  | Episode Reward: 10  | Average Reward 7.59  | Actor loss: 0.00 | Critic loss: 0.45 | Entropy loss: -0.0031  | Total Loss: 0.45 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 34/100  | Episode Reward: 10  | Average Reward 7.59  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0002  | Total Loss: 0.04 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 35/100  | Episode Reward: 8  | Average Reward 7.57  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0486  | Total Loss: 0.11 | Total Steps: 26\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 36/100  | Episode Reward: 10  | Average Reward 7.62  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0093  | Total Loss: 0.10 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 37/100  | Episode Reward: 8  | Average Reward 7.59  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0008  | Total Loss: 0.14 | Total Steps: 29\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: 5  | Average Reward 7.54  | Actor loss: -0.00 | Critic loss: 0.19 | Entropy loss: -0.0108  | Total Loss: 0.18 | Total Steps: 54\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 8  | Average Reward 7.55  | Actor loss: 0.01 | Critic loss: 2.53 | Entropy loss: -0.0281  | Total Loss: 2.51 | Total Steps: 28\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 10  | Average Reward 7.55  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0048  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 9  | Average Reward 7.54  | Actor loss: 0.00 | Critic loss: 1.31 | Entropy loss: -0.0253  | Total Loss: 1.29 | Total Steps: 52\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 8  | Average Reward 7.51  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0103  | Total Loss: 0.13 | Total Steps: 41\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 43/100  | Episode Reward: 10  | Average Reward 7.62  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0019  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 10  | Average Reward 7.64  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0005  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: 8  | Average Reward 7.62  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0071  | Total Loss: 0.01 | Total Steps: 53\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 8  | Average Reward 7.59  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0037  | Total Loss: -0.00 | Total Steps: 46\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 10  | Average Reward 7.59  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0442  | Total Loss: -0.04 | Total Steps: 8\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 5  | Average Reward 7.57  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0018  | Total Loss: 0.12 | Total Steps: 49\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 8  | Average Reward 7.54  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0115  | Total Loss: 0.10 | Total Steps: 37\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 8  | Average Reward 7.66  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0007  | Total Loss: 0.03 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 8  | Average Reward 7.63  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0007  | Total Loss: 0.02 | Total Steps: 38\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 8  | Average Reward 7.63  | Actor loss: -0.00 | Critic loss: 0.04 | Entropy loss: -0.0245  | Total Loss: 0.02 | Total Steps: 77\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 53/100  | Episode Reward: 10  | Average Reward 7.68  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0045  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 54/100  | Episode Reward: 10  | Average Reward 7.68  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0320  | Total Loss: -0.03 | Total Steps: 7\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 10  | Average Reward 7.68  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0013  | Total Loss: 0.08 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: 5  | Average Reward 7.63  | Actor loss: -0.00 | Critic loss: 0.17 | Entropy loss: -0.0173  | Total Loss: 0.15 | Total Steps: 63\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 8  | Average Reward 7.63  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0114  | Total Loss: 0.04 | Total Steps: 34\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 8  | Average Reward 7.62  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0227  | Total Loss: -0.01 | Total Steps: 55\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 10  | Average Reward 7.70  | Actor loss: 0.01 | Critic loss: 0.28 | Entropy loss: -0.0048  | Total Loss: 0.29 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 60/100  | Episode Reward: 10  | Average Reward 7.70  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0005  | Total Loss: 0.13 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 61/100  | Episode Reward: 8  | Average Reward 7.67  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0003  | Total Loss: 0.10 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 8  | Average Reward 7.65  | Actor loss: 0.00 | Critic loss: 1.03 | Entropy loss: -0.0003  | Total Loss: 1.03 | Total Steps: 29\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: 10  | Average Reward 7.65  | Actor loss: 0.01 | Critic loss: 2.45 | Entropy loss: -0.0251  | Total Loss: 2.44 | Total Steps: 37\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 64/100  | Episode Reward: 10  | Average Reward 7.67  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0043  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 65/100  | Episode Reward: 10  | Average Reward 7.67  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0557  | Total Loss: -0.03 | Total Steps: 66\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 10  | Average Reward 7.70  | Actor loss: 0.00 | Critic loss: 20.68 | Entropy loss: -0.0264  | Total Loss: 20.66 | Total Steps: 17\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 10  | Average Reward 7.70  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0650  | Total Loss: -0.06 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 68/100  | Episode Reward: 10  | Average Reward 7.90  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0183  | Total Loss: 0.14 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 8  | Average Reward 7.88  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0011  | Total Loss: 0.15 | Total Steps: 29\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 70/100  | Episode Reward: 5  | Average Reward 7.83  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0066  | Total Loss: 0.01 | Total Steps: 57\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 10  | Average Reward 7.83  | Actor loss: 0.00 | Critic loss: 0.22 | Entropy loss: -0.0588  | Total Loss: 0.16 | Total Steps: 26\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 8  | Average Reward 7.80  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0112  | Total Loss: 0.18 | Total Steps: 29\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 10  | Average Reward 7.80  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0022  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: 8  | Average Reward 7.78  | Actor loss: 0.00 | Critic loss: 0.99 | Entropy loss: -0.0006  | Total Loss: 0.99 | Total Steps: 29\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 10  | Average Reward 7.78  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0002  | Total Loss: 0.03 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 10  | Average Reward 7.78  | Actor loss: 0.01 | Critic loss: 7.55 | Entropy loss: -0.0112  | Total Loss: 7.55 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 77/100  | Episode Reward: 10  | Average Reward 7.80  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0020  | Total Loss: 0.14 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 10  | Average Reward 7.83  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0015  | Total Loss: 0.00 | Total Steps: 40\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 8  | Average Reward 7.80  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0230  | Total Loss: -0.02 | Total Steps: 58\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 400\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 8  | Average Reward 7.78  | Actor loss: 0.00 | Critic loss: 0.41 | Entropy loss: -0.0049  | Total Loss: 0.41 | Total Steps: 434\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 8  | Average Reward 7.75  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0012  | Total Loss: 0.19 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: 8  | Average Reward 7.75  | Actor loss: 0.80 | Critic loss: 0.77 | Entropy loss: -0.0044  | Total Loss: 1.56 | Total Steps: 316\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing  | Episode: 83/100  | Episode Reward: 10  | Average Reward 7.80  | Actor loss: 0.02 | Critic loss: 2.28 | Entropy loss: -0.0137  | Total Loss: 2.29 | Total Steps: 9\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 84/100  | Episode Reward: 5  | Average Reward 7.75  | Actor loss: 0.01 | Critic loss: 0.54 | Entropy loss: -0.0074  | Total Loss: 0.55 | Total Steps: 61\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 85/100  | Episode Reward: 10  | Average Reward 7.78  | Actor loss: 0.08 | Critic loss: 0.55 | Entropy loss: -0.0056  | Total Loss: 0.62 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: 10  | Average Reward 7.99  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0013  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 8  | Average Reward 8.01  | Actor loss: 0.00 | Critic loss: 0.80 | Entropy loss: -0.0004  | Total Loss: 0.80 | Total Steps: 34\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 10  | Average Reward 8.01  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0002  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 89/100  | Episode Reward: 8  | Average Reward 8.19  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0369  | Total Loss: 0.19 | Total Steps: 40\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 90/100  | Episode Reward: 10  | Average Reward 8.19  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0063  | Total Loss: 0.13 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0004  | Total Loss: -0.00 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 5  | Average Reward 8.19  | Actor loss: 0.01 | Critic loss: 10.13 | Entropy loss: -0.0118  | Total Loss: 10.14 | Total Steps: 55\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0006  | Total Loss: 0.08 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 23.92 | Entropy loss: -0.0565  | Total Loss: 23.86 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.43 | Entropy loss: -0.0236  | Total Loss: 0.41 | Total Steps: 67\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 8  | Average Reward 8.20  | Actor loss: 0.07 | Critic loss: 1.91 | Entropy loss: -0.0084  | Total Loss: 1.97 | Total Steps: 55\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 10  | Average Reward 8.22  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0023  | Total Loss: 0.05 | Total Steps: 36\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: 10  | Average Reward 8.24  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0415  | Total Loss: 0.15 | Total Steps: 10\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 10  | Average Reward 8.24  | Actor loss: 0.01 | Critic loss: 1.51 | Entropy loss: -0.0380  | Total Loss: 1.47 | Total Steps: 9\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 10  | Average Reward 8.45  | Actor loss: 0.13 | Critic loss: 0.93 | Entropy loss: -0.0098  | Total Loss: 1.05 | Total Steps: 6\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1502/94000  | Episode Reward: 8  | Average Reward 8.54  | Actor loss: 0.02 | Critic loss: 5.55 | Entropy loss: -0.0016  | Total Loss: 5.57 | Total Steps: 57\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1503/94000  | Episode Reward: 10  | Average Reward 8.54  | Actor loss: -0.07 | Critic loss: 5.41 | Entropy loss: -0.0009  | Total Loss: 5.34 | Total Steps: 54\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1504/94000  | Episode Reward: 10  | Average Reward 8.54  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1505/94000  | Episode Reward: 10  | Average Reward 8.74  | Actor loss: -0.02 | Critic loss: 1.00 | Entropy loss: -0.0013  | Total Loss: 0.98 | Total Steps: 51\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1506/94000  | Episode Reward: 10  | Average Reward 8.74  | Actor loss: 0.04 | Critic loss: 0.06 | Entropy loss: -0.0003  | Total Loss: 0.10 | Total Steps: 8\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1507/94000  | Episode Reward: 10  | Average Reward 8.79  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1508/94000  | Episode Reward: 10  | Average Reward 8.79  | Actor loss: -0.05 | Critic loss: 0.11 | Entropy loss: -0.0005  | Total Loss: 0.06 | Total Steps: 11\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1509/94000  | Episode Reward: 10  | Average Reward 8.81  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1510/94000  | Episode Reward: 10  | Average Reward 8.81  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1511/94000  | Episode Reward: 8  | Average Reward 8.79  | Actor loss: -0.09 | Critic loss: 2.55 | Entropy loss: -0.0010  | Total Loss: 2.46 | Total Steps: 51\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1512/94000  | Episode Reward: 10  | Average Reward 8.84  | Actor loss: -0.00 | Critic loss: 1.17 | Entropy loss: -0.0000  | Total Loss: 1.16 | Total Steps: 38\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1513/94000  | Episode Reward: 10  | Average Reward 8.84  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0000  | Total Loss: 0.13 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1514/94000  | Episode Reward: 10  | Average Reward 8.84  | Actor loss: 0.00 | Critic loss: 2.51 | Entropy loss: -0.0000  | Total Loss: 2.51 | Total Steps: 31\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1515/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1516/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0000  | Total Loss: 0.21 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1517/94000  | Episode Reward: 8  | Average Reward 8.87  | Actor loss: 0.02 | Critic loss: 0.49 | Entropy loss: -0.0003  | Total Loss: 0.51 | Total Steps: 38\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1518/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: -0.01 | Critic loss: 3.38 | Entropy loss: -0.0001  | Total Loss: 3.37 | Total Steps: 29\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1519/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: -0.33 | Critic loss: 3.18 | Entropy loss: -0.0043  | Total Loss: 2.85 | Total Steps: 58\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1520/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: 0.06 | Critic loss: 0.40 | Entropy loss: -0.0005  | Total Loss: 0.46 | Total Steps: 8\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1521/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0000  | Total Loss: 0.18 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Step: 250\n",
      "Decision Step reward: -2.5\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 1522/94000  | Episode Reward: -12  | Average Reward 8.66  | Actor loss: -0.26 | Critic loss: 6.81 | Entropy loss: -0.0059  | Total Loss: 6.54 | Total Steps: 500\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1523/94000  | Episode Reward: 10  | Average Reward 8.69  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1524/94000  | Episode Reward: 10  | Average Reward 8.69  | Actor loss: 0.00 | Critic loss: 1.96 | Entropy loss: -0.0001  | Total Loss: 1.96 | Total Steps: 29\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1525/94000  | Episode Reward: 10  | Average Reward 8.69  | Actor loss: 0.04 | Critic loss: 0.17 | Entropy loss: -0.0017  | Total Loss: 0.21 | Total Steps: 9\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1526/94000  | Episode Reward: 10  | Average Reward 8.71  | Actor loss: -0.00 | Critic loss: 4.67 | Entropy loss: -0.0001  | Total Loss: 4.67 | Total Steps: 55\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1527/94000  | Episode Reward: 10  | Average Reward 8.74  | Actor loss: -0.91 | Critic loss: 2.83 | Entropy loss: -0.0044  | Total Loss: 1.92 | Total Steps: 41\n",
      "\n",
      "---black capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1528/94000  | Episode Reward: 8  | Average Reward 8.71  | Actor loss: -0.05 | Critic loss: 3.66 | Entropy loss: -0.0018  | Total Loss: 3.60 | Total Steps: 104\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1529/94000  | Episode Reward: 5  | Average Reward 8.66  | Actor loss: -0.10 | Critic loss: 1.65 | Entropy loss: -0.0019  | Total Loss: 1.55 | Total Steps: 109\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1530/94000  | Episode Reward: 10  | Average Reward 8.66  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0000  | Total Loss: 0.11 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1531/94000  | Episode Reward: 10  | Average Reward 8.69  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1532/94000  | Episode Reward: 10  | Average Reward 8.69  | Actor loss: 0.42 | Critic loss: 1.71 | Entropy loss: -0.0011  | Total Loss: 2.12 | Total Steps: 13\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1533/94000  | Episode Reward: 10  | Average Reward 8.71  | Actor loss: -0.22 | Critic loss: 2.12 | Entropy loss: -0.0011  | Total Loss: 1.89 | Total Steps: 24\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1534/94000  | Episode Reward: 10  | Average Reward 8.71  | Actor loss: 0.00 | Critic loss: 3.72 | Entropy loss: -0.0000  | Total Loss: 3.73 | Total Steps: 31\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1535/94000  | Episode Reward: 10  | Average Reward 8.91  | Actor loss: 0.02 | Critic loss: 2.41 | Entropy loss: -0.0001  | Total Loss: 2.43 | Total Steps: 31\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1536/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: 0.01 | Critic loss: 0.20 | Entropy loss: -0.0001  | Total Loss: 0.21 | Total Steps: 8\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1537/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: 0.00 | Critic loss: 1.84 | Entropy loss: -0.0000  | Total Loss: 1.84 | Total Steps: 31\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1538/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: -0.02 | Critic loss: 0.89 | Entropy loss: -0.0013  | Total Loss: 0.87 | Total Steps: 51\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1539/94000  | Episode Reward: 8  | Average Reward 8.94  | Actor loss: -0.11 | Critic loss: 6.15 | Entropy loss: -0.0011  | Total Loss: 6.04 | Total Steps: 42\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1540/94000  | Episode Reward: 10  | Average Reward 8.94  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0000  | Total Loss: 0.00 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1541/94000  | Episode Reward: 10  | Average Reward 8.94  | Actor loss: 0.00 | Critic loss: 0.66 | Entropy loss: -0.0001  | Total Loss: 0.66 | Total Steps: 38\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1542/94000  | Episode Reward: 10  | Average Reward 8.94  | Actor loss: 0.01 | Critic loss: 0.28 | Entropy loss: -0.0000  | Total Loss: 0.28 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1543/94000  | Episode Reward: 10  | Average Reward 8.94  | Actor loss: 0.09 | Critic loss: 0.22 | Entropy loss: -0.0017  | Total Loss: 0.30 | Total Steps: 9\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1544/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: -0.17 | Critic loss: 0.99 | Entropy loss: -0.0037  | Total Loss: 0.82 | Total Steps: 55\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1545/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: -0.18 | Critic loss: 4.35 | Entropy loss: -0.0006  | Total Loss: 4.17 | Total Steps: 19\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1546/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.02 | Critic loss: 2.07 | Entropy loss: -0.0004  | Total Loss: 2.09 | Total Steps: 31\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1547/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1548/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.03 | Critic loss: 0.96 | Entropy loss: -0.0003  | Total Loss: 0.98 | Total Steps: 32\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  | Episode: 1549/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.01 | Critic loss: 0.04 | Entropy loss: -0.0001  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1550/94000  | Episode Reward: 8  | Average Reward 8.96  | Actor loss: -0.19 | Critic loss: 1.99 | Entropy loss: -0.0021  | Total Loss: 1.80 | Total Steps: 44\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1551/94000  | Episode Reward: 8  | Average Reward 8.96  | Actor loss: -0.01 | Critic loss: 3.54 | Entropy loss: -0.0002  | Total Loss: 3.53 | Total Steps: 47\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1552/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: 0.02 | Critic loss: 0.03 | Entropy loss: -0.0004  | Total Loss: 0.05 | Total Steps: 8\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1553/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: -0.15 | Critic loss: 1.47 | Entropy loss: -0.0019  | Total Loss: 1.32 | Total Steps: 34\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1554/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.02 | Critic loss: 6.80 | Entropy loss: -0.0000  | Total Loss: 6.82 | Total Steps: 6\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1555/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.47 | Critic loss: 0.90 | Entropy loss: -0.0015  | Total Loss: 1.37 | Total Steps: 9\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1556/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: -0.18 | Critic loss: 1.55 | Entropy loss: -0.0026  | Total Loss: 1.36 | Total Steps: 32\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1557/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: -0.16 | Critic loss: 0.96 | Entropy loss: -0.0013  | Total Loss: 0.80 | Total Steps: 10\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1558/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: 0.26 | Critic loss: 0.98 | Entropy loss: -0.0014  | Total Loss: 1.24 | Total Steps: 10\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1559/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: 0.21 | Critic loss: 0.85 | Entropy loss: -0.0012  | Total Loss: 1.07 | Total Steps: 9\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1560/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: -0.02 | Critic loss: 1.66 | Entropy loss: -0.0046  | Total Loss: 1.64 | Total Steps: 53\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1561/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0000  | Total Loss: 0.12 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1562/94000  | Episode Reward: 8  | Average Reward 9.06  | Actor loss: -0.03 | Critic loss: 6.62 | Entropy loss: -0.0007  | Total Loss: 6.58 | Total Steps: 51\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1563/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.05 | Critic loss: 2.34 | Entropy loss: -0.0003  | Total Loss: 2.38 | Total Steps: 31\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1564/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.01 | Critic loss: 4.59 | Entropy loss: -0.0005  | Total Loss: 4.60 | Total Steps: 29\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1565/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: -0.00 | Critic loss: 1.42 | Entropy loss: -0.0002  | Total Loss: 1.42 | Total Steps: 29\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1566/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0000  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1567/94000  | Episode Reward: 10  | Average Reward 9.14  | Actor loss: 0.01 | Critic loss: 0.26 | Entropy loss: -0.0005  | Total Loss: 0.26 | Total Steps: 11\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1568/94000  | Episode Reward: 8  | Average Reward 9.12  | Actor loss: -0.52 | Critic loss: 13.22 | Entropy loss: -0.0080  | Total Loss: 12.69 | Total Steps: 117\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1569/94000  | Episode Reward: 8  | Average Reward 9.12  | Actor loss: -0.01 | Critic loss: 1.43 | Entropy loss: -0.0018  | Total Loss: 1.42 | Total Steps: 37\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1570/94000  | Episode Reward: 5  | Average Reward 9.06  | Actor loss: -0.52 | Critic loss: 8.02 | Entropy loss: -0.0037  | Total Loss: 7.50 | Total Steps: 42\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1571/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: 1.05 | Critic loss: 1.56 | Entropy loss: -0.0035  | Total Loss: 2.61 | Total Steps: 12\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1572/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: -0.01 | Critic loss: 1.56 | Entropy loss: -0.0006  | Total Loss: 1.55 | Total Steps: 31\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1573/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0000  | Total Loss: 0.12 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1574/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.02 | Critic loss: 0.11 | Entropy loss: -0.0001  | Total Loss: 0.14 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1575/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.26 | Critic loss: 0.59 | Entropy loss: -0.0023  | Total Loss: 0.84 | Total Steps: 40\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1576/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.00 | Critic loss: 1.39 | Entropy loss: -0.0000  | Total Loss: 1.39 | Total Steps: 31\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1577/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.05 | Critic loss: 0.06 | Entropy loss: -0.0006  | Total Loss: 0.12 | Total Steps: 8\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1578/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: -0.40 | Critic loss: 1.54 | Entropy loss: -0.0036  | Total Loss: 1.14 | Total Steps: 38\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1579/94000  | Episode Reward: 5  | Average Reward 9.07  | Actor loss: -0.45 | Critic loss: 7.82 | Entropy loss: -0.0035  | Total Loss: 7.37 | Total Steps: 32\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1580/94000  | Episode Reward: 8  | Average Reward 9.05  | Actor loss: -0.40 | Critic loss: 6.72 | Entropy loss: -0.0021  | Total Loss: 6.32 | Total Steps: 59\n",
      "\n",
      "---red cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1581/94000  | Episode Reward: 8  | Average Reward 9.03  | Actor loss: -0.06 | Critic loss: 6.27 | Entropy loss: -0.0006  | Total Loss: 6.22 | Total Steps: 49\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1582/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1583/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: -0.25 | Critic loss: 1.97 | Entropy loss: -0.0024  | Total Loss: 1.72 | Total Steps: 25\n",
      "\n",
      "---yellow sphere---\n",
      "Decision Step reward: -1.0\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1584/94000  | Episode Reward: 9  | Average Reward 9.02  | Actor loss: -1.07 | Critic loss: 7.51 | Entropy loss: -0.0139  | Total Loss: 6.43 | Total Steps: 60\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1585/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.29 | Critic loss: 1.62 | Entropy loss: -0.0016  | Total Loss: 1.91 | Total Steps: 37\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1586/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.01 | Critic loss: 0.37 | Entropy loss: -0.0005  | Total Loss: 0.38 | Total Steps: 8\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1587/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.00 | Critic loss: 1.41 | Entropy loss: -0.0000  | Total Loss: 1.41 | Total Steps: 31\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1588/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: -0.47 | Critic loss: 2.85 | Entropy loss: -0.0045  | Total Loss: 2.37 | Total Steps: 55\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1589/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.01 | Critic loss: 4.73 | Entropy loss: -0.0008  | Total Loss: 4.74 | Total Steps: 31\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1590/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.11 | Critic loss: 2.66 | Entropy loss: -0.0008  | Total Loss: 2.77 | Total Steps: 10\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1591/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: -0.66 | Critic loss: 5.16 | Entropy loss: -0.0045  | Total Loss: 4.50 | Total Steps: 67\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1592/94000  | Episode Reward: 8  | Average Reward 9.02  | Actor loss: -0.44 | Critic loss: 5.32 | Entropy loss: -0.0023  | Total Loss: 4.87 | Total Steps: 57\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1593/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.21 | Critic loss: 1.07 | Entropy loss: -0.0019  | Total Loss: 1.29 | Total Steps: 32\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1594/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.00 | Critic loss: 0.30 | Entropy loss: -0.0000  | Total Loss: 0.30 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1595/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: -0.13 | Critic loss: 1.70 | Entropy loss: -0.0029  | Total Loss: 1.57 | Total Steps: 49\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1596/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: -0.03 | Critic loss: 1.24 | Entropy loss: -0.0004  | Total Loss: 1.21 | Total Steps: 35\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1597/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: -0.85 | Critic loss: 3.93 | Entropy loss: -0.0087  | Total Loss: 3.08 | Total Steps: 55\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1598/94000  | Episode Reward: 10  | Average Reward 9.27  | Actor loss: 0.07 | Critic loss: 0.19 | Entropy loss: -0.0004  | Total Loss: 0.25 | Total Steps: 8\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1599/94000  | Episode Reward: 10  | Average Reward 9.27  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1600/94000  | Episode Reward: 8  | Average Reward 9.27  | Actor loss: 0.00 | Critic loss: 1.40 | Entropy loss: -0.0001  | Total Loss: 1.41 | Total Steps: 39\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1601/94000  | Episode Reward: 10  | Average Reward 9.27  | Actor loss: 0.20 | Critic loss: 0.16 | Entropy loss: -0.0012  | Total Loss: 0.36 | Total Steps: 7\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 10  | Average Reward 8.45  | Actor loss: 0.00 | Critic loss: 0.47 | Entropy loss: -0.0107  | Total Loss: 0.46 | Total Steps: 8\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 8  | Average Reward 8.42  | Actor loss: 0.03 | Critic loss: 3.08 | Entropy loss: -0.0668  | Total Loss: 3.04 | Total Steps: 65\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 3/100  | Episode Reward: 8  | Average Reward 8.42  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0058  | Total Loss: 0.13 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 5  | Average Reward 8.37  | Actor loss: 0.00 | Critic loss: 0.28 | Entropy loss: -0.0023  | Total Loss: 0.28 | Total Steps: 47\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 10  | Average Reward 8.37  | Actor loss: 0.32 | Critic loss: 4.69 | Entropy loss: -0.0427  | Total Loss: 4.97 | Total Steps: 9\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 10  | Average Reward 8.39  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0078  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: 8  | Average Reward 8.37  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0191  | Total Loss: 0.04 | Total Steps: 46\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 2  | Average Reward 8.29  | Actor loss: 0.02 | Critic loss: 0.27 | Entropy loss: -0.0128  | Total Loss: 0.28 | Total Steps: 51\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 10  | Average Reward 8.30  | Actor loss: 0.03 | Critic loss: 1.50 | Entropy loss: -0.0230  | Total Loss: 1.51 | Total Steps: 11\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 8  | Average Reward 8.28  | Actor loss: 0.05 | Critic loss: 1.07 | Entropy loss: -0.0036  | Total Loss: 1.12 | Total Steps: 43\n",
      "TEST: ---yellow prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 10  | Average Reward 8.28  | Actor loss: 0.02 | Critic loss: 1.70 | Entropy loss: -0.0238  | Total Loss: 1.70 | Total Steps: 24\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 10  | Average Reward 8.33  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0343  | Total Loss: -0.03 | Total Steps: 7\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: 0.01 | Critic loss: 0.13 | Entropy loss: -0.0050  | Total Loss: 0.13 | Total Steps: 96\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 1.75 | Entropy loss: -0.0171  | Total Loss: 1.73 | Total Steps: 50\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 10  | Average Reward 8.38  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0030  | Total Loss: 0.13 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 5  | Average Reward 8.33  | Actor loss: 0.00 | Critic loss: 0.27 | Entropy loss: -0.0104  | Total Loss: 0.26 | Total Steps: 47\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 10  | Average Reward 8.43  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0020  | Total Loss: 0.06 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 10  | Average Reward 8.45  | Actor loss: 0.35 | Critic loss: 5.03 | Entropy loss: -0.0800  | Total Loss: 5.29 | Total Steps: 7\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 0.44 | Entropy loss: -0.0198  | Total Loss: 0.42 | Total Steps: 12\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: 8  | Average Reward 8.62  | Actor loss: 0.01 | Critic loss: 1.93 | Entropy loss: -0.0532  | Total Loss: 1.88 | Total Steps: 46\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0099  | Total Loss: 0.02 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 22/100  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0018  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 6  | Average Reward 8.63  | Actor loss: 0.00 | Critic loss: 2.09 | Entropy loss: -0.0517  | Total Loss: 2.04 | Total Steps: 164\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 10  | Average Reward 8.63  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0020  | Total Loss: 0.01 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 10  | Average Reward 8.63  | Actor loss: 0.14 | Critic loss: 3.77 | Entropy loss: -0.0796  | Total Loss: 3.82 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 10  | Average Reward 8.63  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0141  | Total Loss: -0.01 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 10  | Average Reward 8.69  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0036  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 9  | Average Reward 8.68  | Actor loss: 0.00 | Critic loss: 0.85 | Entropy loss: -0.0300  | Total Loss: 0.82 | Total Steps: 23\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 5  | Average Reward 8.62  | Actor loss: 0.00 | Critic loss: 0.43 | Entropy loss: -0.0250  | Total Loss: 0.41 | Total Steps: 43\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 8  | Average Reward 8.60  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0010  | Total Loss: 0.11 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0004  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 32/100  | Episode Reward: 5  | Average Reward 8.62  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0048  | Total Loss: 0.20 | Total Steps: 47\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 33/100  | Episode Reward: -10  | Average Reward 8.43  | Actor loss: -0.00 | Critic loss: 81.93 | Entropy loss: -0.0004  | Total Loss: 81.93 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 34/100  | Episode Reward: 9  | Average Reward 8.41  | Actor loss: 0.01 | Critic loss: 1.96 | Entropy loss: -0.0484  | Total Loss: 1.92 | Total Steps: 29\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 35/100  | Episode Reward: -46  | Average Reward 7.88  | Actor loss: -1.15 | Critic loss: 118.69 | Entropy loss: -0.0544  | Total Loss: 117.48 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 36/100  | Episode Reward: 8  | Average Reward 7.85  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0026  | Total Loss: 0.12 | Total Steps: 36\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 37/100  | Episode Reward: 10  | Average Reward 7.88  | Actor loss: 0.00 | Critic loss: 0.24 | Entropy loss: -0.0017  | Total Loss: 0.25 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: 10  | Average Reward 7.92  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0018  | Total Loss: 0.10 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 5  | Average Reward 7.89  | Actor loss: 0.02 | Critic loss: 0.14 | Entropy loss: -0.0199  | Total Loss: 0.13 | Total Steps: 48\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 10  | Average Reward 7.89  | Actor loss: 0.01 | Critic loss: 1.36 | Entropy loss: -0.0061  | Total Loss: 1.36 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 10  | Average Reward 7.91  | Actor loss: 0.02 | Critic loss: 0.98 | Entropy loss: -0.0381  | Total Loss: 0.96 | Total Steps: 7\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 10  | Average Reward 7.93  | Actor loss: 0.17 | Critic loss: 5.17 | Entropy loss: -0.0218  | Total Loss: 5.32 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 43/100  | Episode Reward: 10  | Average Reward 7.93  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0480  | Total Loss: 0.12 | Total Steps: 9\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 10  | Average Reward 7.93  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0161  | Total Loss: -0.02 | Total Steps: 44\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: 5  | Average Reward 7.91  | Actor loss: 0.01 | Critic loss: 0.16 | Entropy loss: -0.0013  | Total Loss: 0.17 | Total Steps: 46\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 10  | Average Reward 7.93  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0011  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 8  | Average Reward 7.91  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0094  | Total Loss: 0.01 | Total Steps: 54\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 10  | Average Reward 7.96  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0018  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 10  | Average Reward 7.98  | Actor loss: 0.01 | Critic loss: 1.35 | Entropy loss: -0.0005  | Total Loss: 1.35 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 8  | Average Reward 7.98  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0015  | Total Loss: 0.15 | Total Steps: 365\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 5  | Average Reward 7.96  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0472  | Total Loss: 0.14 | Total Steps: 297\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 10  | Average Reward 7.98  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0607  | Total Loss: -0.05 | Total Steps: 9\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 53/100  | Episode Reward: 8  | Average Reward 7.96  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0050  | Total Loss: 0.15 | Total Steps: 38\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 54/100  | Episode Reward: 10  | Average Reward 7.96  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0018  | Total Loss: 0.02 | Total Steps: 35\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 10  | Average Reward 7.96  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0007  | Total Loss: 0.06 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: 10  | Average Reward 8.01  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0007  | Total Loss: 0.06 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 10  | Average Reward 8.03  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0002  | Total Loss: 0.05 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 10  | Average Reward 8.05  | Actor loss: 0.01 | Critic loss: 1.36 | Entropy loss: -0.0028  | Total Loss: 1.37 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 10  | Average Reward 8.05  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0126  | Total Loss: 0.02 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 60/100  | Episode Reward: 10  | Average Reward 8.05  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0232  | Total Loss: -0.01 | Total Steps: 58\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 61/100  | Episode Reward: 10  | Average Reward 8.08  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0043  | Total Loss: 0.10 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 8  | Average Reward 8.08  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0043  | Total Loss: -0.00 | Total Steps: 39\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: 10  | Average Reward 8.08  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0107  | Total Loss: 0.00 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 64/100  | Episode Reward: 10  | Average Reward 8.08  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0020  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 65/100  | Episode Reward: 8  | Average Reward 8.05  | Actor loss: 0.00 | Critic loss: 0.34 | Entropy loss: -0.0011  | Total Loss: 0.34 | Total Steps: 34\n",
      "TEST: ---green cube---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 10  | Average Reward 8.05  | Actor loss: 0.02 | Critic loss: 1.46 | Entropy loss: -0.0214  | Total Loss: 1.46 | Total Steps: 12\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 10  | Average Reward 8.05  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0330  | Total Loss: -0.03 | Total Steps: 7\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 68/100  | Episode Reward: 10  | Average Reward 8.05  | Actor loss: 0.01 | Critic loss: 1.34 | Entropy loss: -0.0047  | Total Loss: 1.34 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 10  | Average Reward 8.08  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0026  | Total Loss: 0.02 | Total Steps: 35\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 70/100  | Episode Reward: 9  | Average Reward 8.12  | Actor loss: 0.02 | Critic loss: 1.31 | Entropy loss: -0.0575  | Total Loss: 1.27 | Total Steps: 46\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 9  | Average Reward 8.11  | Actor loss: 0.20 | Critic loss: 5.12 | Entropy loss: -0.0409  | Total Loss: 5.27 | Total Steps: 25\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 8  | Average Reward 8.11  | Actor loss: 0.21 | Critic loss: 4.62 | Entropy loss: -0.0121  | Total Loss: 4.82 | Total Steps: 84\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 8  | Average Reward 8.09  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0065  | Total Loss: 0.03 | Total Steps: 65\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: 10  | Average Reward 8.11  | Actor loss: 0.01 | Critic loss: 0.81 | Entropy loss: -0.0039  | Total Loss: 0.81 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 10  | Average Reward 8.11  | Actor loss: 0.02 | Critic loss: 0.40 | Entropy loss: -0.0380  | Total Loss: 0.38 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 10  | Average Reward 8.11  | Actor loss: 0.01 | Critic loss: 0.98 | Entropy loss: -0.0058  | Total Loss: 0.98 | Total Steps: 50\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 77/100  | Episode Reward: 5  | Average Reward 8.06  | Actor loss: 0.02 | Critic loss: 0.65 | Entropy loss: -0.0033  | Total Loss: 0.67 | Total Steps: 47\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 8  | Average Reward 8.04  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0028  | Total Loss: 0.21 | Total Steps: 43\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 10  | Average Reward 8.06  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0009  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 10  | Average Reward 8.09  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0006  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 8  | Average Reward 8.09  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0109  | Total Loss: 0.02 | Total Steps: 50\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: 10  | Average Reward 8.11  | Actor loss: 0.01 | Critic loss: 0.43 | Entropy loss: -0.0366  | Total Loss: 0.40 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 10  | Average Reward 8.11  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0013  | Total Loss: 0.02 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 84/100  | Episode Reward: 8  | Average Reward 8.13  | Actor loss: 0.00 | Critic loss: 0.43 | Entropy loss: -0.0005  | Total Loss: 0.43 | Total Steps: 29\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 85/100  | Episode Reward: -10  | Average Reward 7.93  | Actor loss: -0.00 | Critic loss: 83.99 | Entropy loss: -0.0003  | Total Loss: 83.98 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: 5  | Average Reward 7.88  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0098  | Total Loss: 0.08 | Total Steps: 48\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 10  | Average Reward 7.91  | Actor loss: 0.01 | Critic loss: 0.73 | Entropy loss: -0.0548  | Total Loss: 0.68 | Total Steps: 12\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 5  | Average Reward 7.86  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0058  | Total Loss: 0.12 | Total Steps: 49\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 89/100  | Episode Reward: 8  | Average Reward 7.86  | Actor loss: 0.00 | Critic loss: 0.39 | Entropy loss: -0.0103  | Total Loss: 0.38 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 90/100  | Episode Reward: 10  | Average Reward 7.86  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0033  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 10  | Average Reward 7.86  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0114  | Total Loss: 0.00 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 8  | Average Reward 7.88  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0122  | Total Loss: 0.13 | Total Steps: 49\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: 5  | Average Reward 7.83  | Actor loss: 0.00 | Critic loss: 0.38 | Entropy loss: -0.0034  | Total Loss: 0.38 | Total Steps: 397\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 10  | Average Reward 7.83  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0008  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---red capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: 10  | Average Reward 7.83  | Actor loss: 0.00 | Critic loss: 0.24 | Entropy loss: -0.0013  | Total Loss: 0.24 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 10  | Average Reward 7.86  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0007  | Total Loss: 0.21 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 10  | Average Reward 7.86  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0128  | Total Loss: 0.00 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: 10  | Average Reward 7.86  | Actor loss: 0.00 | Critic loss: 0.24 | Entropy loss: -0.0032  | Total Loss: 0.24 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 8  | Average Reward 7.83  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0268  | Total Loss: -0.02 | Total Steps: 64\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 3  | Average Reward 7.76  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0712  | Total Loss: 0.01 | Total Steps: 79\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1602/94000  | Episode Reward: 10  | Average Reward 9.29  | Actor loss: 0.24 | Critic loss: 2.86 | Entropy loss: -0.0005  | Total Loss: 3.10 | Total Steps: 10\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1603/94000  | Episode Reward: 10  | Average Reward 9.29  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0000  | Total Loss: 0.15 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1604/94000  | Episode Reward: 10  | Average Reward 9.29  | Actor loss: -0.57 | Critic loss: 3.82 | Entropy loss: -0.0044  | Total Loss: 3.24 | Total Steps: 47\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1605/94000  | Episode Reward: 10  | Average Reward 9.29  | Actor loss: 0.00 | Critic loss: 1.01 | Entropy loss: -0.0000  | Total Loss: 1.01 | Total Steps: 31\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1606/94000  | Episode Reward: 10  | Average Reward 9.29  | Actor loss: -0.75 | Critic loss: 1.75 | Entropy loss: -0.0035  | Total Loss: 0.99 | Total Steps: 35\n",
      "\n",
      "---yellow sphere---\n",
      "Decision Step reward: -1.0\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1607/94000  | Episode Reward: 9  | Average Reward 9.28  | Actor loss: -0.78 | Critic loss: 4.36 | Entropy loss: -0.0077  | Total Loss: 3.57 | Total Steps: 55\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1608/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.11 | Critic loss: 1.09 | Entropy loss: -0.0010  | Total Loss: 1.20 | Total Steps: 44\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1609/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.02 | Critic loss: 0.12 | Entropy loss: -0.0013  | Total Loss: 0.14 | Total Steps: 8\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1610/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: -0.43 | Critic loss: 1.66 | Entropy loss: -0.0018  | Total Loss: 1.23 | Total Steps: 38\n",
      "\n",
      "---black capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1611/94000  | Episode Reward: 8  | Average Reward 9.28  | Actor loss: 0.00 | Critic loss: 0.29 | Entropy loss: -0.0001  | Total Loss: 0.30 | Total Steps: 38\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1612/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.03 | Critic loss: 1.51 | Entropy loss: -0.0010  | Total Loss: 1.54 | Total Steps: 50\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1613/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: -0.10 | Critic loss: 2.03 | Entropy loss: -0.0010  | Total Loss: 1.93 | Total Steps: 24\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1614/94000  | Episode Reward: 8  | Average Reward 9.26  | Actor loss: 0.00 | Critic loss: 0.35 | Entropy loss: -0.0001  | Total Loss: 0.36 | Total Steps: 38\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1615/94000  | Episode Reward: 10  | Average Reward 9.26  | Actor loss: 0.24 | Critic loss: 1.13 | Entropy loss: -0.0034  | Total Loss: 1.37 | Total Steps: 50\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1616/94000  | Episode Reward: 10  | Average Reward 9.26  | Actor loss: -0.13 | Critic loss: 4.56 | Entropy loss: -0.0008  | Total Loss: 4.43 | Total Steps: 42\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1617/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.01 | Critic loss: 0.35 | Entropy loss: -0.0000  | Total Loss: 0.36 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1618/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.01 | Critic loss: 1.25 | Entropy loss: -0.0001  | Total Loss: 1.26 | Total Steps: 31\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1619/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.03 | Critic loss: 0.90 | Entropy loss: -0.0005  | Total Loss: 0.93 | Total Steps: 10\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1620/94000  | Episode Reward: 10  | Average Reward 9.28  | Actor loss: 0.03 | Critic loss: 0.65 | Entropy loss: -0.0001  | Total Loss: 0.68 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1621/94000  | Episode Reward: 2  | Average Reward 9.21  | Actor loss: -0.72 | Critic loss: 12.68 | Entropy loss: -0.0034  | Total Loss: 11.96 | Total Steps: 88\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 9.43. Model has been saved-----\n",
      "Training  | Episode: 1622/94000  | Episode Reward: 10  | Average Reward 9.43  | Actor loss: -0.06 | Critic loss: 2.53 | Entropy loss: -0.0005  | Total Loss: 2.47 | Total Steps: 54\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1623/94000  | Episode Reward: 10  | Average Reward 9.43  | Actor loss: 0.00 | Critic loss: 0.94 | Entropy loss: -0.0000  | Total Loss: 0.94 | Total Steps: 31\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1624/94000  | Episode Reward: 10  | Average Reward 9.43  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0000  | Total Loss: 0.08 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1625/94000  | Episode Reward: 10  | Average Reward 9.43  | Actor loss: 0.00 | Critic loss: 1.45 | Entropy loss: -0.0001  | Total Loss: 1.45 | Total Steps: 31\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1626/94000  | Episode Reward: 10  | Average Reward 9.43  | Actor loss: 0.13 | Critic loss: 0.31 | Entropy loss: -0.0006  | Total Loss: 0.44 | Total Steps: 8\n",
      "\n",
      "---blue capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1627/94000  | Episode Reward: 8  | Average Reward 9.40  | Actor loss: 0.03 | Critic loss: 0.39 | Entropy loss: -0.0007  | Total Loss: 0.41 | Total Steps: 38\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1628/94000  | Episode Reward: 10  | Average Reward 9.43  | Actor loss: 0.03 | Critic loss: 1.34 | Entropy loss: -0.0001  | Total Loss: 1.37 | Total Steps: 36\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "-----The best score for averaging previous 100 episode reward is 9.48. Model has been saved-----\n",
      "Training  | Episode: 1629/94000  | Episode Reward: 10  | Average Reward 9.48  | Actor loss: -0.37 | Critic loss: 5.45 | Entropy loss: -0.0037  | Total Loss: 5.07 | Total Steps: 50\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1630/94000  | Episode Reward: 10  | Average Reward 9.48  | Actor loss: 0.00 | Critic loss: 1.14 | Entropy loss: -0.0001  | Total Loss: 1.14 | Total Steps: 31\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1631/94000  | Episode Reward: 10  | Average Reward 9.48  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1632/94000  | Episode Reward: 10  | Average Reward 9.48  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1633/94000  | Episode Reward: 8  | Average Reward 9.46  | Actor loss: -0.62 | Critic loss: 2.77 | Entropy loss: -0.0033  | Total Loss: 2.15 | Total Steps: 48\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1634/94000  | Episode Reward: 10  | Average Reward 9.46  | Actor loss: 0.26 | Critic loss: 1.11 | Entropy loss: -0.0017  | Total Loss: 1.36 | Total Steps: 43\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1635/94000  | Episode Reward: 10  | Average Reward 9.46  | Actor loss: -0.01 | Critic loss: 0.17 | Entropy loss: -0.0005  | Total Loss: 0.15 | Total Steps: 10\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1636/94000  | Episode Reward: 10  | Average Reward 9.46  | Actor loss: -0.01 | Critic loss: 4.26 | Entropy loss: -0.0001  | Total Loss: 4.25 | Total Steps: 29\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1637/94000  | Episode Reward: 8  | Average Reward 9.43  | Actor loss: -0.00 | Critic loss: 0.72 | Entropy loss: -0.0000  | Total Loss: 0.72 | Total Steps: 38\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1638/94000  | Episode Reward: 10  | Average Reward 9.43  | Actor loss: 0.10 | Critic loss: 1.10 | Entropy loss: -0.0033  | Total Loss: 1.20 | Total Steps: 48\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1639/94000  | Episode Reward: 10  | Average Reward 9.46  | Actor loss: 0.00 | Critic loss: 1.11 | Entropy loss: -0.0000  | Total Loss: 1.11 | Total Steps: 31\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1640/94000  | Episode Reward: 8  | Average Reward 9.43  | Actor loss: -0.22 | Critic loss: 5.52 | Entropy loss: -0.0016  | Total Loss: 5.30 | Total Steps: 51\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1641/94000  | Episode Reward: 10  | Average Reward 9.43  | Actor loss: 0.04 | Critic loss: 0.99 | Entropy loss: -0.0005  | Total Loss: 1.03 | Total Steps: 7\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1642/94000  | Episode Reward: 10  | Average Reward 9.43  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0000  | Total Loss: 0.12 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1643/94000  | Episode Reward: 8  | Average Reward 9.40  | Actor loss: 0.18 | Critic loss: 2.23 | Entropy loss: -0.0016  | Total Loss: 2.40 | Total Steps: 47\n",
      "\n",
      "---black capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1644/94000  | Episode Reward: 8  | Average Reward 9.38  | Actor loss: -0.02 | Critic loss: 1.54 | Entropy loss: -0.0012  | Total Loss: 1.51 | Total Steps: 31\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1645/94000  | Episode Reward: 10  | Average Reward 9.38  | Actor loss: 0.00 | Critic loss: 1.46 | Entropy loss: -0.0000  | Total Loss: 1.46 | Total Steps: 31\n",
      "\n",
      "---black capsule---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 1646/94000  | Episode Reward: -10  | Average Reward 9.18  | Actor loss: -0.00 | Critic loss: 6.20 | Entropy loss: -0.0000  | Total Loss: 6.20 | Total Steps: 500\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1647/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.00 | Critic loss: 1.74 | Entropy loss: -0.0000  | Total Loss: 1.74 | Total Steps: 31\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1648/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.07 | Critic loss: 0.35 | Entropy loss: -0.0009  | Total Loss: 0.42 | Total Steps: 40\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1649/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1650/94000  | Episode Reward: 10  | Average Reward 9.21  | Actor loss: -0.02 | Critic loss: 1.36 | Entropy loss: -0.0003  | Total Loss: 1.35 | Total Steps: 34\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1651/94000  | Episode Reward: 10  | Average Reward 9.23  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 1652/94000  | Episode Reward: -10  | Average Reward 9.03  | Actor loss: -0.00 | Critic loss: 4.11 | Entropy loss: -0.0000  | Total Loss: 4.11 | Total Steps: 500\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1653/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.00 | Critic loss: 0.57 | Entropy loss: -0.0000  | Total Loss: 0.57 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1654/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.01 | Critic loss: 1.13 | Entropy loss: -0.0015  | Total Loss: 1.13 | Total Steps: 35\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1655/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.04 | Critic loss: 1.12 | Entropy loss: -0.0005  | Total Loss: 1.16 | Total Steps: 32\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1656/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.02 | Critic loss: 0.33 | Entropy loss: -0.0004  | Total Loss: 0.35 | Total Steps: 38\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1657/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.20 | Critic loss: 1.88 | Entropy loss: -0.0028  | Total Loss: 2.08 | Total Steps: 158\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1658/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1659/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.01 | Critic loss: 1.23 | Entropy loss: -0.0000  | Total Loss: 1.24 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1660/94000  | Episode Reward: 8  | Average Reward 9.01  | Actor loss: -0.00 | Critic loss: 1.53 | Entropy loss: -0.0000  | Total Loss: 1.53 | Total Steps: 38\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1661/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1662/94000  | Episode Reward: 8  | Average Reward 9.01  | Actor loss: -0.00 | Critic loss: 3.62 | Entropy loss: -0.0002  | Total Loss: 3.62 | Total Steps: 47\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1663/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: -0.20 | Critic loss: 0.11 | Entropy loss: -0.0018  | Total Loss: -0.09 | Total Steps: 9\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1664/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: 0.05 | Critic loss: 0.77 | Entropy loss: -0.0015  | Total Loss: 0.82 | Total Steps: 24\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1665/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: 0.03 | Critic loss: 0.03 | Entropy loss: -0.0006  | Total Loss: 0.07 | Total Steps: 8\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1666/94000  | Episode Reward: 8  | Average Reward 8.98  | Actor loss: -0.03 | Critic loss: 1.49 | Entropy loss: -0.0017  | Total Loss: 1.46 | Total Steps: 126\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1667/94000  | Episode Reward: 10  | Average Reward 8.98  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0000  | Total Loss: 0.00 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1668/94000  | Episode Reward: 8  | Average Reward 8.98  | Actor loss: -0.14 | Critic loss: 1.94 | Entropy loss: -0.0016  | Total Loss: 1.80 | Total Steps: 50\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1669/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: 0.00 | Critic loss: 4.14 | Entropy loss: -0.0000  | Total Loss: 4.15 | Total Steps: 31\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1670/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: -0.39 | Critic loss: 3.28 | Entropy loss: -0.0031  | Total Loss: 2.88 | Total Steps: 53\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1671/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.05 | Critic loss: 0.90 | Entropy loss: -0.0004  | Total Loss: 0.95 | Total Steps: 12\n",
      "\n",
      "---red cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1672/94000  | Episode Reward: 8  | Average Reward 9.03  | Actor loss: -0.33 | Critic loss: 4.31 | Entropy loss: -0.0018  | Total Loss: 3.98 | Total Steps: 41\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1673/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.17 | Critic loss: 0.11 | Entropy loss: -0.0009  | Total Loss: 0.28 | Total Steps: 7\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1674/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0000  | Total Loss: 0.19 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1675/94000  | Episode Reward: 8  | Average Reward 9.01  | Actor loss: -0.01 | Critic loss: 7.21 | Entropy loss: -0.0004  | Total Loss: 7.20 | Total Steps: 30\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1676/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: -0.10 | Critic loss: 2.28 | Entropy loss: -0.0003  | Total Loss: 2.18 | Total Steps: 29\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1677/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: -0.04 | Critic loss: 5.04 | Entropy loss: -0.0007  | Total Loss: 5.01 | Total Steps: 43\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1678/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: 0.00 | Critic loss: 1.48 | Entropy loss: -0.0000  | Total Loss: 1.49 | Total Steps: 31\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1679/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0000  | Total Loss: 0.10 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1680/94000  | Episode Reward: 10  | Average Reward 9.08  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1681/94000  | Episode Reward: 10  | Average Reward 9.11  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0000  | Total Loss: 0.12 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1682/94000  | Episode Reward: 10  | Average Reward 9.11  | Actor loss: -0.21 | Critic loss: 3.12 | Entropy loss: -0.0014  | Total Loss: 2.91 | Total Steps: 56\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1683/94000  | Episode Reward: 10  | Average Reward 9.11  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0000  | Total Loss: 0.18 | Total Steps: 6\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1684/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.32 | Critic loss: 0.94 | Entropy loss: -0.0007  | Total Loss: 1.26 | Total Steps: 10\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1685/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.04 | Critic loss: 1.94 | Entropy loss: -0.0012  | Total Loss: 1.98 | Total Steps: 48\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1686/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: -0.09 | Critic loss: 0.14 | Entropy loss: -0.0007  | Total Loss: 0.05 | Total Steps: 12\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1687/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.00 | Critic loss: 1.34 | Entropy loss: -0.0000  | Total Loss: 1.34 | Total Steps: 31\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1688/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: -0.10 | Critic loss: 5.01 | Entropy loss: -0.0015  | Total Loss: 4.91 | Total Steps: 44\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1689/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.10 | Critic loss: 4.82 | Entropy loss: -0.0005  | Total Loss: 4.92 | Total Steps: 29\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1690/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.00 | Critic loss: 1.44 | Entropy loss: -0.0000  | Total Loss: 1.44 | Total Steps: 31\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1691/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.01 | Critic loss: 1.03 | Entropy loss: -0.0001  | Total Loss: 1.04 | Total Steps: 31\n",
      "\n",
      "---black capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1692/94000  | Episode Reward: 10  | Average Reward 9.14  | Actor loss: 0.00 | Critic loss: 1.00 | Entropy loss: -0.0000  | Total Loss: 1.00 | Total Steps: 31\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1693/94000  | Episode Reward: 10  | Average Reward 9.14  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0000  | Total Loss: 0.15 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1694/94000  | Episode Reward: 10  | Average Reward 9.14  | Actor loss: 0.01 | Critic loss: 0.02 | Entropy loss: -0.0007  | Total Loss: 0.02 | Total Steps: 9\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1695/94000  | Episode Reward: 10  | Average Reward 9.14  | Actor loss: -0.09 | Critic loss: 2.33 | Entropy loss: -0.0009  | Total Loss: 2.24 | Total Steps: 36\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1696/94000  | Episode Reward: 10  | Average Reward 9.14  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1697/94000  | Episode Reward: 10  | Average Reward 9.14  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1698/94000  | Episode Reward: 10  | Average Reward 9.14  | Actor loss: 0.36 | Critic loss: 1.13 | Entropy loss: -0.0016  | Total Loss: 1.49 | Total Steps: 36\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1699/94000  | Episode Reward: 10  | Average Reward 9.14  | Actor loss: 0.02 | Critic loss: 0.08 | Entropy loss: -0.0004  | Total Loss: 0.11 | Total Steps: 8\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1700/94000  | Episode Reward: 8  | Average Reward 9.14  | Actor loss: -0.02 | Critic loss: 5.13 | Entropy loss: -0.0023  | Total Loss: 5.11 | Total Steps: 52\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1701/94000  | Episode Reward: 8  | Average Reward 9.12  | Actor loss: -0.00 | Critic loss: 1.99 | Entropy loss: -0.0000  | Total Loss: 1.98 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 1/100  | Episode Reward: -10  | Average Reward 7.57  | Actor loss: -0.00 | Critic loss: 79.05 | Entropy loss: -0.0019  | Total Loss: 79.05 | Total Steps: 500\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 10  | Average Reward 7.59  | Actor loss: 0.00 | Critic loss: 0.29 | Entropy loss: -0.0005  | Total Loss: 0.29 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 3/100  | Episode Reward: 10  | Average Reward 7.62  | Actor loss: 0.00 | Critic loss: 0.22 | Entropy loss: -0.0004  | Total Loss: 0.23 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 10  | Average Reward 7.67  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0013  | Total Loss: 0.05 | Total Steps: 50\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 5  | Average Reward 7.62  | Actor loss: 0.01 | Critic loss: 0.10 | Entropy loss: -0.0024  | Total Loss: 0.10 | Total Steps: 46\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 8  | Average Reward 7.59  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0073  | Total Loss: 0.03 | Total Steps: 51\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: 2  | Average Reward 7.54  | Actor loss: 0.01 | Critic loss: 0.68 | Entropy loss: -0.0033  | Total Loss: 0.68 | Total Steps: 49\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 10  | Average Reward 7.62  | Actor loss: 0.14 | Critic loss: 0.74 | Entropy loss: -0.0489  | Total Loss: 0.84 | Total Steps: 9\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 10  | Average Reward 7.62  | Actor loss: 0.01 | Critic loss: 0.25 | Entropy loss: -0.0096  | Total Loss: 0.26 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 8  | Average Reward 7.62  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0012  | Total Loss: 0.02 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 10  | Average Reward 7.62  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0552  | Total Loss: 0.01 | Total Steps: 7\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 10  | Average Reward 7.62  | Actor loss: 0.01 | Critic loss: 0.28 | Entropy loss: -0.0698  | Total Loss: 0.21 | Total Steps: 9\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 5  | Average Reward 7.57  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0023  | Total Loss: 0.10 | Total Steps: 49\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: 10  | Average Reward 7.57  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0305  | Total Loss: -0.01 | Total Steps: 7\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 10  | Average Reward 7.57  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0052  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 10  | Average Reward 7.62  | Actor loss: 0.00 | Critic loss: 0.74 | Entropy loss: -0.0342  | Total Loss: 0.71 | Total Steps: 9\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 10  | Average Reward 7.62  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0070  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 10  | Average Reward 7.62  | Actor loss: 0.01 | Critic loss: 0.24 | Entropy loss: -0.0028  | Total Loss: 0.25 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 10  | Average Reward 7.62  | Actor loss: 0.00 | Critic loss: 0.47 | Entropy loss: -0.0140  | Total Loss: 0.46 | Total Steps: 10\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: 10  | Average Reward 7.64  | Actor loss: 0.07 | Critic loss: 3.27 | Entropy loss: -0.0256  | Total Loss: 3.31 | Total Steps: 49\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 10  | Average Reward 7.64  | Actor loss: 0.00 | Critic loss: 0.37 | Entropy loss: -0.0045  | Total Loss: 0.37 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 22/100  | Episode Reward: 10  | Average Reward 7.64  | Actor loss: 0.00 | Critic loss: 0.24 | Entropy loss: -0.0299  | Total Loss: 0.21 | Total Steps: 7\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 10  | Average Reward 7.68  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0248  | Total Loss: 0.01 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 8  | Average Reward 7.66  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0015  | Total Loss: 0.15 | Total Steps: 29\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 8  | Average Reward 7.63  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0004  | Total Loss: 0.05 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 10  | Average Reward 7.63  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0008  | Total Loss: 0.10 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 10  | Average Reward 7.63  | Actor loss: 0.00 | Critic loss: 0.29 | Entropy loss: -0.0003  | Total Loss: 0.30 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 10  | Average Reward 7.64  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0008  | Total Loss: 0.11 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 10  | Average Reward 7.69  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0623  | Total Loss: -0.04 | Total Steps: 7\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 10  | Average Reward 7.71  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0105  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 10  | Average Reward 7.71  | Actor loss: -0.00 | Critic loss: 0.07 | Entropy loss: -0.0094  | Total Loss: 0.06 | Total Steps: 40\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 32/100  | Episode Reward: 10  | Average Reward 7.76  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0004  | Total Loss: 0.00 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 33/100  | Episode Reward: 8  | Average Reward 7.94  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0059  | Total Loss: 0.09 | Total Steps: 162\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 34/100  | Episode Reward: 8  | Average Reward 7.93  | Actor loss: 0.06 | Critic loss: 2.69 | Entropy loss: -0.0547  | Total Loss: 2.69 | Total Steps: 56\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 35/100  | Episode Reward: 10  | Average Reward 8.49  | Actor loss: 0.00 | Critic loss: 1.52 | Entropy loss: -0.0416  | Total Loss: 1.48 | Total Steps: 7\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 36/100  | Episode Reward: 8  | Average Reward 8.49  | Actor loss: 0.00 | Critic loss: 0.66 | Entropy loss: -0.0025  | Total Loss: 0.66 | Total Steps: 29\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 37/100  | Episode Reward: 5  | Average Reward 8.44  | Actor loss: 0.00 | Critic loss: 0.75 | Entropy loss: -0.0140  | Total Loss: 0.73 | Total Steps: 52\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: 8  | Average Reward 8.41  | Actor loss: 0.00 | Critic loss: 0.66 | Entropy loss: -0.0016  | Total Loss: 0.66 | Total Steps: 29\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 5  | Average Reward 8.41  | Actor loss: 1.27 | Critic loss: 5.39 | Entropy loss: -0.0107  | Total Loss: 6.65 | Total Steps: 48\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 10  | Average Reward 8.41  | Actor loss: 0.01 | Critic loss: 2.62 | Entropy loss: -0.0104  | Total Loss: 2.62 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 8  | Average Reward 8.39  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0100  | Total Loss: -0.01 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 5  | Average Reward 8.34  | Actor loss: -0.00 | Critic loss: 0.06 | Entropy loss: -0.0179  | Total Loss: 0.04 | Total Steps: 51\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 43/100  | Episode Reward: 8  | Average Reward 8.31  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0011  | Total Loss: 0.04 | Total Steps: 34\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 10  | Average Reward 8.31  | Actor loss: 0.00 | Critic loss: 0.39 | Entropy loss: -0.0034  | Total Loss: 0.39 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: 10  | Average Reward 8.37  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0522  | Total Loss: -0.01 | Total Steps: 7\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 10  | Average Reward 8.37  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0090  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 10  | Average Reward 8.39  | Actor loss: 0.00 | Critic loss: 0.29 | Entropy loss: -0.0044  | Total Loss: 0.29 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 10  | Average Reward 8.39  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0052  | Total Loss: -0.00 | Total Steps: 40\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 8  | Average Reward 8.37  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0003  | Total Loss: 0.14 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 8  | Average Reward 8.37  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0085  | Total Loss: 0.10 | Total Steps: 44\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 8  | Average Reward 8.39  | Actor loss: -0.00 | Critic loss: 0.04 | Entropy loss: -0.0024  | Total Loss: 0.04 | Total Steps: 49\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 10  | Average Reward 8.39  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0596  | Total Loss: -0.06 | Total Steps: 7\n",
      "TEST: ---black sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 53/100  | Episode Reward: 8  | Average Reward 8.39  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0027  | Total Loss: 0.21 | Total Steps: 34\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 54/100  | Episode Reward: 10  | Average Reward 8.39  | Actor loss: 0.00 | Critic loss: 0.73 | Entropy loss: -0.0003  | Total Loss: 0.73 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 8  | Average Reward 8.37  | Actor loss: 0.00 | Critic loss: 0.66 | Entropy loss: -0.0004  | Total Loss: 0.66 | Total Steps: 29\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: 8  | Average Reward 8.34  | Actor loss: 0.00 | Critic loss: 0.85 | Entropy loss: -0.0141  | Total Loss: 0.84 | Total Steps: 50\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 10  | Average Reward 8.34  | Actor loss: 0.01 | Critic loss: 4.91 | Entropy loss: -0.0190  | Total Loss: 4.90 | Total Steps: 10\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 10  | Average Reward 8.34  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0345  | Total Loss: 0.10 | Total Steps: 7\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 10  | Average Reward 8.34  | Actor loss: 0.04 | Critic loss: 0.44 | Entropy loss: -0.0707  | Total Loss: 0.42 | Total Steps: 8\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 60/100  | Episode Reward: 10  | Average Reward 8.34  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0024  | Total Loss: -0.00 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 61/100  | Episode Reward: 10  | Average Reward 8.34  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0039  | Total Loss: 0.02 | Total Steps: 34\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 10  | Average Reward 8.37  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0014  | Total Loss: 0.14 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: 10  | Average Reward 8.37  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0005  | Total Loss: 0.07 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 64/100  | Episode Reward: 9  | Average Reward 8.36  | Actor loss: 0.00 | Critic loss: 0.96 | Entropy loss: -0.0230  | Total Loss: 0.94 | Total Steps: 66\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 65/100  | Episode Reward: 8  | Average Reward 8.36  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0008  | Total Loss: 0.14 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 10  | Average Reward 8.36  | Actor loss: 0.01 | Critic loss: 0.18 | Entropy loss: -0.0049  | Total Loss: 0.18 | Total Steps: 36\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 10  | Average Reward 8.36  | Actor loss: 0.01 | Critic loss: 0.17 | Entropy loss: -0.0179  | Total Loss: 0.17 | Total Steps: 10\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 68/100  | Episode Reward: 10  | Average Reward 8.36  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0031  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 69/100  | Episode Reward: -10  | Average Reward 8.15  | Actor loss: -0.00 | Critic loss: 87.23 | Entropy loss: -0.0000  | Total Loss: 87.22 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 70/100  | Episode Reward: 10  | Average Reward 8.16  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0315  | Total Loss: 0.00 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0054  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 9  | Average Reward 8.19  | Actor loss: 0.08 | Critic loss: 1.75 | Entropy loss: -0.0571  | Total Loss: 1.77 | Total Steps: 34\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0097  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: 6  | Average Reward 8.18  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0501  | Total Loss: -0.04 | Total Steps: 51\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 8  | Average Reward 8.15  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0015  | Total Loss: 0.17 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 10  | Average Reward 8.15  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0004  | Total Loss: 0.08 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 77/100  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0001  | Total Loss: 0.00 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 10  | Average Reward 8.23  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0151  | Total Loss: 0.01 | Total Steps: 36\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 5  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0016  | Total Loss: 0.13 | Total Steps: 42\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 0.31 | Entropy loss: -0.0032  | Total Loss: 0.31 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0094  | Total Loss: 0.17 | Total Steps: 22\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 1.23 | Entropy loss: -0.0284  | Total Loss: 1.20 | Total Steps: 51\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.01 | Critic loss: 2.48 | Entropy loss: -0.0132  | Total Loss: 2.48 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 84/100  | Episode Reward: 10  | Average Reward 8.23  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0348  | Total Loss: 0.02 | Total Steps: 7\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 85/100  | Episode Reward: 10  | Average Reward 8.43  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0013  | Total Loss: 0.01 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: 10  | Average Reward 8.48  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0375  | Total Loss: -0.01 | Total Steps: 9\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 10  | Average Reward 8.48  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0064  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 8  | Average Reward 8.51  | Actor loss: 0.00 | Critic loss: 0.22 | Entropy loss: -0.0006  | Total Loss: 0.22 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 89/100  | Episode Reward: 10  | Average Reward 8.53  | Actor loss: 0.00 | Critic loss: 1.35 | Entropy loss: -0.0383  | Total Loss: 1.32 | Total Steps: 58\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 90/100  | Episode Reward: 10  | Average Reward 8.53  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0994  | Total Loss: 0.12 | Total Steps: 9\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 10  | Average Reward 8.53  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0325  | Total Loss: -0.02 | Total Steps: 10\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 10  | Average Reward 8.55  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0012  | Total Loss: 0.03 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: 10  | Average Reward 8.61  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0001  | Total Loss: 0.00 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 10  | Average Reward 8.61  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0002  | Total Loss: 0.07 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: 9  | Average Reward 8.60  | Actor loss: 0.05 | Critic loss: 1.95 | Entropy loss: -0.0335  | Total Loss: 1.96 | Total Steps: 52\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0057  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 5  | Average Reward 8.54  | Actor loss: 0.00 | Critic loss: 0.41 | Entropy loss: -0.0092  | Total Loss: 0.41 | Total Steps: 48\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: 10  | Average Reward 8.54  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0021  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 8  | Average Reward 8.54  | Actor loss: 0.00 | Critic loss: 0.26 | Entropy loss: -0.0017  | Total Loss: 0.26 | Total Steps: 34\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 8  | Average Reward 8.59  | Actor loss: 0.00 | Critic loss: 0.64 | Entropy loss: -0.0021  | Total Loss: 0.64 | Total Steps: 29\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1702/94000  | Episode Reward: 5  | Average Reward 9.06  | Actor loss: -0.36 | Critic loss: 6.80 | Entropy loss: -0.0024  | Total Loss: 6.44 | Total Steps: 63\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1703/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1704/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 1705/94000  | Episode Reward: -10  | Average Reward 8.87  | Actor loss: -0.03 | Critic loss: 7.52 | Entropy loss: -0.0008  | Total Loss: 7.49 | Total Steps: 500\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1706/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0000  | Total Loss: 0.13 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1707/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.18 | Critic loss: 4.37 | Entropy loss: -0.0033  | Total Loss: 4.55 | Total Steps: 51\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1708/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.09 | Critic loss: 0.38 | Entropy loss: -0.0004  | Total Loss: 0.47 | Total Steps: 9\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1709/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: -0.10 | Critic loss: 1.20 | Entropy loss: -0.0012  | Total Loss: 1.10 | Total Steps: 9\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1710/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: -0.02 | Critic loss: 0.53 | Entropy loss: -0.0012  | Total Loss: 0.51 | Total Steps: 16\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1711/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.00 | Critic loss: 2.08 | Entropy loss: -0.0000  | Total Loss: 2.08 | Total Steps: 31\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1712/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.00 | Critic loss: 1.38 | Entropy loss: -0.0001  | Total Loss: 1.38 | Total Steps: 31\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1713/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: -0.00 | Critic loss: 2.43 | Entropy loss: -0.0003  | Total Loss: 2.42 | Total Steps: 49\n",
      "\n",
      "---black cube---\n",
      "Step: 250\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1714/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: 0.14 | Critic loss: 1.34 | Entropy loss: -0.0018  | Total Loss: 1.48 | Total Steps: 426\n",
      "\n",
      "---black cube---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 1715/94000  | Episode Reward: -10  | Average Reward 8.72  | Actor loss: -0.00 | Critic loss: 2.77 | Entropy loss: -0.0002  | Total Loss: 2.77 | Total Steps: 500\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1716/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---green prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1717/94000  | Episode Reward: 8  | Average Reward 8.70  | Actor loss: -0.00 | Critic loss: 4.04 | Entropy loss: -0.0000  | Total Loss: 4.03 | Total Steps: 30\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1718/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 3.52 | Entropy loss: -0.0000  | Total Loss: 3.52 | Total Steps: 31\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1719/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.08 | Critic loss: 1.00 | Entropy loss: -0.0002  | Total Loss: 1.08 | Total Steps: 8\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1720/94000  | Episode Reward: 10  | Average Reward 8.70  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0000  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1721/94000  | Episode Reward: 8  | Average Reward 8.75  | Actor loss: 0.01 | Critic loss: 2.02 | Entropy loss: -0.0010  | Total Loss: 2.04 | Total Steps: 77\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1722/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.01 | Critic loss: 4.42 | Entropy loss: -0.0003  | Total Loss: 4.43 | Total Steps: 9\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1723/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.02 | Critic loss: 4.15 | Entropy loss: -0.0007  | Total Loss: 4.17 | Total Steps: 29\n",
      "\n",
      "---yellow cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1724/94000  | Episode Reward: 8  | Average Reward 8.72  | Actor loss: -0.72 | Critic loss: 2.91 | Entropy loss: -0.0021  | Total Loss: 2.19 | Total Steps: 15\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1725/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: 0.07 | Critic loss: 2.12 | Entropy loss: -0.0012  | Total Loss: 2.20 | Total Steps: 31\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1726/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: -0.51 | Critic loss: 2.14 | Entropy loss: -0.0054  | Total Loss: 1.63 | Total Steps: 36\n",
      "\n",
      "---black capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1727/94000  | Episode Reward: 8  | Average Reward 8.72  | Actor loss: -0.10 | Critic loss: 2.46 | Entropy loss: -0.0008  | Total Loss: 2.36 | Total Steps: 46\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1728/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0000  | Total Loss: 0.19 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1729/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: 0.54 | Critic loss: 2.52 | Entropy loss: -0.0018  | Total Loss: 3.06 | Total Steps: 36\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1730/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1731/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: 0.08 | Critic loss: 0.02 | Entropy loss: -0.0023  | Total Loss: 0.10 | Total Steps: 9\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1732/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: -0.23 | Critic loss: 0.23 | Entropy loss: -0.0014  | Total Loss: -0.00 | Total Steps: 12\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1733/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1734/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1735/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1736/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: -1.14 | Critic loss: 4.73 | Entropy loss: -0.0068  | Total Loss: 3.59 | Total Steps: 52\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1737/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.00 | Critic loss: 1.66 | Entropy loss: -0.0000  | Total Loss: 1.66 | Total Steps: 31\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1738/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1739/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.00 | Critic loss: 1.10 | Entropy loss: -0.0000  | Total Loss: 1.10 | Total Steps: 31\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1740/94000  | Episode Reward: 5  | Average Reward 8.75  | Actor loss: -0.03 | Critic loss: 3.46 | Entropy loss: -0.0009  | Total Loss: 3.42 | Total Steps: 49\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1741/94000  | Episode Reward: 8  | Average Reward 8.72  | Actor loss: -0.01 | Critic loss: 4.19 | Entropy loss: -0.0001  | Total Loss: 4.18 | Total Steps: 49\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1742/94000  | Episode Reward: 8  | Average Reward 8.70  | Actor loss: -0.05 | Critic loss: 3.91 | Entropy loss: -0.0003  | Total Loss: 3.86 | Total Steps: 39\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1743/94000  | Episode Reward: 10  | Average Reward 8.72  | Actor loss: 0.04 | Critic loss: 0.68 | Entropy loss: -0.0008  | Total Loss: 0.72 | Total Steps: 43\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1744/94000  | Episode Reward: 10  | Average Reward 8.75  | Actor loss: 0.04 | Critic loss: 0.06 | Entropy loss: -0.0013  | Total Loss: 0.09 | Total Steps: 8\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -1.0\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1745/94000  | Episode Reward: 9  | Average Reward 8.74  | Actor loss: 0.04 | Critic loss: 1.17 | Entropy loss: -0.0035  | Total Loss: 1.21 | Total Steps: 37\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1746/94000  | Episode Reward: 10  | Average Reward 8.94  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0000  | Total Loss: 0.14 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1747/94000  | Episode Reward: 8  | Average Reward 8.91  | Actor loss: -0.44 | Critic loss: 5.08 | Entropy loss: -0.0032  | Total Loss: 4.63 | Total Steps: 54\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1748/94000  | Episode Reward: 5  | Average Reward 8.87  | Actor loss: -0.43 | Critic loss: 4.81 | Entropy loss: -0.0018  | Total Loss: 4.38 | Total Steps: 45\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  | Episode: 1749/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1750/94000  | Episode Reward: 8  | Average Reward 8.84  | Actor loss: -1.51 | Critic loss: 6.10 | Entropy loss: -0.0326  | Total Loss: 4.56 | Total Steps: 155\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1751/94000  | Episode Reward: 5  | Average Reward 8.79  | Actor loss: -0.59 | Critic loss: 5.97 | Entropy loss: -0.0024  | Total Loss: 5.38 | Total Steps: 53\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1752/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.01 | Critic loss: 1.21 | Entropy loss: -0.0001  | Total Loss: 1.22 | Total Steps: 31\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1753/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.00 | Critic loss: 1.10 | Entropy loss: -0.0000  | Total Loss: 1.10 | Total Steps: 31\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1754/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.03 | Critic loss: 0.49 | Entropy loss: -0.0001  | Total Loss: 0.51 | Total Steps: 8\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1755/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.25 | Critic loss: 4.35 | Entropy loss: -0.0038  | Total Loss: 4.60 | Total Steps: 31\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1756/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: -0.17 | Critic loss: 4.38 | Entropy loss: -0.0062  | Total Loss: 4.21 | Total Steps: 60\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1757/94000  | Episode Reward: 4  | Average Reward 8.93  | Actor loss: -0.63 | Critic loss: 6.53 | Entropy loss: -0.0049  | Total Loss: 5.90 | Total Steps: 46\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1758/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: 0.05 | Critic loss: 0.10 | Entropy loss: -0.0007  | Total Loss: 0.15 | Total Steps: 9\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1759/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: -0.00 | Critic loss: 0.14 | Entropy loss: -0.0020  | Total Loss: 0.14 | Total Steps: 7\n",
      "\n",
      "---red sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1760/94000  | Episode Reward: 8  | Average Reward 8.93  | Actor loss: 0.02 | Critic loss: 0.77 | Entropy loss: -0.0007  | Total Loss: 0.79 | Total Steps: 40\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1761/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0000  | Total Loss: 0.21 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1762/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0000  | Total Loss: 0.15 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1763/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1764/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: 0.01 | Critic loss: 0.46 | Entropy loss: -0.0001  | Total Loss: 0.47 | Total Steps: 38\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1765/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0000  | Total Loss: 0.18 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1766/94000  | Episode Reward: 10  | Average Reward 8.98  | Actor loss: -0.61 | Critic loss: 1.63 | Entropy loss: -0.0025  | Total Loss: 1.02 | Total Steps: 23\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1767/94000  | Episode Reward: 10  | Average Reward 8.98  | Actor loss: -0.55 | Critic loss: 3.85 | Entropy loss: -0.0042  | Total Loss: 3.29 | Total Steps: 32\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1768/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: -0.33 | Critic loss: 1.02 | Entropy loss: -0.0045  | Total Loss: 0.68 | Total Steps: 36\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1769/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: 0.12 | Critic loss: 1.68 | Entropy loss: -0.0020  | Total Loss: 1.79 | Total Steps: 47\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1770/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: -0.21 | Critic loss: 2.42 | Entropy loss: -0.0021  | Total Loss: 2.20 | Total Steps: 50\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1771/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: 0.13 | Critic loss: 1.12 | Entropy loss: -0.0009  | Total Loss: 1.25 | Total Steps: 44\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1772/94000  | Episode Reward: 8  | Average Reward 9.01  | Actor loss: -0.10 | Critic loss: 1.76 | Entropy loss: -0.0004  | Total Loss: 1.66 | Total Steps: 30\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1773/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: 0.06 | Critic loss: 0.26 | Entropy loss: -0.0015  | Total Loss: 0.32 | Total Steps: 8\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1774/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: 0.00 | Critic loss: 1.54 | Entropy loss: -0.0000  | Total Loss: 1.54 | Total Steps: 31\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1775/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0000  | Total Loss: 0.15 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1776/94000  | Episode Reward: 8  | Average Reward 9.01  | Actor loss: -0.14 | Critic loss: 8.01 | Entropy loss: -0.0005  | Total Loss: 7.87 | Total Steps: 43\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1777/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: 0.01 | Critic loss: 0.81 | Entropy loss: -0.0000  | Total Loss: 0.81 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1778/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: -0.08 | Critic loss: 1.40 | Entropy loss: -0.0034  | Total Loss: 1.32 | Total Steps: 34\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1779/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: -0.23 | Critic loss: 3.13 | Entropy loss: -0.0018  | Total Loss: 2.90 | Total Steps: 38\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1780/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: -0.56 | Critic loss: 3.39 | Entropy loss: -0.0074  | Total Loss: 2.83 | Total Steps: 46\n",
      "\n",
      "---yellow sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1781/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: -0.04 | Critic loss: 6.18 | Entropy loss: -0.0028  | Total Loss: 6.14 | Total Steps: 57\n",
      "\n",
      "---yellow cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1782/94000  | Episode Reward: -8  | Average Reward 8.83  | Actor loss: -2.67 | Critic loss: 23.43 | Entropy loss: -0.0192  | Total Loss: 20.74 | Total Steps: 109\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1783/94000  | Episode Reward: 10  | Average Reward 8.83  | Actor loss: 0.06 | Critic loss: 2.38 | Entropy loss: -0.0011  | Total Loss: 2.44 | Total Steps: 49\n",
      "\n",
      "---red cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1784/94000  | Episode Reward: 8  | Average Reward 8.80  | Actor loss: -0.42 | Critic loss: 4.40 | Entropy loss: -0.0024  | Total Loss: 3.97 | Total Steps: 52\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1785/94000  | Episode Reward: 8  | Average Reward 8.78  | Actor loss: 0.01 | Critic loss: 1.43 | Entropy loss: -0.0005  | Total Loss: 1.43 | Total Steps: 37\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1786/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.06 | Critic loss: 1.56 | Entropy loss: -0.0008  | Total Loss: 1.63 | Total Steps: 30\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1787/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: 0.01 | Critic loss: 0.84 | Entropy loss: -0.0000  | Total Loss: 0.85 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1788/94000  | Episode Reward: 10  | Average Reward 8.78  | Actor loss: -0.49 | Critic loss: 7.98 | Entropy loss: -0.0137  | Total Loss: 7.47 | Total Steps: 157\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Step: 250\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1789/94000  | Episode Reward: 0  | Average Reward 8.68  | Actor loss: -0.46 | Critic loss: 6.49 | Entropy loss: -0.0031  | Total Loss: 6.02 | Total Steps: 326\n",
      "\n",
      "---red sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1790/94000  | Episode Reward: 8  | Average Reward 8.65  | Actor loss: -0.18 | Critic loss: 4.60 | Entropy loss: -0.0021  | Total Loss: 4.41 | Total Steps: 39\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1791/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.26 | Critic loss: 2.19 | Entropy loss: -0.0006  | Total Loss: 2.45 | Total Steps: 9\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1792/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: -0.32 | Critic loss: 2.47 | Entropy loss: -0.0062  | Total Loss: 2.14 | Total Steps: 55\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1793/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 2.14 | Entropy loss: -0.0000  | Total Loss: 2.15 | Total Steps: 31\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1794/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: -0.62 | Critic loss: 3.63 | Entropy loss: -0.0056  | Total Loss: 3.01 | Total Steps: 63\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1795/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 1.32 | Entropy loss: -0.0003  | Total Loss: 1.32 | Total Steps: 49\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1796/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.00 | Critic loss: 0.24 | Entropy loss: -0.0000  | Total Loss: 0.24 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1797/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.01 | Critic loss: 0.58 | Entropy loss: -0.0000  | Total Loss: 0.59 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1798/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.01 | Critic loss: 0.43 | Entropy loss: -0.0000  | Total Loss: 0.44 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1799/94000  | Episode Reward: 10  | Average Reward 8.65  | Actor loss: 0.03 | Critic loss: 0.74 | Entropy loss: -0.0010  | Total Loss: 0.77 | Total Steps: 34\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1800/94000  | Episode Reward: 8  | Average Reward 8.65  | Actor loss: -0.14 | Critic loss: 2.22 | Entropy loss: -0.0009  | Total Loss: 2.08 | Total Steps: 30\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1801/94000  | Episode Reward: 10  | Average Reward 8.68  | Actor loss: 0.24 | Critic loss: 0.66 | Entropy loss: -0.0006  | Total Loss: 0.90 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 10  | Average Reward 8.79  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0002  | Total Loss: 0.16 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 2/100  | Episode Reward: -10  | Average Reward 8.59  | Actor loss: -0.01 | Critic loss: 80.81 | Entropy loss: -0.0017  | Total Loss: 80.80 | Total Steps: 500\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 3/100  | Episode Reward: 10  | Average Reward 8.59  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0003  | Total Loss: 0.13 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 2  | Average Reward 8.51  | Actor loss: 8.03 | Critic loss: 27.43 | Entropy loss: -0.0676  | Total Loss: 35.39 | Total Steps: 131\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 10  | Average Reward 8.56  | Actor loss: 0.00 | Critic loss: 0.43 | Entropy loss: -0.0210  | Total Loss: 0.41 | Total Steps: 10\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 10  | Average Reward 8.59  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0042  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: -10  | Average Reward 8.46  | Actor loss: 16.04 | Critic loss: 48.83 | Entropy loss: -0.0846  | Total Loss: 64.78 | Total Steps: 180\n",
      "TEST: ---blue cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 8  | Average Reward 8.44  | Actor loss: 0.01 | Critic loss: 0.49 | Entropy loss: -0.0092  | Total Loss: 0.49 | Total Steps: 40\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 10  | Average Reward 8.44  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0017  | Total Loss: 0.06 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: 0.00 | Critic loss: 1.88 | Entropy loss: -0.0005  | Total Loss: 1.89 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: 0.02 | Critic loss: 0.14 | Entropy loss: -0.0380  | Total Loss: 0.12 | Total Steps: 13\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 400\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: -2  | Average Reward 8.34  | Actor loss: 0.00 | Critic loss: 1.81 | Entropy loss: -0.0834  | Total Loss: 1.73 | Total Steps: 419\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 5  | Average Reward 8.34  | Actor loss: 0.00 | Critic loss: 0.28 | Entropy loss: -0.0105  | Total Loss: 0.27 | Total Steps: 42\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 14/100  | Episode Reward: -10  | Average Reward 8.14  | Actor loss: -0.00 | Critic loss: 78.67 | Entropy loss: -0.0033  | Total Loss: 78.67 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 8  | Average Reward 8.12  | Actor loss: 0.00 | Critic loss: 0.22 | Entropy loss: -0.0006  | Total Loss: 0.22 | Total Steps: 38\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 10  | Average Reward 8.12  | Actor loss: 0.25 | Critic loss: 3.36 | Entropy loss: -0.0217  | Total Loss: 3.58 | Total Steps: 29\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 8  | Average Reward 8.09  | Actor loss: 0.02 | Critic loss: 1.53 | Entropy loss: -0.0042  | Total Loss: 1.54 | Total Steps: 43\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 8  | Average Reward 8.06  | Actor loss: 0.00 | Critic loss: 0.44 | Entropy loss: -0.0030  | Total Loss: 0.44 | Total Steps: 48\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 10  | Average Reward 8.06  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0012  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: 0  | Average Reward 7.96  | Actor loss: 20.24 | Critic loss: 46.58 | Entropy loss: -0.0684  | Total Loss: 66.75 | Total Steps: 126\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 8  | Average Reward 7.94  | Actor loss: 0.00 | Critic loss: 0.69 | Entropy loss: -0.0091  | Total Loss: 0.68 | Total Steps: 38\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 22/100  | Episode Reward: 8  | Average Reward 7.92  | Actor loss: 0.00 | Critic loss: 0.25 | Entropy loss: -0.0175  | Total Loss: 0.23 | Total Steps: 64\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 10  | Average Reward 7.92  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0032  | Total Loss: 0.14 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 10  | Average Reward 7.94  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0187  | Total Loss: 0.06 | Total Steps: 10\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 10  | Average Reward 7.96  | Actor loss: 0.00 | Critic loss: 0.40 | Entropy loss: -0.0033  | Total Loss: 0.40 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 8  | Average Reward 7.94  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0033  | Total Loss: 0.18 | Total Steps: 30\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 10  | Average Reward 7.94  | Actor loss: 0.01 | Critic loss: 3.86 | Entropy loss: -0.0213  | Total Loss: 3.85 | Total Steps: 28\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 10  | Average Reward 7.94  | Actor loss: 0.11 | Critic loss: 2.88 | Entropy loss: -0.0029  | Total Loss: 2.99 | Total Steps: 40\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 10  | Average Reward 7.94  | Actor loss: 0.00 | Critic loss: 0.24 | Entropy loss: -0.0378  | Total Loss: 0.20 | Total Steps: 65\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 10  | Average Reward 7.94  | Actor loss: 0.21 | Critic loss: 1.79 | Entropy loss: -0.0144  | Total Loss: 1.99 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 9  | Average Reward 7.93  | Actor loss: 0.87 | Critic loss: 13.23 | Entropy loss: -0.0660  | Total Loss: 14.03 | Total Steps: 36\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 32/100  | Episode Reward: 9  | Average Reward 7.92  | Actor loss: 2.56 | Critic loss: 13.63 | Entropy loss: -0.0316  | Total Loss: 16.15 | Total Steps: 27\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 33/100  | Episode Reward: 10  | Average Reward 7.95  | Actor loss: 0.00 | Critic loss: 0.36 | Entropy loss: -0.0011  | Total Loss: 0.36 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 34/100  | Episode Reward: -22  | Average Reward 7.65  | Actor loss: 0.00 | Critic loss: 1.06 | Entropy loss: -0.0740  | Total Loss: 0.99 | Total Steps: 495\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 35/100  | Episode Reward: 10  | Average Reward 7.65  | Actor loss: 0.00 | Critic loss: 1.23 | Entropy loss: -0.0025  | Total Loss: 1.23 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 36/100  | Episode Reward: 10  | Average Reward 7.67  | Actor loss: 0.04 | Critic loss: 2.54 | Entropy loss: -0.0379  | Total Loss: 2.54 | Total Steps: 7\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 37/100  | Episode Reward: 10  | Average Reward 7.72  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0073  | Total Loss: 0.02 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: -9  | Average Reward 7.56  | Actor loss: 3.11 | Critic loss: 17.98 | Entropy loss: -0.0758  | Total Loss: 21.01 | Total Steps: 418\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 10  | Average Reward 7.61  | Actor loss: 0.24 | Critic loss: 2.19 | Entropy loss: -0.0381  | Total Loss: 2.39 | Total Steps: 17\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 8  | Average Reward 7.58  | Actor loss: 0.00 | Critic loss: 0.35 | Entropy loss: -0.0014  | Total Loss: 0.35 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 8  | Average Reward 7.58  | Actor loss: 0.00 | Critic loss: 0.18 | Entropy loss: -0.0032  | Total Loss: 0.18 | Total Steps: 30\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 9  | Average Reward 7.62  | Actor loss: 0.01 | Critic loss: 0.38 | Entropy loss: -0.0682  | Total Loss: 0.32 | Total Steps: 18\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 43/100  | Episode Reward: 5  | Average Reward 7.60  | Actor loss: 0.02 | Critic loss: 0.47 | Entropy loss: -0.0126  | Total Loss: 0.47 | Total Steps: 107\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 8  | Average Reward 7.58  | Actor loss: 0.00 | Critic loss: 1.08 | Entropy loss: -0.0007  | Total Loss: 1.08 | Total Steps: 29\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: 8  | Average Reward 7.55  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0005  | Total Loss: 0.21 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 10  | Average Reward 7.55  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0003  | Total Loss: 0.10 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 2  | Average Reward 7.47  | Actor loss: 0.04 | Critic loss: 0.92 | Entropy loss: -0.0134  | Total Loss: 0.95 | Total Steps: 74\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 10  | Average Reward 7.47  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0244  | Total Loss: 0.03 | Total Steps: 10\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 49/100  | Episode Reward: -36  | Average Reward 7.04  | Actor loss: -0.10 | Critic loss: 87.40 | Entropy loss: -0.0829  | Total Loss: 87.22 | Total Steps: 500\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 10  | Average Reward 7.07  | Actor loss: 0.00 | Critic loss: 0.69 | Entropy loss: -0.0036  | Total Loss: 0.69 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 10  | Average Reward 7.09  | Actor loss: 0.01 | Critic loss: 1.62 | Entropy loss: -0.0153  | Total Loss: 1.61 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 10  | Average Reward 7.09  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0007  | Total Loss: 0.15 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 53/100  | Episode Reward: 10  | Average Reward 7.12  | Actor loss: 0.03 | Critic loss: 1.26 | Entropy loss: -0.0416  | Total Loss: 1.24 | Total Steps: 17\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 54/100  | Episode Reward: -10  | Average Reward 6.92  | Actor loss: -0.01 | Critic loss: 78.34 | Entropy loss: -0.0006  | Total Loss: 78.33 | Total Steps: 500\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 10  | Average Reward 6.95  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0003  | Total Loss: 0.10 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: 9  | Average Reward 6.96  | Actor loss: 0.35 | Critic loss: 8.04 | Entropy loss: -0.0492  | Total Loss: 8.34 | Total Steps: 11\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 10  | Average Reward 6.96  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0091  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 8  | Average Reward 6.93  | Actor loss: 0.80 | Critic loss: 1.31 | Entropy loss: -0.0185  | Total Loss: 2.09 | Total Steps: 53\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 6  | Average Reward 6.90  | Actor loss: 0.00 | Critic loss: 0.40 | Entropy loss: -0.0112  | Total Loss: 0.39 | Total Steps: 96\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 60/100  | Episode Reward: 10  | Average Reward 6.90  | Actor loss: 0.03 | Critic loss: 3.39 | Entropy loss: -0.0970  | Total Loss: 3.33 | Total Steps: 9\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 61/100  | Episode Reward: 5  | Average Reward 6.85  | Actor loss: 0.00 | Critic loss: 0.37 | Entropy loss: -0.0027  | Total Loss: 0.37 | Total Steps: 49\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 10  | Average Reward 6.85  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0014  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: 5  | Average Reward 6.80  | Actor loss: 0.01 | Critic loss: 3.30 | Entropy loss: -0.0741  | Total Loss: 3.24 | Total Steps: 115\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 64/100  | Episode Reward: 10  | Average Reward 6.81  | Actor loss: 0.00 | Critic loss: 0.83 | Entropy loss: -0.0365  | Total Loss: 0.80 | Total Steps: 20\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 65/100  | Episode Reward: 10  | Average Reward 6.83  | Actor loss: 0.00 | Critic loss: 0.50 | Entropy loss: -0.0436  | Total Loss: 0.46 | Total Steps: 8\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 10  | Average Reward 6.83  | Actor loss: 0.01 | Critic loss: 3.65 | Entropy loss: -0.0090  | Total Loss: 3.66 | Total Steps: 36\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 10  | Average Reward 6.83  | Actor loss: 0.03 | Critic loss: 5.84 | Entropy loss: -0.0046  | Total Loss: 5.86 | Total Steps: 36\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 68/100  | Episode Reward: 10  | Average Reward 6.83  | Actor loss: 0.00 | Critic loss: 0.35 | Entropy loss: -0.0003  | Total Loss: 0.35 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 10  | Average Reward 7.04  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0004  | Total Loss: 0.21 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 70/100  | Episode Reward: 10  | Average Reward 7.04  | Actor loss: 4.54 | Critic loss: 6.13 | Entropy loss: -0.0555  | Total Loss: 10.62 | Total Steps: 7\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 10  | Average Reward 7.04  | Actor loss: 0.01 | Critic loss: 1.58 | Entropy loss: -0.0029  | Total Loss: 1.58 | Total Steps: 40\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 10  | Average Reward 7.04  | Actor loss: 0.23 | Critic loss: 9.70 | Entropy loss: -0.0176  | Total Loss: 9.91 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 8  | Average Reward 7.03  | Actor loss: 0.10 | Critic loss: 7.59 | Entropy loss: -0.0461  | Total Loss: 7.65 | Total Steps: 30\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: 10  | Average Reward 7.06  | Actor loss: 0.00 | Critic loss: 0.27 | Entropy loss: -0.0018  | Total Loss: 0.27 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 10  | Average Reward 7.08  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0005  | Total Loss: 0.07 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 5  | Average Reward 7.04  | Actor loss: 0.00 | Critic loss: 0.28 | Entropy loss: -0.0055  | Total Loss: 0.27 | Total Steps: 44\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 77/100  | Episode Reward: -2  | Average Reward 6.92  | Actor loss: 0.01 | Critic loss: 1.84 | Entropy loss: -0.0687  | Total Loss: 1.78 | Total Steps: 246\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 10  | Average Reward 6.92  | Actor loss: 0.00 | Critic loss: 0.39 | Entropy loss: -0.0117  | Total Loss: 0.39 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 10  | Average Reward 6.96  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0290  | Total Loss: 0.17 | Total Steps: 10\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 8  | Average Reward 6.94  | Actor loss: 0.00 | Critic loss: 0.35 | Entropy loss: -0.0077  | Total Loss: 0.35 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 8  | Average Reward 6.92  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0125  | Total Loss: 0.05 | Total Steps: 37\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: 8  | Average Reward 6.89  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0038  | Total Loss: 0.09 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 8  | Average Reward 6.87  | Actor loss: 0.00 | Critic loss: 1.14 | Entropy loss: -0.0032  | Total Loss: 1.14 | Total Steps: 34\n",
      "TEST: ---blue cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 84/100  | Episode Reward: -10  | Average Reward 6.67  | Actor loss: -0.01 | Critic loss: 91.18 | Entropy loss: -0.0016  | Total Loss: 91.17 | Total Steps: 500\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 85/100  | Episode Reward: 8  | Average Reward 6.64  | Actor loss: 0.08 | Critic loss: 1.13 | Entropy loss: -0.0034  | Total Loss: 1.21 | Total Steps: 44\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: 10  | Average Reward 6.64  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0003  | Total Loss: 0.16 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 8  | Average Reward 6.62  | Actor loss: 0.03 | Critic loss: 0.98 | Entropy loss: -0.0272  | Total Loss: 0.99 | Total Steps: 76\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 10  | Average Reward 6.64  | Actor loss: 0.01 | Critic loss: 0.41 | Entropy loss: -0.0050  | Total Loss: 0.41 | Total Steps: 41\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 89/100  | Episode Reward: 10  | Average Reward 6.64  | Actor loss: 0.03 | Critic loss: 0.78 | Entropy loss: -0.0051  | Total Loss: 0.80 | Total Steps: 39\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 90/100  | Episode Reward: -28  | Average Reward 6.26  | Actor loss: -0.52 | Critic loss: 88.41 | Entropy loss: -0.0822  | Total Loss: 87.80 | Total Steps: 500\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 10  | Average Reward 6.26  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0029  | Total Loss: 0.13 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 10  | Average Reward 6.26  | Actor loss: 0.05 | Critic loss: 14.60 | Entropy loss: -0.0089  | Total Loss: 14.64 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: -2  | Average Reward 6.14  | Actor loss: 0.02 | Critic loss: 0.95 | Entropy loss: -0.0741  | Total Loss: 0.89 | Total Steps: 183\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 10  | Average Reward 6.14  | Actor loss: 0.00 | Critic loss: 0.49 | Entropy loss: -0.0237  | Total Loss: 0.47 | Total Steps: 7\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: 8  | Average Reward 6.12  | Actor loss: 0.10 | Critic loss: 0.20 | Entropy loss: -0.0066  | Total Loss: 0.29 | Total Steps: 39\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 8  | Average Reward 6.10  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0073  | Total Loss: -0.00 | Total Steps: 45\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 8  | Average Reward 6.12  | Actor loss: 0.00 | Critic loss: 1.23 | Entropy loss: -0.0033  | Total Loss: 1.23 | Total Steps: 29\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: 8  | Average Reward 6.10  | Actor loss: 0.00 | Critic loss: 0.96 | Entropy loss: -0.0028  | Total Loss: 0.96 | Total Steps: 29\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 8  | Average Reward 6.10  | Actor loss: 0.00 | Critic loss: 1.04 | Entropy loss: -0.0160  | Total Loss: 1.02 | Total Steps: 59\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 10  | Average Reward 6.12  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0033  | Total Loss: 0.00 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1802/94000  | Episode Reward: 10  | Average Reward 8.73  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0000  | Total Loss: 0.16 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1803/94000  | Episode Reward: 8  | Average Reward 8.71  | Actor loss: 0.01 | Critic loss: 0.17 | Entropy loss: -0.0017  | Total Loss: 0.18 | Total Steps: 38\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1804/94000  | Episode Reward: 10  | Average Reward 8.71  | Actor loss: -0.01 | Critic loss: 3.84 | Entropy loss: -0.0001  | Total Loss: 3.83 | Total Steps: 42\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1805/94000  | Episode Reward: 8  | Average Reward 8.88  | Actor loss: -0.06 | Critic loss: 2.29 | Entropy loss: -0.0057  | Total Loss: 2.22 | Total Steps: 185\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1806/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.15 | Critic loss: 4.34 | Entropy loss: -0.0028  | Total Loss: 4.48 | Total Steps: 43\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1807/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.05 | Critic loss: 1.19 | Entropy loss: -0.0001  | Total Loss: 1.23 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1808/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.02 | Critic loss: 0.71 | Entropy loss: -0.0006  | Total Loss: 0.73 | Total Steps: 10\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1809/94000  | Episode Reward: 8  | Average Reward 8.86  | Actor loss: -0.01 | Critic loss: 1.38 | Entropy loss: -0.0016  | Total Loss: 1.37 | Total Steps: 31\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1810/94000  | Episode Reward: 10  | Average Reward 8.86  | Actor loss: -0.19 | Critic loss: 2.04 | Entropy loss: -0.0012  | Total Loss: 1.85 | Total Steps: 44\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1811/94000  | Episode Reward: 10  | Average Reward 8.86  | Actor loss: 0.03 | Critic loss: 0.63 | Entropy loss: -0.0000  | Total Loss: 0.66 | Total Steps: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1812/94000  | Episode Reward: 8  | Average Reward 8.83  | Actor loss: -0.02 | Critic loss: 1.46 | Entropy loss: -0.0012  | Total Loss: 1.43 | Total Steps: 49\n",
      "\n",
      "---yellow capsule---\n",
      "Decision Step reward: -1.0\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1813/94000  | Episode Reward: 9  | Average Reward 8.82  | Actor loss: -0.55 | Critic loss: 7.64 | Entropy loss: -0.0079  | Total Loss: 7.09 | Total Steps: 65\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1814/94000  | Episode Reward: 10  | Average Reward 8.82  | Actor loss: 0.00 | Critic loss: 0.24 | Entropy loss: -0.0000  | Total Loss: 0.24 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1815/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.00 | Critic loss: 0.40 | Entropy loss: -0.0006  | Total Loss: 0.41 | Total Steps: 35\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1816/94000  | Episode Reward: 8  | Average Reward 8.99  | Actor loss: -0.03 | Critic loss: 1.17 | Entropy loss: -0.0006  | Total Loss: 1.14 | Total Steps: 46\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1817/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0000  | Total Loss: 0.11 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1818/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.41 | Critic loss: 3.35 | Entropy loss: -0.0008  | Total Loss: 3.75 | Total Steps: 12\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1819/94000  | Episode Reward: 8  | Average Reward 8.99  | Actor loss: -0.67 | Critic loss: 1.70 | Entropy loss: -0.0033  | Total Loss: 1.03 | Total Steps: 43\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1820/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: -0.28 | Critic loss: 4.62 | Entropy loss: -0.0055  | Total Loss: 4.34 | Total Steps: 56\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1821/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.30 | Critic loss: 1.02 | Entropy loss: -0.0009  | Total Loss: 1.32 | Total Steps: 7\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1822/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.45 | Critic loss: 0.52 | Entropy loss: -0.0030  | Total Loss: 0.96 | Total Steps: 9\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1823/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: -0.15 | Critic loss: 0.12 | Entropy loss: -0.0011  | Total Loss: -0.03 | Total Steps: 11\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1824/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.00 | Critic loss: 0.41 | Entropy loss: -0.0010  | Total Loss: 0.41 | Total Steps: 50\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1825/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.01 | Critic loss: 0.19 | Entropy loss: -0.0000  | Total Loss: 0.20 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1826/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.00 | Critic loss: 0.63 | Entropy loss: -0.0000  | Total Loss: 0.63 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1827/94000  | Episode Reward: 10  | Average Reward 9.07  | Actor loss: 0.20 | Critic loss: 2.25 | Entropy loss: -0.0007  | Total Loss: 2.46 | Total Steps: 36\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1828/94000  | Episode Reward: 10  | Average Reward 9.07  | Actor loss: 0.64 | Critic loss: 0.32 | Entropy loss: -0.0016  | Total Loss: 0.96 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1829/94000  | Episode Reward: 10  | Average Reward 9.07  | Actor loss: 0.01 | Critic loss: 1.62 | Entropy loss: -0.0002  | Total Loss: 1.63 | Total Steps: 31\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1830/94000  | Episode Reward: 10  | Average Reward 9.07  | Actor loss: 0.00 | Critic loss: 1.27 | Entropy loss: -0.0000  | Total Loss: 1.27 | Total Steps: 31\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1831/94000  | Episode Reward: 8  | Average Reward 9.04  | Actor loss: -0.73 | Critic loss: 5.96 | Entropy loss: -0.0037  | Total Loss: 5.23 | Total Steps: 51\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1832/94000  | Episode Reward: 5  | Average Reward 8.99  | Actor loss: -0.65 | Critic loss: 4.07 | Entropy loss: -0.0040  | Total Loss: 3.42 | Total Steps: 51\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1833/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.07 | Critic loss: 0.03 | Entropy loss: -0.0006  | Total Loss: 0.10 | Total Steps: 8\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1834/94000  | Episode Reward: 8  | Average Reward 8.97  | Actor loss: 0.06 | Critic loss: 0.89 | Entropy loss: -0.0017  | Total Loss: 0.94 | Total Steps: 43\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1835/94000  | Episode Reward: 0  | Average Reward 8.87  | Actor loss: -0.42 | Critic loss: 11.32 | Entropy loss: -0.0012  | Total Loss: 10.89 | Total Steps: 45\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1836/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: -0.09 | Critic loss: 3.89 | Entropy loss: -0.0003  | Total Loss: 3.80 | Total Steps: 40\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1837/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0000  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1838/94000  | Episode Reward: 8  | Average Reward 8.85  | Actor loss: -1.14 | Critic loss: 2.70 | Entropy loss: -0.0034  | Total Loss: 1.56 | Total Steps: 32\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1839/94000  | Episode Reward: 8  | Average Reward 8.82  | Actor loss: 0.02 | Critic loss: 2.36 | Entropy loss: -0.0044  | Total Loss: 2.37 | Total Steps: 164\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1840/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: 0.14 | Critic loss: 1.08 | Entropy loss: -0.0004  | Total Loss: 1.22 | Total Steps: 11\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1841/94000  | Episode Reward: 10  | Average Reward 8.89  | Actor loss: 0.01 | Critic loss: 0.26 | Entropy loss: -0.0000  | Total Loss: 0.26 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1842/94000  | Episode Reward: 8  | Average Reward 8.89  | Actor loss: -0.16 | Critic loss: 4.58 | Entropy loss: -0.0010  | Total Loss: 4.42 | Total Steps: 41\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1843/94000  | Episode Reward: 10  | Average Reward 8.89  | Actor loss: 0.08 | Critic loss: 0.22 | Entropy loss: -0.0010  | Total Loss: 0.30 | Total Steps: 12\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  | Episode: 1844/94000  | Episode Reward: 10  | Average Reward 8.89  | Actor loss: 0.13 | Critic loss: 0.30 | Entropy loss: -0.0018  | Total Loss: 0.43 | Total Steps: 9\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1845/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.12 | Critic loss: 0.81 | Entropy loss: -0.0019  | Total Loss: 0.93 | Total Steps: 40\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1846/94000  | Episode Reward: 10  | Average Reward 8.90  | Actor loss: 0.00 | Critic loss: 1.48 | Entropy loss: -0.0000  | Total Loss: 1.48 | Total Steps: 31\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1847/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: 0.00 | Critic loss: 1.37 | Entropy loss: -0.0000  | Total Loss: 1.37 | Total Steps: 31\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1848/94000  | Episode Reward: 10  | Average Reward 8.98  | Actor loss: -0.15 | Critic loss: 1.18 | Entropy loss: -0.0014  | Total Loss: 1.03 | Total Steps: 38\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1849/94000  | Episode Reward: 10  | Average Reward 8.98  | Actor loss: -0.18 | Critic loss: 0.47 | Entropy loss: -0.0024  | Total Loss: 0.28 | Total Steps: 50\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1850/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1851/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1852/94000  | Episode Reward: 8  | Average Reward 9.03  | Actor loss: -0.36 | Critic loss: 5.82 | Entropy loss: -0.0042  | Total Loss: 5.46 | Total Steps: 53\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1853/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: -0.07 | Critic loss: 2.39 | Entropy loss: -0.0011  | Total Loss: 2.32 | Total Steps: 49\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1854/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1855/94000  | Episode Reward: 10  | Average Reward 9.03  | Actor loss: 0.06 | Critic loss: 0.30 | Entropy loss: -0.0006  | Total Loss: 0.37 | Total Steps: 11\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1856/94000  | Episode Reward: 5  | Average Reward 8.98  | Actor loss: -0.03 | Critic loss: 7.46 | Entropy loss: -0.0026  | Total Loss: 7.43 | Total Steps: 51\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1857/94000  | Episode Reward: 8  | Average Reward 9.02  | Actor loss: -0.25 | Critic loss: 9.19 | Entropy loss: -0.0028  | Total Loss: 8.94 | Total Steps: 82\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1858/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.00 | Critic loss: 0.51 | Entropy loss: -0.0000  | Total Loss: 0.51 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1859/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.11 | Critic loss: 0.28 | Entropy loss: -0.0009  | Total Loss: 0.39 | Total Steps: 8\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1860/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: -0.01 | Critic loss: 0.72 | Entropy loss: -0.0005  | Total Loss: 0.71 | Total Steps: 12\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1861/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: -0.01 | Critic loss: 3.83 | Entropy loss: -0.0002  | Total Loss: 3.83 | Total Steps: 55\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1862/94000  | Episode Reward: 8  | Average Reward 9.02  | Actor loss: 0.02 | Critic loss: 5.14 | Entropy loss: -0.0022  | Total Loss: 5.16 | Total Steps: 45\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1863/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.08 | Critic loss: 0.48 | Entropy loss: -0.0006  | Total Loss: 0.56 | Total Steps: 8\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1864/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.00 | Critic loss: 1.82 | Entropy loss: -0.0000  | Total Loss: 1.82 | Total Steps: 31\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1865/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0000  | Total Loss: 0.12 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1866/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.30 | Critic loss: 4.54 | Entropy loss: -0.0010  | Total Loss: 4.83 | Total Steps: 12\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1867/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: -1.01 | Critic loss: 4.27 | Entropy loss: -0.0036  | Total Loss: 3.26 | Total Steps: 33\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1868/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1869/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: -0.11 | Critic loss: 2.54 | Entropy loss: -0.0008  | Total Loss: 2.43 | Total Steps: 42\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1870/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.01 | Critic loss: 2.34 | Entropy loss: -0.0000  | Total Loss: 2.35 | Total Steps: 31\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1871/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1872/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: -0.04 | Critic loss: 1.42 | Entropy loss: -0.0002  | Total Loss: 1.38 | Total Steps: 35\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1873/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: -0.10 | Critic loss: 0.94 | Entropy loss: -0.0019  | Total Loss: 0.83 | Total Steps: 41\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1874/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: -0.15 | Critic loss: 4.84 | Entropy loss: -0.0040  | Total Loss: 4.68 | Total Steps: 61\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1875/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.01 | Critic loss: 2.18 | Entropy loss: -0.0001  | Total Loss: 2.19 | Total Steps: 31\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1876/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: 0.00 | Critic loss: 1.09 | Entropy loss: -0.0000  | Total Loss: 1.09 | Total Steps: 31\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1877/94000  | Episode Reward: 8  | Average Reward 9.04  | Actor loss: 0.01 | Critic loss: 6.10 | Entropy loss: -0.0008  | Total Loss: 6.12 | Total Steps: 37\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1878/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.10 | Critic loss: 0.90 | Entropy loss: -0.0029  | Total Loss: 1.00 | Total Steps: 31\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1879/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.05 | Critic loss: 0.07 | Entropy loss: -0.0006  | Total Loss: 0.12 | Total Steps: 11\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1880/94000  | Episode Reward: 8  | Average Reward 9.02  | Actor loss: -0.41 | Critic loss: 3.74 | Entropy loss: -0.0020  | Total Loss: 3.32 | Total Steps: 55\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1881/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.06 | Critic loss: 0.42 | Entropy loss: -0.0015  | Total Loss: 0.48 | Total Steps: 40\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1882/94000  | Episode Reward: 8  | Average Reward 9.16  | Actor loss: 0.01 | Critic loss: 1.78 | Entropy loss: -0.0001  | Total Loss: 1.78 | Total Steps: 38\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1883/94000  | Episode Reward: 10  | Average Reward 9.16  | Actor loss: -0.08 | Critic loss: 0.09 | Entropy loss: -0.0018  | Total Loss: 0.01 | Total Steps: 9\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1884/94000  | Episode Reward: 10  | Average Reward 9.19  | Actor loss: -0.09 | Critic loss: 4.92 | Entropy loss: -0.0023  | Total Loss: 4.83 | Total Steps: 55\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1885/94000  | Episode Reward: 10  | Average Reward 9.21  | Actor loss: -0.09 | Critic loss: 0.07 | Entropy loss: -0.0022  | Total Loss: -0.03 | Total Steps: 9\n",
      "\n",
      "---black cylinder---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 1886/94000  | Episode Reward: -10  | Average Reward 9.02  | Actor loss: -0.00 | Critic loss: 5.51 | Entropy loss: -0.0002  | Total Loss: 5.50 | Total Steps: 500\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1887/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.00 | Critic loss: 0.93 | Entropy loss: -0.0001  | Total Loss: 0.93 | Total Steps: 50\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1888/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.05 | Critic loss: 1.95 | Entropy loss: -0.0013  | Total Loss: 2.00 | Total Steps: 34\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1889/94000  | Episode Reward: 8  | Average Reward 9.09  | Actor loss: -0.12 | Critic loss: 2.18 | Entropy loss: -0.0028  | Total Loss: 2.05 | Total Steps: 60\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1890/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.01 | Critic loss: 0.65 | Entropy loss: -0.0000  | Total Loss: 0.65 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1891/94000  | Episode Reward: 8  | Average Reward 9.09  | Actor loss: 0.00 | Critic loss: 0.47 | Entropy loss: -0.0000  | Total Loss: 0.48 | Total Steps: 38\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1892/94000  | Episode Reward: 2  | Average Reward 9.02  | Actor loss: -0.06 | Critic loss: 6.64 | Entropy loss: -0.0025  | Total Loss: 6.58 | Total Steps: 53\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1893/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.05 | Critic loss: 0.04 | Entropy loss: -0.0007  | Total Loss: 0.09 | Total Steps: 9\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1894/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: -0.18 | Critic loss: 4.92 | Entropy loss: -0.0042  | Total Loss: 4.73 | Total Steps: 46\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1895/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.57 | Critic loss: 0.89 | Entropy loss: -0.0017  | Total Loss: 1.46 | Total Steps: 13\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1896/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.08 | Critic loss: 1.75 | Entropy loss: -0.0024  | Total Loss: 1.83 | Total Steps: 126\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1897/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.00 | Critic loss: 0.31 | Entropy loss: -0.0000  | Total Loss: 0.31 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1898/94000  | Episode Reward: 8  | Average Reward 8.99  | Actor loss: 0.04 | Critic loss: 1.65 | Entropy loss: -0.0004  | Total Loss: 1.69 | Total Steps: 38\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1899/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1900/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.00 | Critic loss: 2.49 | Entropy loss: -0.0002  | Total Loss: 2.49 | Total Steps: 31\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1901/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: -0.00 | Critic loss: 0.62 | Entropy loss: -0.0001  | Total Loss: 0.62 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 9  | Average Reward 6.12  | Actor loss: 0.00 | Critic loss: 1.42 | Entropy loss: -0.0422  | Total Loss: 1.38 | Total Steps: 25\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 2/100  | Episode Reward: -52  | Average Reward 5.70  | Actor loss: -12.47 | Critic loss: 112.40 | Entropy loss: -0.0505  | Total Loss: 99.88 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 3/100  | Episode Reward: -2  | Average Reward 5.58  | Actor loss: 0.28 | Critic loss: 20.65 | Entropy loss: -0.0557  | Total Loss: 20.87 | Total Steps: 183\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 10  | Average Reward 5.66  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0095  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 10  | Average Reward 5.66  | Actor loss: 0.00 | Critic loss: 0.24 | Entropy loss: -0.0017  | Total Loss: 0.24 | Total Steps: 40\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 10  | Average Reward 5.66  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0005  | Total Loss: 0.08 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: 10  | Average Reward 5.86  | Actor loss: 0.00 | Critic loss: 0.35 | Entropy loss: -0.0005  | Total Loss: 0.35 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 6  | Average Reward 5.84  | Actor loss: 0.07 | Critic loss: 9.30 | Entropy loss: -0.0452  | Total Loss: 9.32 | Total Steps: 61\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 10  | Average Reward 5.84  | Actor loss: 0.00 | Critic loss: 0.65 | Entropy loss: -0.0078  | Total Loss: 0.64 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 10  | Average Reward 5.84  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0015  | Total Loss: 0.02 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 10  | Average Reward 5.84  | Actor loss: 0.00 | Critic loss: 0.65 | Entropy loss: -0.0005  | Total Loss: 0.66 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 10  | Average Reward 5.96  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0154  | Total Loss: -0.01 | Total Steps: 44\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 10  | Average Reward 6.01  | Actor loss: 0.00 | Critic loss: 0.59 | Entropy loss: -0.0010  | Total Loss: 0.59 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: 10  | Average Reward 6.21  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0144  | Total Loss: 0.08 | Total Steps: 10\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 15/100  | Episode Reward: -10  | Average Reward 6.04  | Actor loss: -0.00 | Critic loss: 70.70 | Entropy loss: -0.0022  | Total Loss: 70.69 | Total Steps: 500\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 10  | Average Reward 6.04  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0006  | Total Loss: 0.02 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 8  | Average Reward 6.04  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0009  | Total Loss: 0.11 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 10  | Average Reward 6.07  | Actor loss: 0.00 | Critic loss: 0.68 | Entropy loss: -0.0308  | Total Loss: 0.66 | Total Steps: 7\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 10  | Average Reward 6.07  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0057  | Total Loss: -0.01 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: 10  | Average Reward 6.17  | Actor loss: 0.04 | Critic loss: 12.11 | Entropy loss: -0.0134  | Total Loss: 12.13 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 10  | Average Reward 6.19  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0024  | Total Loss: 0.09 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 22/100  | Episode Reward: 8  | Average Reward 6.19  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0079  | Total Loss: 0.03 | Total Steps: 30\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 10  | Average Reward 6.19  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0015  | Total Loss: 0.02 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 24/100  | Episode Reward: -10  | Average Reward 5.99  | Actor loss: -0.00 | Critic loss: 76.32 | Entropy loss: -0.0001  | Total Loss: 76.32 | Total Steps: 500\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 10  | Average Reward 5.99  | Actor loss: 0.00 | Critic loss: 0.39 | Entropy loss: -0.0307  | Total Loss: 0.36 | Total Steps: 10\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 10  | Average Reward 6.01  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0057  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 8  | Average Reward 5.99  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0005  | Total Loss: 0.15 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 10  | Average Reward 5.99  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0009  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 10  | Average Reward 5.99  | Actor loss: 0.03 | Critic loss: 7.44 | Entropy loss: -0.0032  | Total Loss: 7.47 | Total Steps: 36\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 10  | Average Reward 5.99  | Actor loss: 0.00 | Critic loss: 0.24 | Entropy loss: -0.0010  | Total Loss: 0.24 | Total Steps: 36\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 10  | Average Reward 6.00  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0005  | Total Loss: 0.13 | Total Steps: 6\n",
      "TEST: ---black sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 32/100  | Episode Reward: 10  | Average Reward 6.01  | Actor loss: 0.00 | Critic loss: 0.36 | Entropy loss: -0.0002  | Total Loss: 0.36 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 33/100  | Episode Reward: 10  | Average Reward 6.01  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0002  | Total Loss: 0.10 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 34/100  | Episode Reward: -36  | Average Reward 5.86  | Actor loss: -1.72 | Critic loss: 117.06 | Entropy loss: -0.0441  | Total Loss: 115.29 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 35/100  | Episode Reward: 5  | Average Reward 5.81  | Actor loss: 0.00 | Critic loss: 0.32 | Entropy loss: -0.0021  | Total Loss: 0.32 | Total Steps: 49\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 36/100  | Episode Reward: 10  | Average Reward 5.81  | Actor loss: 0.01 | Critic loss: 1.31 | Entropy loss: -0.0101  | Total Loss: 1.31 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 37/100  | Episode Reward: 5  | Average Reward 5.76  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0120  | Total Loss: 0.09 | Total Steps: 47\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: 10  | Average Reward 5.95  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0416  | Total Loss: -0.02 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 8  | Average Reward 5.92  | Actor loss: 0.01 | Critic loss: 0.36 | Entropy loss: -0.0043  | Total Loss: 0.36 | Total Steps: 125\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 10  | Average Reward 5.95  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0100  | Total Loss: 0.05 | Total Steps: 50\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 10  | Average Reward 5.97  | Actor loss: 0.00 | Critic loss: 0.50 | Entropy loss: -0.0030  | Total Loss: 0.50 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 10  | Average Reward 5.99  | Actor loss: 0.00 | Critic loss: 0.47 | Entropy loss: -0.0064  | Total Loss: 0.46 | Total Steps: 9\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 43/100  | Episode Reward: -44  | Average Reward 5.49  | Actor loss: -1.27 | Critic loss: 91.37 | Entropy loss: -0.0499  | Total Loss: 90.06 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: -1  | Average Reward 5.41  | Actor loss: 1.12 | Critic loss: 15.92 | Entropy loss: -0.0470  | Total Loss: 16.99 | Total Steps: 129\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 45/100  | Episode Reward: -10  | Average Reward 5.23  | Actor loss: -0.00 | Critic loss: 69.97 | Entropy loss: -0.0021  | Total Loss: 69.96 | Total Steps: 500\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 10  | Average Reward 5.23  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0007  | Total Loss: 0.13 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 10  | Average Reward 5.30  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0007  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 10  | Average Reward 5.30  | Actor loss: 0.01 | Critic loss: 10.65 | Entropy loss: -0.0235  | Total Loss: 10.64 | Total Steps: 7\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 10  | Average Reward 5.76  | Actor loss: 0.00 | Critic loss: 0.60 | Entropy loss: -0.0042  | Total Loss: 0.60 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 2  | Average Reward 5.68  | Actor loss: 0.02 | Critic loss: 0.52 | Entropy loss: -0.0164  | Total Loss: 0.53 | Total Steps: 57\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 51/100  | Episode Reward: -62  | Average Reward 4.96  | Actor loss: -2.68 | Critic loss: 65.42 | Entropy loss: -0.0499  | Total Loss: 62.69 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 9  | Average Reward 4.95  | Actor loss: 0.00 | Critic loss: 0.70 | Entropy loss: -0.0356  | Total Loss: 0.67 | Total Steps: 27\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 53/100  | Episode Reward: -48  | Average Reward 4.37  | Actor loss: -1.60 | Critic loss: 94.27 | Entropy loss: -0.0542  | Total Loss: 92.61 | Total Steps: 500\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 54/100  | Episode Reward: 10  | Average Reward 4.57  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0093  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 10  | Average Reward 4.57  | Actor loss: 0.00 | Critic loss: 0.50 | Entropy loss: -0.0029  | Total Loss: 0.50 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: -39  | Average Reward 4.09  | Actor loss: 0.00 | Critic loss: 3.60 | Entropy loss: -0.0519  | Total Loss: 3.55 | Total Steps: 434\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 8  | Average Reward 4.07  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0099  | Total Loss: 0.03 | Total Steps: 40\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 10  | Average Reward 4.09  | Actor loss: 0.28 | Critic loss: 0.32 | Entropy loss: -0.0172  | Total Loss: 0.58 | Total Steps: 44\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 10  | Average Reward 4.12  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0646  | Total Loss: -0.03 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 60/100  | Episode Reward: 8  | Average Reward 4.10  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0160  | Total Loss: 0.06 | Total Steps: 48\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "TEST: Step: 400\n",
      "Testing  | Episode: 61/100  | Episode Reward: -16  | Average Reward 3.89  | Actor loss: 0.01 | Critic loss: 0.68 | Entropy loss: -0.0539  | Total Loss: 0.63 | Total Steps: 400\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 10  | Average Reward 3.89  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0107  | Total Loss: 0.01 | Total Steps: 34\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: 8  | Average Reward 3.92  | Actor loss: 0.07 | Critic loss: 0.24 | Entropy loss: -0.0087  | Total Loss: 0.31 | Total Steps: 53\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 64/100  | Episode Reward: -1  | Average Reward 3.81  | Actor loss: 0.03 | Critic loss: 5.06 | Entropy loss: -0.0491  | Total Loss: 5.05 | Total Steps: 209\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 65/100  | Episode Reward: 5  | Average Reward 3.75  | Actor loss: 0.00 | Critic loss: 0.29 | Entropy loss: -0.0025  | Total Loss: 0.29 | Total Steps: 49\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 10  | Average Reward 3.75  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0175  | Total Loss: -0.02 | Total Steps: 45\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 8  | Average Reward 3.73  | Actor loss: 0.01 | Critic loss: 0.58 | Entropy loss: -0.0010  | Total Loss: 0.59 | Total Steps: 36\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 68/100  | Episode Reward: 10  | Average Reward 3.73  | Actor loss: 0.03 | Critic loss: 18.14 | Entropy loss: -0.0280  | Total Loss: 18.14 | Total Steps: 7\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 10  | Average Reward 3.73  | Actor loss: 0.03 | Critic loss: 1.35 | Entropy loss: -0.0873  | Total Loss: 1.30 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 70/100  | Episode Reward: 5  | Average Reward 3.68  | Actor loss: 0.01 | Critic loss: 1.54 | Entropy loss: -0.0058  | Total Loss: 1.55 | Total Steps: 47\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 8  | Average Reward 3.65  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0005  | Total Loss: 0.15 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 10  | Average Reward 3.65  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0004  | Total Loss: 0.14 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 10  | Average Reward 3.67  | Actor loss: 0.00 | Critic loss: 0.38 | Entropy loss: -0.0001  | Total Loss: 0.38 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: 10  | Average Reward 3.67  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0002  | Total Loss: 0.02 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 10  | Average Reward 3.67  | Actor loss: 0.00 | Critic loss: 0.69 | Entropy loss: -0.0002  | Total Loss: 0.69 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 10  | Average Reward 3.73  | Actor loss: 0.00 | Critic loss: 0.65 | Entropy loss: -0.0003  | Total Loss: 0.65 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 77/100  | Episode Reward: -15  | Average Reward 3.60  | Actor loss: -0.00 | Critic loss: 92.27 | Entropy loss: -0.0020  | Total Loss: 92.27 | Total Steps: 500\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 10  | Average Reward 3.60  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0155  | Total Loss: 0.10 | Total Steps: 51\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 10  | Average Reward 3.60  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0100  | Total Loss: 0.20 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 8  | Average Reward 3.60  | Actor loss: 0.00 | Critic loss: 1.21 | Entropy loss: -0.0415  | Total Loss: 1.17 | Total Steps: 32\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 8  | Average Reward 3.60  | Actor loss: 0.00 | Critic loss: 0.87 | Entropy loss: -0.0103  | Total Loss: 0.86 | Total Steps: 67\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: 2  | Average Reward 3.55  | Actor loss: 0.00 | Critic loss: 1.46 | Entropy loss: -0.0094  | Total Loss: 1.45 | Total Steps: 66\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 8  | Average Reward 3.55  | Actor loss: 0.00 | Critic loss: 0.40 | Entropy loss: -0.0023  | Total Loss: 0.40 | Total Steps: 34\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 84/100  | Episode Reward: 10  | Average Reward 3.75  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0007  | Total Loss: 0.07 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 85/100  | Episode Reward: 10  | Average Reward 3.77  | Actor loss: 0.01 | Critic loss: 0.23 | Entropy loss: -0.0382  | Total Loss: 0.19 | Total Steps: 9\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: 10  | Average Reward 3.77  | Actor loss: 0.00 | Critic loss: 0.60 | Entropy loss: -0.0066  | Total Loss: 0.59 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 10  | Average Reward 3.80  | Actor loss: 0.00 | Critic loss: 0.22 | Entropy loss: -0.0013  | Total Loss: 0.22 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: -8  | Average Reward 3.62  | Actor loss: 0.00 | Critic loss: 3.21 | Entropy loss: -0.0122  | Total Loss: 3.20 | Total Steps: 113\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 89/100  | Episode Reward: 10  | Average Reward 3.62  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0022  | Total Loss: 0.21 | Total Steps: 6\n",
      "TEST: ---red capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 90/100  | Episode Reward: 10  | Average Reward 4.00  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0051  | Total Loss: 0.07 | Total Steps: 34\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 8  | Average Reward 3.98  | Actor loss: 0.00 | Critic loss: 0.33 | Entropy loss: -0.0005  | Total Loss: 0.33 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 10  | Average Reward 3.98  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0092  | Total Loss: -0.00 | Total Steps: 9\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: 10  | Average Reward 4.10  | Actor loss: 0.03 | Critic loss: 10.78 | Entropy loss: -0.0126  | Total Loss: 10.80 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: -1  | Average Reward 3.99  | Actor loss: 2.49 | Critic loss: 15.54 | Entropy loss: -0.0425  | Total Loss: 17.99 | Total Steps: 134\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: 5  | Average Reward 3.96  | Actor loss: 0.00 | Critic loss: 0.37 | Entropy loss: -0.0067  | Total Loss: 0.37 | Total Steps: 136\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 5  | Average Reward 3.94  | Actor loss: 0.01 | Critic loss: 0.32 | Entropy loss: -0.0023  | Total Loss: 0.33 | Total Steps: 47\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 10  | Average Reward 3.96  | Actor loss: 0.01 | Critic loss: 1.65 | Entropy loss: -0.0716  | Total Loss: 1.59 | Total Steps: 27\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: 0  | Average Reward 3.89  | Actor loss: 8.45 | Critic loss: 27.77 | Entropy loss: -0.0448  | Total Loss: 36.17 | Total Steps: 173\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 10  | Average Reward 3.92  | Actor loss: 0.66 | Critic loss: 0.87 | Entropy loss: -0.0883  | Total Loss: 1.44 | Total Steps: 7\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 8  | Average Reward 3.89  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0090  | Total Loss: 0.00 | Total Steps: 64\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1902/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: -0.57 | Critic loss: 3.63 | Entropy loss: -0.0020  | Total Loss: 3.06 | Total Steps: 41\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1903/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.04 | Critic loss: 0.46 | Entropy loss: -0.0002  | Total Loss: 0.50 | Total Steps: 8\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1904/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.01 | Critic loss: 0.10 | Entropy loss: -0.0000  | Total Loss: 0.10 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1905/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: 0.10 | Critic loss: 1.79 | Entropy loss: -0.0007  | Total Loss: 1.89 | Total Steps: 30\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1906/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: -0.06 | Critic loss: 0.13 | Entropy loss: -0.0011  | Total Loss: 0.06 | Total Steps: 9\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1907/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: 0.00 | Critic loss: 1.16 | Entropy loss: -0.0000  | Total Loss: 1.16 | Total Steps: 31\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1908/94000  | Episode Reward: 10  | Average Reward 9.06  | Actor loss: 0.00 | Critic loss: 1.53 | Entropy loss: -0.0000  | Total Loss: 1.53 | Total Steps: 31\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1909/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: -0.20 | Critic loss: 0.16 | Entropy loss: -0.0011  | Total Loss: -0.05 | Total Steps: 10\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1910/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: -0.91 | Critic loss: 7.69 | Entropy loss: -0.0068  | Total Loss: 6.77 | Total Steps: 108\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1911/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: 0.04 | Critic loss: 4.64 | Entropy loss: -0.0003  | Total Loss: 4.68 | Total Steps: 31\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1912/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.00 | Critic loss: 0.71 | Entropy loss: -0.0000  | Total Loss: 0.72 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1913/94000  | Episode Reward: 8  | Average Reward 9.10  | Actor loss: -0.19 | Critic loss: 1.28 | Entropy loss: -0.0020  | Total Loss: 1.08 | Total Steps: 46\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1914/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: 0.18 | Critic loss: 0.43 | Entropy loss: -0.0006  | Total Loss: 0.61 | Total Steps: 8\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1915/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: 0.04 | Critic loss: 0.33 | Entropy loss: -0.0001  | Total Loss: 0.36 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1916/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.06 | Critic loss: 0.32 | Entropy loss: -0.0003  | Total Loss: 0.38 | Total Steps: 11\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1917/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.04 | Critic loss: 0.28 | Entropy loss: -0.0001  | Total Loss: 0.32 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1918/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.00 | Critic loss: 0.62 | Entropy loss: -0.0000  | Total Loss: 0.62 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1919/94000  | Episode Reward: 10  | Average Reward 9.15  | Actor loss: -0.07 | Critic loss: 4.61 | Entropy loss: -0.0047  | Total Loss: 4.54 | Total Steps: 59\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1920/94000  | Episode Reward: 8  | Average Reward 9.12  | Actor loss: -0.04 | Critic loss: 5.89 | Entropy loss: -0.0006  | Total Loss: 5.84 | Total Steps: 54\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1921/94000  | Episode Reward: 5  | Average Reward 9.07  | Actor loss: -0.11 | Critic loss: 9.45 | Entropy loss: -0.0007  | Total Loss: 9.34 | Total Steps: 43\n",
      "\n",
      "---green prism---\n",
      "Step: 250\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1922/94000  | Episode Reward: 8  | Average Reward 9.05  | Actor loss: -0.15 | Critic loss: 2.66 | Entropy loss: -0.0072  | Total Loss: 2.50 | Total Steps: 487\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1923/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.01 | Critic loss: 0.38 | Entropy loss: -0.0002  | Total Loss: 0.39 | Total Steps: 8\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1924/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: -0.10 | Critic loss: 0.06 | Entropy loss: -0.0011  | Total Loss: -0.04 | Total Steps: 9\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1925/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: -0.01 | Critic loss: 0.02 | Entropy loss: -0.0004  | Total Loss: 0.01 | Total Steps: 8\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1926/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.07 | Critic loss: 4.06 | Entropy loss: -0.0013  | Total Loss: 4.13 | Total Steps: 17\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1927/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: -0.04 | Critic loss: 4.46 | Entropy loss: -0.0008  | Total Loss: 4.42 | Total Steps: 51\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1928/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.00 | Critic loss: 2.59 | Entropy loss: -0.0000  | Total Loss: 2.59 | Total Steps: 31\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1929/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: -0.06 | Critic loss: 1.75 | Entropy loss: -0.0002  | Total Loss: 1.69 | Total Steps: 35\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1930/94000  | Episode Reward: 8  | Average Reward 9.03  | Actor loss: -0.46 | Critic loss: 7.84 | Entropy loss: -0.0028  | Total Loss: 7.38 | Total Steps: 54\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1931/94000  | Episode Reward: 10  | Average Reward 9.05  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0003  | Total Loss: 0.21 | Total Steps: 39\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1932/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0000  | Total Loss: 0.13 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1933/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0000  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1934/94000  | Episode Reward: 8  | Average Reward 9.10  | Actor loss: 0.00 | Critic loss: 0.32 | Entropy loss: -0.0001  | Total Loss: 0.33 | Total Steps: 38\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1935/94000  | Episode Reward: 5  | Average Reward 9.15  | Actor loss: -0.36 | Critic loss: 4.96 | Entropy loss: -0.0044  | Total Loss: 4.60 | Total Steps: 50\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1936/94000  | Episode Reward: 10  | Average Reward 9.15  | Actor loss: 0.04 | Critic loss: 0.73 | Entropy loss: -0.0004  | Total Loss: 0.77 | Total Steps: 40\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1937/94000  | Episode Reward: 10  | Average Reward 9.15  | Actor loss: -0.01 | Critic loss: 1.01 | Entropy loss: -0.0001  | Total Loss: 1.00 | Total Steps: 46\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1938/94000  | Episode Reward: 8  | Average Reward 9.15  | Actor loss: 0.00 | Critic loss: 2.10 | Entropy loss: -0.0003  | Total Loss: 2.11 | Total Steps: 49\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1939/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0000  | Total Loss: 0.08 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1940/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0000  | Total Loss: 0.16 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1941/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: -0.22 | Critic loss: 2.05 | Entropy loss: -0.0012  | Total Loss: 1.83 | Total Steps: 37\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1942/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1943/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: 0.12 | Critic loss: 0.85 | Entropy loss: -0.0018  | Total Loss: 0.97 | Total Steps: 35\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1944/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: 0.12 | Critic loss: 6.27 | Entropy loss: -0.0030  | Total Loss: 6.38 | Total Steps: 16\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1945/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: 0.04 | Critic loss: 1.05 | Entropy loss: -0.0001  | Total Loss: 1.08 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1946/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: 0.00 | Critic loss: 0.20 | Entropy loss: -0.0000  | Total Loss: 0.20 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1947/94000  | Episode Reward: 10  | Average Reward 9.20  | Actor loss: -0.20 | Critic loss: 1.85 | Entropy loss: -0.0015  | Total Loss: 1.65 | Total Steps: 52\n",
      "\n",
      "---red sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1948/94000  | Episode Reward: 8  | Average Reward 9.18  | Actor loss: 0.11 | Critic loss: 6.38 | Entropy loss: -0.0018  | Total Loss: 6.49 | Total Steps: 37\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1949/94000  | Episode Reward: 5  | Average Reward 9.12  | Actor loss: -0.02 | Critic loss: 5.11 | Entropy loss: -0.0002  | Total Loss: 5.09 | Total Steps: 49\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1950/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: -0.91 | Critic loss: 4.61 | Entropy loss: -0.0035  | Total Loss: 3.69 | Total Steps: 54\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1951/94000  | Episode Reward: 8  | Average Reward 9.10  | Actor loss: 0.00 | Critic loss: 0.30 | Entropy loss: -0.0001  | Total Loss: 0.30 | Total Steps: 38\n",
      "\n",
      "---red cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1952/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: -0.91 | Critic loss: 5.59 | Entropy loss: -0.0085  | Total Loss: 4.66 | Total Steps: 69\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1953/94000  | Episode Reward: 5  | Average Reward 9.07  | Actor loss: -0.04 | Critic loss: 8.27 | Entropy loss: -0.0005  | Total Loss: 8.23 | Total Steps: 53\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1954/94000  | Episode Reward: 10  | Average Reward 9.07  | Actor loss: 0.01 | Critic loss: 1.47 | Entropy loss: -0.0000  | Total Loss: 1.48 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1955/94000  | Episode Reward: 10  | Average Reward 9.07  | Actor loss: 0.01 | Critic loss: 0.36 | Entropy loss: -0.0000  | Total Loss: 0.36 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1956/94000  | Episode Reward: 8  | Average Reward 9.10  | Actor loss: 0.30 | Critic loss: 1.03 | Entropy loss: -0.0041  | Total Loss: 1.33 | Total Steps: 68\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1957/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: -0.27 | Critic loss: 2.21 | Entropy loss: -0.0038  | Total Loss: 1.94 | Total Steps: 55\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1958/94000  | Episode Reward: 8  | Average Reward 9.10  | Actor loss: -0.57 | Critic loss: 4.15 | Entropy loss: -0.0031  | Total Loss: 3.58 | Total Steps: 53\n",
      "\n",
      "---red cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1959/94000  | Episode Reward: 8  | Average Reward 9.07  | Actor loss: -0.19 | Critic loss: 6.04 | Entropy loss: -0.0020  | Total Loss: 5.84 | Total Steps: 54\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1960/94000  | Episode Reward: 2  | Average Reward 9.00  | Actor loss: -0.14 | Critic loss: 8.19 | Entropy loss: -0.0013  | Total Loss: 8.05 | Total Steps: 52\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1961/94000  | Episode Reward: 5  | Average Reward 8.95  | Actor loss: -1.30 | Critic loss: 8.08 | Entropy loss: -0.0043  | Total Loss: 6.78 | Total Steps: 55\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1962/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.01 | Critic loss: 0.88 | Entropy loss: -0.0000  | Total Loss: 0.89 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1963/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: -0.04 | Critic loss: 5.99 | Entropy loss: -0.0042  | Total Loss: 5.95 | Total Steps: 56\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1964/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1965/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0000  | Total Loss: 0.20 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1966/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.04 | Critic loss: 2.99 | Entropy loss: -0.0003  | Total Loss: 3.03 | Total Steps: 31\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1967/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.01 | Critic loss: 2.03 | Entropy loss: -0.0001  | Total Loss: 2.04 | Total Steps: 31\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1968/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.41 | Critic loss: 0.74 | Entropy loss: -0.0010  | Total Loss: 1.15 | Total Steps: 9\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1969/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.14 | Critic loss: 1.42 | Entropy loss: -0.0011  | Total Loss: 1.55 | Total Steps: 12\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1970/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0000  | Total Loss: 0.21 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1971/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0000  | Total Loss: 0.11 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1972/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.00 | Critic loss: 1.63 | Entropy loss: -0.0000  | Total Loss: 1.63 | Total Steps: 31\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1973/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.01 | Critic loss: 0.42 | Entropy loss: -0.0000  | Total Loss: 0.43 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1974/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.00 | Critic loss: 0.97 | Entropy loss: -0.0000  | Total Loss: 0.97 | Total Steps: 31\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1975/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1976/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: -0.11 | Critic loss: 1.87 | Entropy loss: -0.0006  | Total Loss: 1.77 | Total Steps: 49\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1977/94000  | Episode Reward: 10  | Average Reward 9.00  | Actor loss: 0.08 | Critic loss: 0.67 | Entropy loss: -0.0012  | Total Loss: 0.74 | Total Steps: 39\n",
      "\n",
      "---black capsule---\n",
      "Step: 250\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1978/94000  | Episode Reward: 8  | Average Reward 8.97  | Actor loss: -0.06 | Critic loss: 2.31 | Entropy loss: -0.0054  | Total Loss: 2.24 | Total Steps: 490\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1979/94000  | Episode Reward: 8  | Average Reward 8.95  | Actor loss: -0.00 | Critic loss: 1.19 | Entropy loss: -0.0004  | Total Loss: 1.19 | Total Steps: 49\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1980/94000  | Episode Reward: 8  | Average Reward 8.95  | Actor loss: -0.47 | Critic loss: 1.44 | Entropy loss: -0.0056  | Total Loss: 0.97 | Total Steps: 53\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1981/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.02 | Critic loss: 0.88 | Entropy loss: -0.0005  | Total Loss: 0.91 | Total Steps: 49\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1982/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.14 | Critic loss: 0.10 | Entropy loss: -0.0006  | Total Loss: 0.24 | Total Steps: 8\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1983/94000  | Episode Reward: 8  | Average Reward 8.95  | Actor loss: -0.42 | Critic loss: 4.03 | Entropy loss: -0.0022  | Total Loss: 3.61 | Total Steps: 58\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  | Episode: 1984/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1985/94000  | Episode Reward: 8  | Average Reward 8.93  | Actor loss: 0.05 | Critic loss: 2.35 | Entropy loss: -0.0015  | Total Loss: 2.40 | Total Steps: 51\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1986/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: -0.44 | Critic loss: 4.88 | Entropy loss: -0.0095  | Total Loss: 4.43 | Total Steps: 56\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1987/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.00 | Critic loss: 0.64 | Entropy loss: -0.0000  | Total Loss: 0.64 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1988/94000  | Episode Reward: 10  | Average Reward 9.12  | Actor loss: 0.01 | Critic loss: 0.59 | Entropy loss: -0.0003  | Total Loss: 0.60 | Total Steps: 39\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1989/94000  | Episode Reward: 10  | Average Reward 9.15  | Actor loss: -0.00 | Critic loss: 1.86 | Entropy loss: -0.0001  | Total Loss: 1.86 | Total Steps: 29\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1990/94000  | Episode Reward: 10  | Average Reward 9.15  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0000  | Total Loss: 0.13 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1991/94000  | Episode Reward: 10  | Average Reward 9.18  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1992/94000  | Episode Reward: 10  | Average Reward 9.25  | Actor loss: -0.25 | Critic loss: 4.38 | Entropy loss: -0.0032  | Total Loss: 4.12 | Total Steps: 47\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1993/94000  | Episode Reward: 10  | Average Reward 9.25  | Actor loss: 0.13 | Critic loss: 1.23 | Entropy loss: -0.0014  | Total Loss: 1.35 | Total Steps: 10\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1994/94000  | Episode Reward: 10  | Average Reward 9.25  | Actor loss: 0.22 | Critic loss: 0.50 | Entropy loss: -0.0025  | Total Loss: 0.72 | Total Steps: 41\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1995/94000  | Episode Reward: 10  | Average Reward 9.25  | Actor loss: 0.08 | Critic loss: 0.63 | Entropy loss: -0.0007  | Total Loss: 0.71 | Total Steps: 9\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1996/94000  | Episode Reward: 8  | Average Reward 9.22  | Actor loss: 0.06 | Critic loss: 1.27 | Entropy loss: -0.0023  | Total Loss: 1.33 | Total Steps: 97\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -1.0\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1997/94000  | Episode Reward: 9  | Average Reward 9.21  | Actor loss: 0.07 | Critic loss: 2.88 | Entropy loss: -0.0038  | Total Loss: 2.95 | Total Steps: 32\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1998/94000  | Episode Reward: 10  | Average Reward 9.24  | Actor loss: 0.03 | Critic loss: 0.08 | Entropy loss: -0.0004  | Total Loss: 0.11 | Total Steps: 10\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 1999/94000  | Episode Reward: 10  | Average Reward 9.24  | Actor loss: 0.15 | Critic loss: 1.09 | Entropy loss: -0.0021  | Total Loss: 1.24 | Total Steps: 32\n",
      "\n",
      "---black cylinder---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 2000/94000  | Episode Reward: -10  | Average Reward 9.04  | Actor loss: -0.00 | Critic loss: 3.85 | Entropy loss: -0.0001  | Total Loss: 3.85 | Total Steps: 500\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2001/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "Model has been saved\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 8  | Average Reward 3.88  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0008  | Total Loss: 0.10 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 10  | Average Reward 4.49  | Actor loss: -0.00 | Critic loss: 0.04 | Entropy loss: -0.0098  | Total Loss: 0.03 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 3/100  | Episode Reward: 8  | Average Reward 4.58  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0014  | Total Loss: 0.08 | Total Steps: 38\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 10  | Average Reward 4.58  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0005  | Total Loss: 0.12 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 10  | Average Reward 4.58  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0067  | Total Loss: 0.02 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 8  | Average Reward 4.56  | Actor loss: 0.01 | Critic loss: 0.03 | Entropy loss: -0.0018  | Total Loss: 0.04 | Total Steps: 50\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: 8  | Average Reward 4.54  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0032  | Total Loss: 0.04 | Total Steps: 36\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 8  | Average Reward 4.55  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0087  | Total Loss: 0.01 | Total Steps: 41\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 10  | Average Reward 4.55  | Actor loss: -0.00 | Critic loss: 0.07 | Entropy loss: -0.0021  | Total Loss: 0.07 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: -36  | Average Reward 4.09  | Actor loss: 0.14 | Critic loss: 9.53 | Entropy loss: -0.0591  | Total Loss: 9.61 | Total Steps: 332\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 10  | Average Reward 4.09  | Actor loss: 0.01 | Critic loss: 2.28 | Entropy loss: -0.0484  | Total Loss: 2.24 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 10  | Average Reward 4.09  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0073  | Total Loss: 0.00 | Total Steps: 47\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 10  | Average Reward 4.09  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0005  | Total Loss: 0.02 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: 10  | Average Reward 4.09  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0035  | Total Loss: 0.05 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 10  | Average Reward 4.29  | Actor loss: 0.00 | Critic loss: 0.65 | Entropy loss: -0.0011  | Total Loss: 0.65 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 2  | Average Reward 4.21  | Actor loss: 0.00 | Critic loss: 0.55 | Entropy loss: -0.0065  | Total Loss: 0.54 | Total Steps: 58\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 10  | Average Reward 4.24  | Actor loss: 0.00 | Critic loss: 0.63 | Entropy loss: -0.0011  | Total Loss: 0.63 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 8  | Average Reward 4.21  | Actor loss: 0.00 | Critic loss: 0.81 | Entropy loss: -0.0206  | Total Loss: 0.79 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 8  | Average Reward 4.19  | Actor loss: -0.00 | Critic loss: 0.06 | Entropy loss: -0.0249  | Total Loss: 0.03 | Total Steps: 41\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 20/100  | Episode Reward: -96  | Average Reward 3.13  | Actor loss: -2.84 | Critic loss: 92.61 | Entropy loss: -0.0603  | Total Loss: 89.71 | Total Steps: 500\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 10  | Average Reward 3.13  | Actor loss: -0.00 | Critic loss: 0.04 | Entropy loss: -0.0351  | Total Loss: 0.01 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 22/100  | Episode Reward: 10  | Average Reward 3.16  | Actor loss: 0.00 | Critic loss: 0.44 | Entropy loss: -0.0122  | Total Loss: 0.43 | Total Steps: 11\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 10  | Average Reward 3.16  | Actor loss: 0.00 | Critic loss: 0.24 | Entropy loss: -0.0199  | Total Loss: 0.22 | Total Steps: 10\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 10  | Average Reward 3.36  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0035  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 10  | Average Reward 3.36  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0053  | Total Loss: 0.05 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 10  | Average Reward 3.36  | Actor loss: 0.01 | Critic loss: 3.14 | Entropy loss: -0.0062  | Total Loss: 3.14 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 10  | Average Reward 3.38  | Actor loss: 0.00 | Critic loss: 0.43 | Entropy loss: -0.0003  | Total Loss: 0.43 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 8  | Average Reward 3.36  | Actor loss: 0.00 | Critic loss: 1.52 | Entropy loss: -0.0204  | Total Loss: 1.51 | Total Steps: 49\n",
      "TEST: ---green cube---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 10  | Average Reward 3.36  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0229  | Total Loss: -0.02 | Total Steps: 10\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 10  | Average Reward 3.36  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0346  | Total Loss: 0.13 | Total Steps: 7\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 10  | Average Reward 3.36  | Actor loss: 0.04 | Critic loss: 1.85 | Entropy loss: -0.0366  | Total Loss: 1.86 | Total Steps: 7\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 32/100  | Episode Reward: -81  | Average Reward 2.45  | Actor loss: -0.12 | Critic loss: 84.18 | Entropy loss: -0.0646  | Total Loss: 84.00 | Total Steps: 500\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 33/100  | Episode Reward: 10  | Average Reward 2.45  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0110  | Total Loss: -0.01 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 34/100  | Episode Reward: 10  | Average Reward 2.92  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0134  | Total Loss: 0.20 | Total Steps: 57\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 35/100  | Episode Reward: 4  | Average Reward 2.90  | Actor loss: 0.36 | Critic loss: 15.65 | Entropy loss: -0.0427  | Total Loss: 15.97 | Total Steps: 66\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 36/100  | Episode Reward: 8  | Average Reward 2.88  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0055  | Total Loss: 0.03 | Total Steps: 30\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 37/100  | Episode Reward: 8  | Average Reward 2.90  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0087  | Total Loss: 0.13 | Total Steps: 44\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: 10  | Average Reward 2.90  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0016  | Total Loss: 0.06 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 39/100  | Episode Reward: -10  | Average Reward 2.73  | Actor loss: -0.00 | Critic loss: 69.00 | Entropy loss: -0.0002  | Total Loss: 68.99 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 10  | Average Reward 2.73  | Actor loss: 0.03 | Critic loss: 10.87 | Entropy loss: -0.0151  | Total Loss: 10.89 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 41/100  | Episode Reward: -84  | Average Reward 1.79  | Actor loss: -0.78 | Critic loss: 72.28 | Entropy loss: -0.0569  | Total Loss: 71.45 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 8  | Average Reward 1.77  | Actor loss: 0.26 | Critic loss: 10.45 | Entropy loss: -0.0514  | Total Loss: 10.66 | Total Steps: 27\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 43/100  | Episode Reward: 10  | Average Reward 2.31  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0060  | Total Loss: -0.01 | Total Steps: 96\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 5  | Average Reward 2.38  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0042  | Total Loss: 0.06 | Total Steps: 47\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: 10  | Average Reward 2.58  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0010  | Total Loss: 0.10 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 46/100  | Episode Reward: -10  | Average Reward 2.38  | Actor loss: -0.00 | Critic loss: 69.40 | Entropy loss: -0.0033  | Total Loss: 69.40 | Total Steps: 500\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 10  | Average Reward 2.38  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0082  | Total Loss: -0.00 | Total Steps: 50\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 10  | Average Reward 2.38  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0070  | Total Loss: 0.12 | Total Steps: 57\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 5  | Average Reward 2.33  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0047  | Total Loss: 0.07 | Total Steps: 42\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 8  | Average Reward 2.38  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0138  | Total Loss: 0.02 | Total Steps: 51\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 5  | Average Reward 3.05  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0273  | Total Loss: -0.00 | Total Steps: 51\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 10  | Average Reward 3.06  | Actor loss: 0.00 | Critic loss: 0.65 | Entropy loss: -0.0018  | Total Loss: 0.65 | Total Steps: 31\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 53/100  | Episode Reward: 10  | Average Reward 3.64  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0063  | Total Loss: 0.00 | Total Steps: 47\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 54/100  | Episode Reward: 10  | Average Reward 3.64  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0004  | Total Loss: 0.06 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 8  | Average Reward 3.62  | Actor loss: 0.00 | Critic loss: 1.16 | Entropy loss: -0.0010  | Total Loss: 1.16 | Total Steps: 29\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: 5  | Average Reward 4.05  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0058  | Total Loss: 0.04 | Total Steps: 107\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 10  | Average Reward 4.08  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0004  | Total Loss: 0.06 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 8  | Average Reward 4.05  | Actor loss: 0.02 | Critic loss: 0.22 | Entropy loss: -0.0022  | Total Loss: 0.24 | Total Steps: 44\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 8  | Average Reward 4.03  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0003  | Total Loss: 0.03 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 60/100  | Episode Reward: 8  | Average Reward 4.03  | Actor loss: -0.00 | Critic loss: 0.05 | Entropy loss: -0.0031  | Total Loss: 0.04 | Total Steps: 39\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 61/100  | Episode Reward: 10  | Average Reward 4.29  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0015  | Total Loss: 0.03 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 10  | Average Reward 4.29  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0005  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: -7  | Average Reward 4.14  | Actor loss: 21.33 | Critic loss: 30.64 | Entropy loss: -0.0548  | Total Loss: 51.92 | Total Steps: 122\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 64/100  | Episode Reward: -87  | Average Reward 3.29  | Actor loss: -1.96 | Critic loss: 99.08 | Entropy loss: -0.0642  | Total Loss: 97.06 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 65/100  | Episode Reward: 8  | Average Reward 3.31  | Actor loss: 0.00 | Critic loss: 1.14 | Entropy loss: -0.0126  | Total Loss: 1.13 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 10  | Average Reward 3.31  | Actor loss: 0.01 | Critic loss: 0.13 | Entropy loss: -0.0048  | Total Loss: 0.14 | Total Steps: 36\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 8  | Average Reward 3.31  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0020  | Total Loss: 0.03 | Total Steps: 36\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 68/100  | Episode Reward: 10  | Average Reward 3.31  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0207  | Total Loss: -0.01 | Total Steps: 49\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 10  | Average Reward 3.31  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0056  | Total Loss: 0.10 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 70/100  | Episode Reward: -114  | Average Reward 2.12  | Actor loss: -1.59 | Critic loss: 79.05 | Entropy loss: -0.0608  | Total Loss: 77.40 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 10  | Average Reward 2.15  | Actor loss: 0.00 | Critic loss: 0.47 | Entropy loss: -0.0321  | Total Loss: 0.44 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 8  | Average Reward 2.12  | Actor loss: 0.00 | Critic loss: 0.49 | Entropy loss: -0.0020  | Total Loss: 0.49 | Total Steps: 29\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 8  | Average Reward 2.10  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0008  | Total Loss: 0.00 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: 10  | Average Reward 2.10  | Actor loss: 0.00 | Critic loss: 0.25 | Entropy loss: -0.0023  | Total Loss: 0.25 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 10  | Average Reward 2.10  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0003  | Total Loss: 0.01 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 10  | Average Reward 2.10  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0007  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---red capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 77/100  | Episode Reward: 10  | Average Reward 2.35  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0494  | Total Loss: 0.02 | Total Steps: 9\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 10  | Average Reward 2.35  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0126  | Total Loss: 0.07 | Total Steps: 36\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 8  | Average Reward 2.33  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0007  | Total Loss: 0.02 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 10  | Average Reward 2.35  | Actor loss: 0.02 | Critic loss: 1.02 | Entropy loss: -0.0188  | Total Loss: 1.02 | Total Steps: 11\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 81/100  | Episode Reward: -87  | Average Reward 1.40  | Actor loss: -0.18 | Critic loss: 86.43 | Entropy loss: -0.0561  | Total Loss: 86.19 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 82/100  | Episode Reward: -78  | Average Reward 0.59  | Actor loss: -1.99 | Critic loss: 83.87 | Entropy loss: -0.0559  | Total Loss: 81.83 | Total Steps: 500\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 10  | Average Reward 0.62  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0096  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 84/100  | Episode Reward: 10  | Average Reward 0.62  | Actor loss: 0.00 | Critic loss: 0.35 | Entropy loss: -0.0163  | Total Loss: 0.33 | Total Steps: 9\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 85/100  | Episode Reward: 10  | Average Reward 0.62  | Actor loss: -0.00 | Critic loss: 0.04 | Entropy loss: -0.0033  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: 8  | Average Reward 0.59  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0190  | Total Loss: 0.01 | Total Steps: 47\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 87/100  | Episode Reward: -97  | Average Reward -0.47  | Actor loss: -2.57 | Critic loss: 82.23 | Entropy loss: -0.0569  | Total Loss: 79.60 | Total Steps: 500\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 10  | Average Reward -0.30  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0097  | Total Loss: -0.01 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 89/100  | Episode Reward: 5  | Average Reward -0.35  | Actor loss: 0.00 | Critic loss: 0.31 | Entropy loss: -0.0011  | Total Loss: 0.31 | Total Steps: 42\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 90/100  | Episode Reward: 10  | Average Reward -0.35  | Actor loss: 0.01 | Critic loss: 7.72 | Entropy loss: -0.0437  | Total Loss: 7.68 | Total Steps: 7\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 10  | Average Reward -0.33  | Actor loss: 0.02 | Critic loss: 2.97 | Entropy loss: -0.0133  | Total Loss: 2.98 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 10  | Average Reward -0.33  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0159  | Total Loss: 0.01 | Total Steps: 10\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: 8  | Average Reward -0.35  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0055  | Total Loss: 0.02 | Total Steps: 36\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 10  | Average Reward -0.24  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0111  | Total Loss: 0.03 | Total Steps: 44\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: 10  | Average Reward -0.19  | Actor loss: 0.01 | Critic loss: 3.06 | Entropy loss: -0.0083  | Total Loss: 3.07 | Total Steps: 36\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 10  | Average Reward -0.14  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0037  | Total Loss: 0.06 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 10  | Average Reward -0.14  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0016  | Total Loss: 0.03 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 98/100  | Episode Reward: -91  | Average Reward -1.05  | Actor loss: -0.41 | Critic loss: 79.86 | Entropy loss: -0.0554  | Total Loss: 79.40 | Total Steps: 500\n",
      "TEST: ---blue cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 10  | Average Reward -1.05  | Actor loss: -0.00 | Critic loss: 0.04 | Entropy loss: -0.0098  | Total Loss: 0.03 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 10  | Average Reward -1.02  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0105  | Total Loss: 0.02 | Total Steps: 49\n",
      "\n",
      "---red cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2002/94000  | Episode Reward: 5  | Average Reward 8.99  | Actor loss: -0.48 | Critic loss: 12.79 | Entropy loss: -0.0032  | Total Loss: 12.31 | Total Steps: 97\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2003/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.19 | Critic loss: 0.69 | Entropy loss: -0.0007  | Total Loss: 0.87 | Total Steps: 10\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2004/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.01 | Critic loss: 0.15 | Entropy loss: -0.0000  | Total Loss: 0.16 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2005/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.20 | Critic loss: 3.17 | Entropy loss: -0.0012  | Total Loss: 3.38 | Total Steps: 37\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2006/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.05 | Critic loss: 0.58 | Entropy loss: -0.0007  | Total Loss: 0.62 | Total Steps: 44\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2007/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2008/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2009/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.02 | Critic loss: 2.61 | Entropy loss: -0.0005  | Total Loss: 2.63 | Total Steps: 31\n",
      "\n",
      "---blue cube---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 2010/94000  | Episode Reward: -10  | Average Reward 8.79  | Actor loss: -0.00 | Critic loss: 4.69 | Entropy loss: -0.0001  | Total Loss: 4.69 | Total Steps: 500\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2011/94000  | Episode Reward: 10  | Average Reward 8.79  | Actor loss: 0.15 | Critic loss: 1.01 | Entropy loss: -0.0012  | Total Loss: 1.15 | Total Steps: 8\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2012/94000  | Episode Reward: 10  | Average Reward 8.79  | Actor loss: 0.03 | Critic loss: 4.86 | Entropy loss: -0.0006  | Total Loss: 4.89 | Total Steps: 29\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2013/94000  | Episode Reward: 10  | Average Reward 8.81  | Actor loss: 0.03 | Critic loss: 3.35 | Entropy loss: -0.0003  | Total Loss: 3.38 | Total Steps: 31\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2014/94000  | Episode Reward: 10  | Average Reward 8.81  | Actor loss: 0.00 | Critic loss: 1.43 | Entropy loss: -0.0004  | Total Loss: 1.43 | Total Steps: 29\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2015/94000  | Episode Reward: 10  | Average Reward 8.81  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2016/94000  | Episode Reward: 10  | Average Reward 8.81  | Actor loss: -0.63 | Critic loss: 4.66 | Entropy loss: -0.0075  | Total Loss: 4.02 | Total Steps: 60\n",
      "\n",
      "---red cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2017/94000  | Episode Reward: 8  | Average Reward 8.79  | Actor loss: 0.27 | Critic loss: 6.15 | Entropy loss: -0.0027  | Total Loss: 6.42 | Total Steps: 33\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2018/94000  | Episode Reward: 10  | Average Reward 8.79  | Actor loss: 0.02 | Critic loss: 1.27 | Entropy loss: -0.0004  | Total Loss: 1.29 | Total Steps: 31\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2019/94000  | Episode Reward: 10  | Average Reward 8.79  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0000  | Total Loss: 0.23 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2020/94000  | Episode Reward: 10  | Average Reward 8.81  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2021/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: 0.01 | Critic loss: 0.88 | Entropy loss: -0.0002  | Total Loss: 0.89 | Total Steps: 32\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2022/94000  | Episode Reward: 10  | Average Reward 8.89  | Actor loss: 0.11 | Critic loss: 0.33 | Entropy loss: -0.0011  | Total Loss: 0.43 | Total Steps: 41\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2023/94000  | Episode Reward: 8  | Average Reward 8.87  | Actor loss: -0.05 | Critic loss: 1.72 | Entropy loss: -0.0024  | Total Loss: 1.67 | Total Steps: 215\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2024/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: 0.06 | Critic loss: 0.33 | Entropy loss: -0.0008  | Total Loss: 0.39 | Total Steps: 12\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2025/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: -0.13 | Critic loss: 2.51 | Entropy loss: -0.0010  | Total Loss: 2.38 | Total Steps: 47\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2026/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: -0.19 | Critic loss: 1.47 | Entropy loss: -0.0009  | Total Loss: 1.28 | Total Steps: 34\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2027/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: 0.04 | Critic loss: 0.63 | Entropy loss: -0.0019  | Total Loss: 0.68 | Total Steps: 14\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2028/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: 0.17 | Critic loss: 0.62 | Entropy loss: -0.0027  | Total Loss: 0.79 | Total Steps: 46\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2029/94000  | Episode Reward: 10  | Average Reward 8.87  | Actor loss: -0.02 | Critic loss: 5.18 | Entropy loss: -0.0001  | Total Loss: 5.15 | Total Steps: 42\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2030/94000  | Episode Reward: 10  | Average Reward 8.89  | Actor loss: 0.00 | Critic loss: 2.33 | Entropy loss: -0.0000  | Total Loss: 2.33 | Total Steps: 31\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2031/94000  | Episode Reward: 10  | Average Reward 8.89  | Actor loss: 0.00 | Critic loss: 1.08 | Entropy loss: -0.0001  | Total Loss: 1.08 | Total Steps: 31\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2032/94000  | Episode Reward: 10  | Average Reward 8.89  | Actor loss: 0.00 | Critic loss: 1.09 | Entropy loss: -0.0000  | Total Loss: 1.10 | Total Steps: 31\n",
      "\n",
      "---yellow capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2033/94000  | Episode Reward: 10  | Average Reward 8.89  | Actor loss: -0.55 | Critic loss: 4.65 | Entropy loss: -0.0094  | Total Loss: 4.09 | Total Steps: 68\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2034/94000  | Episode Reward: 10  | Average Reward 8.91  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0000  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2035/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: -0.11 | Critic loss: 0.05 | Entropy loss: -0.0012  | Total Loss: -0.06 | Total Steps: 9\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2036/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0000  | Total Loss: 0.13 | Total Steps: 6\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2037/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: 0.00 | Critic loss: 0.77 | Entropy loss: -0.0001  | Total Loss: 0.77 | Total Steps: 38\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2038/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2039/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.00 | Critic loss: 1.12 | Entropy loss: -0.0000  | Total Loss: 1.12 | Total Steps: 31\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2040/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.14 | Critic loss: 0.71 | Entropy loss: -0.0019  | Total Loss: 0.85 | Total Steps: 44\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2041/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.42 | Critic loss: 1.84 | Entropy loss: -0.0014  | Total Loss: 2.26 | Total Steps: 36\n",
      "\n",
      "---black cube---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 2042/94000  | Episode Reward: -10  | Average Reward 8.79  | Actor loss: -0.00 | Critic loss: 6.23 | Entropy loss: -0.0001  | Total Loss: 6.23 | Total Steps: 500\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2043/94000  | Episode Reward: 10  | Average Reward 8.79  | Actor loss: -0.39 | Critic loss: 2.11 | Entropy loss: -0.0027  | Total Loss: 1.72 | Total Steps: 51\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2044/94000  | Episode Reward: 5  | Average Reward 8.74  | Actor loss: -0.16 | Critic loss: 4.73 | Entropy loss: -0.0012  | Total Loss: 4.57 | Total Steps: 76\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2045/94000  | Episode Reward: 10  | Average Reward 8.74  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2046/94000  | Episode Reward: 10  | Average Reward 8.74  | Actor loss: 0.20 | Critic loss: 0.26 | Entropy loss: -0.0007  | Total Loss: 0.46 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2047/94000  | Episode Reward: 10  | Average Reward 8.74  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2048/94000  | Episode Reward: 10  | Average Reward 8.77  | Actor loss: -0.05 | Critic loss: 1.08 | Entropy loss: -0.0034  | Total Loss: 1.03 | Total Steps: 16\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2049/94000  | Episode Reward: 10  | Average Reward 8.81  | Actor loss: -0.66 | Critic loss: 4.74 | Entropy loss: -0.0041  | Total Loss: 4.08 | Total Steps: 67\n",
      "\n",
      "---yellow capsule---\n",
      "Decision Step reward: -1.0\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2050/94000  | Episode Reward: 9  | Average Reward 8.80  | Actor loss: -0.13 | Critic loss: 1.64 | Entropy loss: -0.0033  | Total Loss: 1.51 | Total Steps: 26\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2051/94000  | Episode Reward: 10  | Average Reward 8.83  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0000  | Total Loss: 0.08 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Step: 250\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 2052/94000  | Episode Reward: -29  | Average Reward 8.44  | Actor loss: -3.71 | Critic loss: 14.88 | Entropy loss: -0.0702  | Total Loss: 11.11 | Total Steps: 500\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2053/94000  | Episode Reward: 8  | Average Reward 8.46  | Actor loss: -0.01 | Critic loss: 4.96 | Entropy loss: -0.0004  | Total Loss: 4.96 | Total Steps: 49\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2054/94000  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: -0.00 | Critic loss: 0.66 | Entropy loss: -0.0005  | Total Loss: 0.66 | Total Steps: 49\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2055/94000  | Episode Reward: 5  | Average Reward 8.41  | Actor loss: -0.12 | Critic loss: 4.48 | Entropy loss: -0.0009  | Total Loss: 4.36 | Total Steps: 49\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2056/94000  | Episode Reward: 10  | Average Reward 8.44  | Actor loss: 0.00 | Critic loss: 2.62 | Entropy loss: -0.0000  | Total Loss: 2.62 | Total Steps: 31\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2057/94000  | Episode Reward: 10  | Average Reward 8.44  | Actor loss: 0.15 | Critic loss: 6.22 | Entropy loss: -0.0013  | Total Loss: 6.37 | Total Steps: 56\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2058/94000  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: 0.31 | Critic loss: 0.90 | Entropy loss: -0.0007  | Total Loss: 1.21 | Total Steps: 10\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2059/94000  | Episode Reward: 8  | Average Reward 8.46  | Actor loss: 0.08 | Critic loss: 6.50 | Entropy loss: -0.0014  | Total Loss: 6.57 | Total Steps: 45\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2060/94000  | Episode Reward: 10  | Average Reward 8.54  | Actor loss: -0.03 | Critic loss: 0.93 | Entropy loss: -0.0013  | Total Loss: 0.90 | Total Steps: 64\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2061/94000  | Episode Reward: 10  | Average Reward 8.59  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2062/94000  | Episode Reward: 10  | Average Reward 8.59  | Actor loss: 0.24 | Critic loss: 1.15 | Entropy loss: -0.0006  | Total Loss: 1.39 | Total Steps: 11\n",
      "\n",
      "---green cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2063/94000  | Episode Reward: 10  | Average Reward 8.59  | Actor loss: 0.11 | Critic loss: 0.69 | Entropy loss: -0.0014  | Total Loss: 0.80 | Total Steps: 40\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2064/94000  | Episode Reward: 10  | Average Reward 8.59  | Actor loss: 0.19 | Critic loss: 0.24 | Entropy loss: -0.0005  | Total Loss: 0.43 | Total Steps: 8\n",
      "\n",
      "---yellow cube---\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Step: 250\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2065/94000  | Episode Reward: -25  | Average Reward 8.24  | Actor loss: -0.90 | Critic loss: 4.87 | Entropy loss: -0.0700  | Total Loss: 3.90 | Total Steps: 437\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2066/94000  | Episode Reward: 10  | Average Reward 8.24  | Actor loss: 0.30 | Critic loss: 1.81 | Entropy loss: -0.0006  | Total Loss: 2.10 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2067/94000  | Episode Reward: 10  | Average Reward 8.24  | Actor loss: 0.16 | Critic loss: 0.58 | Entropy loss: -0.0076  | Total Loss: 0.73 | Total Steps: 41\n",
      "\n",
      "---black capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2068/94000  | Episode Reward: 8  | Average Reward 8.21  | Actor loss: -0.01 | Critic loss: 1.25 | Entropy loss: -0.0076  | Total Loss: 1.23 | Total Steps: 108\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2069/94000  | Episode Reward: 8  | Average Reward 8.19  | Actor loss: -0.08 | Critic loss: 3.28 | Entropy loss: -0.0017  | Total Loss: 3.20 | Total Steps: 77\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2070/94000  | Episode Reward: 10  | Average Reward 8.19  | Actor loss: 0.00 | Critic loss: 0.35 | Entropy loss: -0.0001  | Total Loss: 0.35 | Total Steps: 49\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2071/94000  | Episode Reward: 8  | Average Reward 8.16  | Actor loss: -0.01 | Critic loss: 6.11 | Entropy loss: -0.0001  | Total Loss: 6.11 | Total Steps: 34\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2072/94000  | Episode Reward: 10  | Average Reward 8.16  | Actor loss: 0.00 | Critic loss: 0.25 | Entropy loss: -0.0000  | Total Loss: 0.25 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2073/94000  | Episode Reward: 10  | Average Reward 8.16  | Actor loss: 0.01 | Critic loss: 1.66 | Entropy loss: -0.0000  | Total Loss: 1.67 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Decision Step reward: -1.0\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2074/94000  | Episode Reward: 9  | Average Reward 8.15  | Actor loss: -0.10 | Critic loss: 5.47 | Entropy loss: -0.0089  | Total Loss: 5.36 | Total Steps: 61\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2075/94000  | Episode Reward: 10  | Average Reward 8.15  | Actor loss: 0.00 | Critic loss: 2.48 | Entropy loss: -0.0001  | Total Loss: 2.48 | Total Steps: 31\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2076/94000  | Episode Reward: 10  | Average Reward 8.15  | Actor loss: 0.00 | Critic loss: 1.83 | Entropy loss: -0.0000  | Total Loss: 1.84 | Total Steps: 31\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2077/94000  | Episode Reward: 5  | Average Reward 8.11  | Actor loss: -0.07 | Critic loss: 7.43 | Entropy loss: -0.0008  | Total Loss: 7.35 | Total Steps: 47\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2078/94000  | Episode Reward: 10  | Average Reward 8.13  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0000  | Total Loss: 0.16 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2079/94000  | Episode Reward: 10  | Average Reward 8.15  | Actor loss: -0.00 | Critic loss: 1.53 | Entropy loss: -0.0017  | Total Loss: 1.53 | Total Steps: 50\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2080/94000  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.17 | Critic loss: 0.34 | Entropy loss: -0.0010  | Total Loss: 0.51 | Total Steps: 10\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2081/94000  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0000  | Total Loss: 0.10 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2082/94000  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.51 | Critic loss: 1.30 | Entropy loss: -0.0012  | Total Loss: 1.81 | Total Steps: 10\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2083/94000  | Episode Reward: 8  | Average Reward 8.18  | Actor loss: -0.13 | Critic loss: 1.90 | Entropy loss: -0.0018  | Total Loss: 1.77 | Total Steps: 30\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2084/94000  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.21 | Critic loss: 0.50 | Entropy loss: -0.0011  | Total Loss: 0.71 | Total Steps: 10\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2085/94000  | Episode Reward: 10  | Average Reward 8.21  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Decision Step reward: -1.0\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2086/94000  | Episode Reward: 9  | Average Reward 8.20  | Actor loss: 0.22 | Critic loss: 2.17 | Entropy loss: -0.0040  | Total Loss: 2.39 | Total Steps: 28\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2087/94000  | Episode Reward: 8  | Average Reward 8.17  | Actor loss: -0.00 | Critic loss: 0.19 | Entropy loss: -0.0001  | Total Loss: 0.19 | Total Steps: 38\n",
      "\n",
      "---yellow cube---\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2088/94000  | Episode Reward: -9  | Average Reward 7.98  | Actor loss: -2.28 | Critic loss: 11.03 | Entropy loss: -0.0471  | Total Loss: 8.70 | Total Steps: 174\n",
      "\n",
      "---red sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2089/94000  | Episode Reward: 10  | Average Reward 7.98  | Actor loss: -0.16 | Critic loss: 5.86 | Entropy loss: -0.0009  | Total Loss: 5.70 | Total Steps: 19\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2090/94000  | Episode Reward: 10  | Average Reward 7.98  | Actor loss: 0.06 | Critic loss: 2.22 | Entropy loss: -0.0025  | Total Loss: 2.28 | Total Steps: 20\n",
      "\n",
      "---yellow sphere---\n",
      "Decision Step reward: -1.0\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2091/94000  | Episode Reward: 9  | Average Reward 7.97  | Actor loss: -0.10 | Critic loss: 4.98 | Entropy loss: -0.0073  | Total Loss: 4.88 | Total Steps: 56\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2092/94000  | Episode Reward: 10  | Average Reward 7.97  | Actor loss: 0.01 | Critic loss: 0.10 | Entropy loss: -0.0005  | Total Loss: 0.11 | Total Steps: 9\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2093/94000  | Episode Reward: 10  | Average Reward 7.97  | Actor loss: -1.00 | Critic loss: 0.26 | Entropy loss: -0.0059  | Total Loss: -0.74 | Total Steps: 13\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2094/94000  | Episode Reward: 10  | Average Reward 7.97  | Actor loss: 0.05 | Critic loss: 0.36 | Entropy loss: -0.0003  | Total Loss: 0.41 | Total Steps: 11\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2095/94000  | Episode Reward: 10  | Average Reward 7.97  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2096/94000  | Episode Reward: 10  | Average Reward 8.00  | Actor loss: -0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2097/94000  | Episode Reward: 2  | Average Reward 7.93  | Actor loss: -0.72 | Critic loss: 12.37 | Entropy loss: -0.0056  | Total Loss: 11.64 | Total Steps: 95\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2098/94000  | Episode Reward: 8  | Average Reward 7.91  | Actor loss: 0.05 | Critic loss: 2.88 | Entropy loss: -0.0009  | Total Loss: 2.94 | Total Steps: 34\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2099/94000  | Episode Reward: 10  | Average Reward 7.91  | Actor loss: 0.00 | Critic loss: 2.70 | Entropy loss: -0.0000  | Total Loss: 2.71 | Total Steps: 31\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2100/94000  | Episode Reward: 10  | Average Reward 8.11  | Actor loss: 0.00 | Critic loss: 0.28 | Entropy loss: -0.0000  | Total Loss: 0.28 | Total Steps: 6\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2101/94000  | Episode Reward: 10  | Average Reward 8.11  | Actor loss: 0.12 | Critic loss: 0.56 | Entropy loss: -0.0008  | Total Loss: 0.68 | Total Steps: 10\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 10  | Average Reward -1.00  | Actor loss: 0.00 | Critic loss: 4.44 | Entropy loss: -0.0008  | Total Loss: 4.44 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 10  | Average Reward -1.00  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0368  | Total Loss: 0.12 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "TEST: Step: 200\n",
      "Testing  | Episode: 3/100  | Episode Reward: -11  | Average Reward -1.19  | Actor loss: 22.25 | Critic loss: 45.49 | Entropy loss: -0.0709  | Total Loss: 67.67 | Total Steps: 200\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 10  | Average Reward -1.19  | Actor loss: 0.06 | Critic loss: 18.40 | Entropy loss: -0.0371  | Total Loss: 18.43 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 5  | Average Reward -1.24  | Actor loss: 0.00 | Critic loss: 0.49 | Entropy loss: -0.0193  | Total Loss: 0.48 | Total Steps: 48\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 10  | Average Reward -1.21  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0022  | Total Loss: 0.04 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: 8  | Average Reward -1.21  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0003  | Total Loss: 0.14 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: -15  | Average Reward -1.44  | Actor loss: 0.31 | Critic loss: 12.27 | Entropy loss: -0.0669  | Total Loss: 12.51 | Total Steps: 244\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 10  | Average Reward -1.44  | Actor loss: 0.01 | Critic loss: 2.59 | Entropy loss: -0.0114  | Total Loss: 2.59 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 8  | Average Reward -1.00  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0070  | Total Loss: 0.05 | Total Steps: 54\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 0  | Average Reward -1.10  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0597  | Total Loss: -0.05 | Total Steps: 122\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 10  | Average Reward -1.10  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0556  | Total Loss: -0.05 | Total Steps: 9\n",
      "TEST: ---green cube---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 10  | Average Reward -1.10  | Actor loss: 0.00 | Critic loss: 0.27 | Entropy loss: -0.0095  | Total Loss: 0.26 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: 10  | Average Reward -1.10  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0022  | Total Loss: 0.04 | Total Steps: 126\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 8  | Average Reward -1.12  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0003  | Total Loss: 0.09 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 10  | Average Reward -1.05  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0002  | Total Loss: 0.07 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 10  | Average Reward -1.05  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0484  | Total Loss: 0.02 | Total Steps: 10\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 10  | Average Reward -1.02  | Actor loss: -0.00 | Critic loss: 0.05 | Entropy loss: -0.0085  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 5  | Average Reward -1.05  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0053  | Total Loss: -0.00 | Total Steps: 49\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: 10  | Average Reward 0.01  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0004  | Total Loss: 0.13 | Total Steps: 36\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 8  | Average Reward -0.02  | Actor loss: 0.00 | Critic loss: 0.36 | Entropy loss: -0.0105  | Total Loss: 0.35 | Total Steps: 44\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 22/100  | Episode Reward: 10  | Average Reward -0.02  | Actor loss: 0.07 | Critic loss: 3.87 | Entropy loss: -0.0215  | Total Loss: 3.92 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 10  | Average Reward -0.02  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0016  | Total Loss: 0.00 | Total Steps: 40\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 8  | Average Reward -0.04  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0015  | Total Loss: 0.17 | Total Steps: 34\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 8  | Average Reward -0.07  | Actor loss: 0.00 | Critic loss: 0.88 | Entropy loss: -0.0003  | Total Loss: 0.88 | Total Steps: 29\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 5  | Average Reward -0.12  | Actor loss: 0.05 | Critic loss: 5.63 | Entropy loss: -0.0587  | Total Loss: 5.62 | Total Steps: 150\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 10  | Average Reward -0.12  | Actor loss: 0.01 | Critic loss: 1.15 | Entropy loss: -0.0100  | Total Loss: 1.14 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 28/100  | Episode Reward: -68  | Average Reward -0.88  | Actor loss: -0.51 | Critic loss: 64.62 | Entropy loss: -0.0675  | Total Loss: 64.04 | Total Steps: 500\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 10  | Average Reward -0.88  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0424  | Total Loss: 0.05 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 10  | Average Reward -0.88  | Actor loss: 0.01 | Critic loss: 1.13 | Entropy loss: -0.0072  | Total Loss: 1.13 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: 8  | Average Reward -0.90  | Actor loss: 0.00 | Critic loss: 1.19 | Entropy loss: -0.0086  | Total Loss: 1.19 | Total Steps: 34\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 32/100  | Episode Reward: 8  | Average Reward -0.01  | Actor loss: 0.00 | Critic loss: 0.82 | Entropy loss: -0.0169  | Total Loss: 0.81 | Total Steps: 39\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 33/100  | Episode Reward: 10  | Average Reward -0.01  | Actor loss: -0.00 | Critic loss: 0.05 | Entropy loss: -0.0033  | Total Loss: 0.04 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 34/100  | Episode Reward: 8  | Average Reward -0.04  | Actor loss: 0.00 | Critic loss: 0.79 | Entropy loss: -0.0003  | Total Loss: 0.79 | Total Steps: 29\n",
      "TEST: ---black sphere---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 35/100  | Episode Reward: 10  | Average Reward 0.02  | Actor loss: 0.00 | Critic loss: 1.50 | Entropy loss: -0.0002  | Total Loss: 1.50 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 36/100  | Episode Reward: 10  | Average Reward 0.04  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0002  | Total Loss: 0.15 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 37/100  | Episode Reward: 10  | Average Reward 0.07  | Actor loss: -0.00 | Critic loss: 0.05 | Entropy loss: -0.0006  | Total Loss: 0.05 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: 8  | Average Reward 0.04  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0015  | Total Loss: 0.05 | Total Steps: 34\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 5  | Average Reward 0.20  | Actor loss: 0.01 | Critic loss: 0.06 | Entropy loss: -0.0022  | Total Loss: 0.07 | Total Steps: 47\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 10  | Average Reward 0.20  | Actor loss: 0.01 | Critic loss: 14.06 | Entropy loss: -0.0202  | Total Loss: 14.05 | Total Steps: 7\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 9  | Average Reward 1.12  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0102  | Total Loss: 0.21 | Total Steps: 127\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 5  | Average Reward 1.09  | Actor loss: 0.00 | Critic loss: 0.78 | Entropy loss: -0.0009  | Total Loss: 0.78 | Total Steps: 49\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 43/100  | Episode Reward: 10  | Average Reward 1.09  | Actor loss: 0.00 | Critic loss: 0.27 | Entropy loss: -0.0004  | Total Loss: 0.27 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 10  | Average Reward 1.15  | Actor loss: 0.01 | Critic loss: 0.28 | Entropy loss: -0.0207  | Total Loss: 0.26 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: 10  | Average Reward 1.15  | Actor loss: 0.00 | Critic loss: 0.69 | Entropy loss: -0.0008  | Total Loss: 0.69 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 8  | Average Reward 1.32  | Actor loss: 0.00 | Critic loss: 0.44 | Entropy loss: -0.0007  | Total Loss: 0.44 | Total Steps: 38\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 5  | Average Reward 1.27  | Actor loss: 0.00 | Critic loss: 0.31 | Entropy loss: -0.0030  | Total Loss: 0.31 | Total Steps: 47\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 10  | Average Reward 1.27  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0496  | Total Loss: -0.05 | Total Steps: 8\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 10  | Average Reward 1.32  | Actor loss: 0.00 | Critic loss: 0.71 | Entropy loss: -0.0017  | Total Loss: 0.71 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 10  | Average Reward 1.34  | Actor loss: 0.00 | Critic loss: 0.94 | Entropy loss: -0.0388  | Total Loss: 0.91 | Total Steps: 8\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 5  | Average Reward 1.34  | Actor loss: 0.25 | Critic loss: 0.03 | Entropy loss: -0.0115  | Total Loss: 0.27 | Total Steps: 46\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 10  | Average Reward 1.34  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0021  | Total Loss: 0.23 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 53/100  | Episode Reward: 10  | Average Reward 1.34  | Actor loss: 0.01 | Critic loss: 1.13 | Entropy loss: -0.0005  | Total Loss: 1.13 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 54/100  | Episode Reward: 10  | Average Reward 1.34  | Actor loss: -0.00 | Critic loss: 0.04 | Entropy loss: -0.0005  | Total Loss: 0.03 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 10  | Average Reward 1.37  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0133  | Total Loss: 0.02 | Total Steps: 12\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: 8  | Average Reward 1.40  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0050  | Total Loss: 0.11 | Total Steps: 199\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 2  | Average Reward 1.32  | Actor loss: 0.00 | Critic loss: 1.93 | Entropy loss: -0.0038  | Total Loss: 1.93 | Total Steps: 58\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 5  | Average Reward 1.29  | Actor loss: 0.00 | Critic loss: 0.77 | Entropy loss: -0.0114  | Total Loss: 0.76 | Total Steps: 47\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 59/100  | Episode Reward: 10  | Average Reward 1.32  | Actor loss: 0.01 | Critic loss: 0.29 | Entropy loss: -0.0238  | Total Loss: 0.27 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 60/100  | Episode Reward: 10  | Average Reward 1.34  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0107  | Total Loss: 0.03 | Total Steps: 34\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 61/100  | Episode Reward: -30  | Average Reward 0.94  | Actor loss: 0.78 | Critic loss: 11.78 | Entropy loss: -0.0723  | Total Loss: 12.48 | Total Steps: 362\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 10  | Average Reward 0.94  | Actor loss: 0.00 | Critic loss: 0.38 | Entropy loss: -0.0135  | Total Loss: 0.37 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 63/100  | Episode Reward: -10  | Average Reward 0.92  | Actor loss: -0.01 | Critic loss: 80.06 | Entropy loss: -0.0002  | Total Loss: 80.05 | Total Steps: 500\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 64/100  | Episode Reward: 10  | Average Reward 1.89  | Actor loss: 0.00 | Critic loss: 4.40 | Entropy loss: -0.0083  | Total Loss: 4.40 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 65/100  | Episode Reward: 10  | Average Reward 1.91  | Actor loss: 0.00 | Critic loss: 1.50 | Entropy loss: -0.0004  | Total Loss: 1.50 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 66/100  | Episode Reward: -10  | Average Reward 1.71  | Actor loss: -0.01 | Critic loss: 79.61 | Entropy loss: -0.0049  | Total Loss: 79.60 | Total Steps: 500\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 10  | Average Reward 1.74  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0054  | Total Loss: -0.00 | Total Steps: 40\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 68/100  | Episode Reward: 10  | Average Reward 1.74  | Actor loss: -0.00 | Critic loss: 0.04 | Entropy loss: -0.0016  | Total Loss: 0.03 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 8  | Average Reward 1.71  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0076  | Total Loss: 0.06 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 70/100  | Episode Reward: 8  | Average Reward 2.92  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0004  | Total Loss: 0.09 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 10  | Average Reward 2.92  | Actor loss: 0.01 | Critic loss: 2.19 | Entropy loss: -0.0033  | Total Loss: 2.20 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 10  | Average Reward 2.94  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0423  | Total Loss: -0.04 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 8  | Average Reward 2.94  | Actor loss: 0.02 | Critic loss: 4.31 | Entropy loss: -0.0068  | Total Loss: 4.32 | Total Steps: 80\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: 10  | Average Reward 2.94  | Actor loss: 0.01 | Critic loss: 0.39 | Entropy loss: -0.0342  | Total Loss: 0.37 | Total Steps: 9\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 75/100  | Episode Reward: 10  | Average Reward 2.94  | Actor loss: 0.01 | Critic loss: 2.56 | Entropy loss: -0.0059  | Total Loss: 2.56 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 8  | Average Reward 2.92  | Actor loss: 0.01 | Critic loss: 0.68 | Entropy loss: -0.0011  | Total Loss: 0.69 | Total Steps: 37\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 77/100  | Episode Reward: 10  | Average Reward 2.92  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0005  | Total Loss: 0.10 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 10  | Average Reward 2.92  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0004  | Total Loss: 0.10 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 8  | Average Reward 2.92  | Actor loss: 0.02 | Critic loss: 3.95 | Entropy loss: -0.0446  | Total Loss: 3.92 | Total Steps: 26\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 5  | Average Reward 2.88  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0070  | Total Loss: 0.11 | Total Steps: 52\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 8  | Average Reward 3.82  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0010  | Total Loss: 0.06 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: 5  | Average Reward 4.65  | Actor loss: 0.00 | Critic loss: 0.22 | Entropy loss: -0.0012  | Total Loss: 0.22 | Total Steps: 49\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 8  | Average Reward 4.62  | Actor loss: 0.00 | Critic loss: 0.66 | Entropy loss: -0.0139  | Total Loss: 0.65 | Total Steps: 29\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 84/100  | Episode Reward: -3  | Average Reward 4.50  | Actor loss: 0.00 | Critic loss: 0.41 | Entropy loss: -0.0766  | Total Loss: 0.33 | Total Steps: 176\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 85/100  | Episode Reward: 8  | Average Reward 4.47  | Actor loss: 0.00 | Critic loss: 0.84 | Entropy loss: -0.0028  | Total Loss: 0.84 | Total Steps: 29\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: 10  | Average Reward 4.50  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0383  | Total Loss: -0.04 | Total Steps: 8\n",
      "TEST: ---red capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 10  | Average Reward 5.57  | Actor loss: 0.00 | Critic loss: 0.74 | Entropy loss: -0.0251  | Total Loss: 0.71 | Total Steps: 10\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 8  | Average Reward 5.54  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0052  | Total Loss: 0.03 | Total Steps: 56\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 89/100  | Episode Reward: 5  | Average Reward 5.54  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0046  | Total Loss: 0.02 | Total Steps: 54\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 90/100  | Episode Reward: 8  | Average Reward 5.51  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0035  | Total Loss: 0.02 | Total Steps: 49\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 10  | Average Reward 5.51  | Actor loss: 0.01 | Critic loss: 2.83 | Entropy loss: -0.0008  | Total Loss: 2.84 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 10  | Average Reward 5.51  | Actor loss: -0.00 | Critic loss: 0.03 | Entropy loss: -0.0008  | Total Loss: 0.03 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 93/100  | Episode Reward: 8  | Average Reward 5.51  | Actor loss: 1.61 | Critic loss: 0.80 | Entropy loss: -0.0148  | Total Loss: 2.39 | Total Steps: 37\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 8  | Average Reward 5.49  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0048  | Total Loss: 0.06 | Total Steps: 96\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: 10  | Average Reward 5.49  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0012  | Total Loss: 0.08 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 8  | Average Reward 5.46  | Actor loss: 0.01 | Critic loss: 0.20 | Entropy loss: -0.0037  | Total Loss: 0.20 | Total Steps: 45\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 5  | Average Reward 5.42  | Actor loss: 0.01 | Critic loss: 0.04 | Entropy loss: -0.0103  | Total Loss: 0.04 | Total Steps: 47\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: 2  | Average Reward 6.35  | Actor loss: 0.00 | Critic loss: 0.32 | Entropy loss: -0.0095  | Total Loss: 0.31 | Total Steps: 51\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 8  | Average Reward 6.33  | Actor loss: 0.00 | Critic loss: 0.25 | Entropy loss: -0.0053  | Total Loss: 0.25 | Total Steps: 39\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 10  | Average Reward 6.33  | Actor loss: 0.01 | Critic loss: 1.15 | Entropy loss: -0.0011  | Total Loss: 1.15 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2102/94000  | Episode Reward: 10  | Average Reward 8.15  | Actor loss: 0.01 | Critic loss: 1.21 | Entropy loss: -0.0001  | Total Loss: 1.22 | Total Steps: 31\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2103/94000  | Episode Reward: 10  | Average Reward 8.15  | Actor loss: 0.00 | Critic loss: 1.49 | Entropy loss: -0.0000  | Total Loss: 1.49 | Total Steps: 31\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2104/94000  | Episode Reward: 10  | Average Reward 8.15  | Actor loss: 0.16 | Critic loss: 0.14 | Entropy loss: -0.0005  | Total Loss: 0.30 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2105/94000  | Episode Reward: 10  | Average Reward 8.15  | Actor loss: 0.07 | Critic loss: 1.58 | Entropy loss: -0.0002  | Total Loss: 1.64 | Total Steps: 36\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2106/94000  | Episode Reward: 10  | Average Reward 8.15  | Actor loss: 0.52 | Critic loss: 0.68 | Entropy loss: -0.0020  | Total Loss: 1.20 | Total Steps: 9\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2107/94000  | Episode Reward: 10  | Average Reward 8.15  | Actor loss: -0.00 | Critic loss: 2.46 | Entropy loss: -0.0001  | Total Loss: 2.46 | Total Steps: 34\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2108/94000  | Episode Reward: 8  | Average Reward 8.13  | Actor loss: -1.57 | Critic loss: 7.12 | Entropy loss: -0.0061  | Total Loss: 5.55 | Total Steps: 54\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2109/94000  | Episode Reward: 10  | Average Reward 8.13  | Actor loss: 0.32 | Critic loss: 0.22 | Entropy loss: -0.0029  | Total Loss: 0.54 | Total Steps: 11\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2110/94000  | Episode Reward: 10  | Average Reward 8.33  | Actor loss: -0.01 | Critic loss: 3.33 | Entropy loss: -0.0001  | Total Loss: 3.33 | Total Steps: 29\n",
      "\n",
      "---red cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2111/94000  | Episode Reward: 5  | Average Reward 8.28  | Actor loss: -0.10 | Critic loss: 2.94 | Entropy loss: -0.0017  | Total Loss: 2.84 | Total Steps: 45\n",
      "\n",
      "---red cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2112/94000  | Episode Reward: 8  | Average Reward 8.26  | Actor loss: -0.07 | Critic loss: 6.38 | Entropy loss: -0.0008  | Total Loss: 6.31 | Total Steps: 54\n",
      "\n",
      "---yellow cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2113/94000  | Episode Reward: 5  | Average Reward 8.21  | Actor loss: -1.87 | Critic loss: 8.73 | Entropy loss: -0.0137  | Total Loss: 6.85 | Total Steps: 73\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2114/94000  | Episode Reward: 8  | Average Reward 8.18  | Actor loss: -0.02 | Critic loss: 2.67 | Entropy loss: -0.0015  | Total Loss: 2.64 | Total Steps: 57\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2115/94000  | Episode Reward: 8  | Average Reward 8.15  | Actor loss: 0.15 | Critic loss: 0.57 | Entropy loss: -0.0020  | Total Loss: 0.72 | Total Steps: 38\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2116/94000  | Episode Reward: 10  | Average Reward 8.15  | Actor loss: 0.05 | Critic loss: 1.19 | Entropy loss: -0.0010  | Total Loss: 1.24 | Total Steps: 35\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2117/94000  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 0.28 | Entropy loss: -0.0000  | Total Loss: 0.28 | Total Steps: 6\n",
      "\n",
      "---red prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2118/94000  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.04 | Critic loss: 0.08 | Entropy loss: -0.0003  | Total Loss: 0.12 | Total Steps: 8\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2119/94000  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2120/94000  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0000  | Total Loss: 0.15 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2121/94000  | Episode Reward: 8  | Average Reward 8.15  | Actor loss: -0.13 | Critic loss: 9.14 | Entropy loss: -0.0091  | Total Loss: 9.00 | Total Steps: 69\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2122/94000  | Episode Reward: 10  | Average Reward 8.15  | Actor loss: -0.00 | Critic loss: 0.38 | Entropy loss: -0.0001  | Total Loss: 0.38 | Total Steps: 46\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2123/94000  | Episode Reward: 10  | Average Reward 8.18  | Actor loss: 0.00 | Critic loss: 0.29 | Entropy loss: -0.0001  | Total Loss: 0.29 | Total Steps: 39\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2124/94000  | Episode Reward: 8  | Average Reward 8.15  | Actor loss: -0.37 | Critic loss: 4.17 | Entropy loss: -0.0025  | Total Loss: 3.79 | Total Steps: 44\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2125/94000  | Episode Reward: 8  | Average Reward 8.13  | Actor loss: 0.11 | Critic loss: 0.61 | Entropy loss: -0.0021  | Total Loss: 0.72 | Total Steps: 38\n",
      "\n",
      "---yellow capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -1.0\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2126/94000  | Episode Reward: 4  | Average Reward 8.07  | Actor loss: -0.76 | Critic loss: 6.69 | Entropy loss: -0.0110  | Total Loss: 5.92 | Total Steps: 68\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2127/94000  | Episode Reward: 8  | Average Reward 8.04  | Actor loss: -0.00 | Critic loss: 3.35 | Entropy loss: -0.0001  | Total Loss: 3.35 | Total Steps: 49\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2128/94000  | Episode Reward: 10  | Average Reward 8.04  | Actor loss: 0.02 | Critic loss: 0.18 | Entropy loss: -0.0000  | Total Loss: 0.20 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2129/94000  | Episode Reward: 10  | Average Reward 8.04  | Actor loss: 0.03 | Critic loss: 0.77 | Entropy loss: -0.0006  | Total Loss: 0.80 | Total Steps: 11\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2130/94000  | Episode Reward: 8  | Average Reward 8.02  | Actor loss: -0.17 | Critic loss: 1.29 | Entropy loss: -0.0023  | Total Loss: 1.12 | Total Steps: 47\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2131/94000  | Episode Reward: 5  | Average Reward 7.97  | Actor loss: -0.47 | Critic loss: 2.44 | Entropy loss: -0.0041  | Total Loss: 1.97 | Total Steps: 53\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2132/94000  | Episode Reward: 10  | Average Reward 7.97  | Actor loss: -0.16 | Critic loss: 2.17 | Entropy loss: -0.0026  | Total Loss: 2.01 | Total Steps: 36\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2133/94000  | Episode Reward: 10  | Average Reward 7.97  | Actor loss: 0.04 | Critic loss: 0.07 | Entropy loss: -0.0011  | Total Loss: 0.11 | Total Steps: 10\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2134/94000  | Episode Reward: 10  | Average Reward 7.97  | Actor loss: -0.06 | Critic loss: 1.49 | Entropy loss: -0.0017  | Total Loss: 1.43 | Total Steps: 53\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2135/94000  | Episode Reward: 10  | Average Reward 7.97  | Actor loss: 0.03 | Critic loss: 1.02 | Entropy loss: -0.0005  | Total Loss: 1.05 | Total Steps: 12\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2136/94000  | Episode Reward: 10  | Average Reward 7.97  | Actor loss: 0.11 | Critic loss: 0.69 | Entropy loss: -0.0004  | Total Loss: 0.79 | Total Steps: 8\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2137/94000  | Episode Reward: 10  | Average Reward 7.97  | Actor loss: 0.10 | Critic loss: 0.90 | Entropy loss: -0.0028  | Total Loss: 1.00 | Total Steps: 11\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2138/94000  | Episode Reward: 10  | Average Reward 7.97  | Actor loss: 0.04 | Critic loss: 0.17 | Entropy loss: -0.0005  | Total Loss: 0.21 | Total Steps: 9\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2139/94000  | Episode Reward: 10  | Average Reward 7.97  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0000  | Total Loss: 0.10 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2140/94000  | Episode Reward: 8  | Average Reward 7.95  | Actor loss: -0.00 | Critic loss: 1.80 | Entropy loss: -0.0001  | Total Loss: 1.79 | Total Steps: 39\n",
      "\n",
      "---black capsule---\n",
      "Step: 250\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2141/94000  | Episode Reward: 8  | Average Reward 7.92  | Actor loss: -0.02 | Critic loss: 1.39 | Entropy loss: -0.0027  | Total Loss: 1.37 | Total Steps: 368\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2142/94000  | Episode Reward: 10  | Average Reward 8.12  | Actor loss: 0.00 | Critic loss: 0.25 | Entropy loss: -0.0000  | Total Loss: 0.25 | Total Steps: 6\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2143/94000  | Episode Reward: 10  | Average Reward 8.12  | Actor loss: 0.02 | Critic loss: 0.02 | Entropy loss: -0.0003  | Total Loss: 0.05 | Total Steps: 8\n",
      "\n",
      "---yellow sphere---\n",
      "Decision Step reward: -1.0\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2144/94000  | Episode Reward: 9  | Average Reward 8.16  | Actor loss: -0.25 | Critic loss: 2.53 | Entropy loss: -0.0055  | Total Loss: 2.28 | Total Steps: 38\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2145/94000  | Episode Reward: 10  | Average Reward 8.16  | Actor loss: 0.02 | Critic loss: 0.38 | Entropy loss: -0.0003  | Total Loss: 0.40 | Total Steps: 40\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2146/94000  | Episode Reward: 10  | Average Reward 8.16  | Actor loss: -0.00 | Critic loss: 3.90 | Entropy loss: -0.0000  | Total Loss: 3.90 | Total Steps: 29\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2147/94000  | Episode Reward: 10  | Average Reward 8.16  | Actor loss: 0.00 | Critic loss: 2.34 | Entropy loss: -0.0003  | Total Loss: 2.34 | Total Steps: 37\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2148/94000  | Episode Reward: 10  | Average Reward 8.16  | Actor loss: 0.27 | Critic loss: 1.03 | Entropy loss: -0.0015  | Total Loss: 1.29 | Total Steps: 38\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2149/94000  | Episode Reward: 10  | Average Reward 8.16  | Actor loss: 0.00 | Critic loss: 3.02 | Entropy loss: -0.0000  | Total Loss: 3.02 | Total Steps: 31\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2150/94000  | Episode Reward: 10  | Average Reward 8.17  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.06 | Total Steps: 6\n",
      "\n",
      "---red prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2151/94000  | Episode Reward: 5  | Average Reward 8.12  | Actor loss: -0.63 | Critic loss: 7.34 | Entropy loss: -0.0032  | Total Loss: 6.71 | Total Steps: 50\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2152/94000  | Episode Reward: 10  | Average Reward 8.51  | Actor loss: 0.05 | Critic loss: 3.86 | Entropy loss: -0.0007  | Total Loss: 3.91 | Total Steps: 35\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2153/94000  | Episode Reward: 5  | Average Reward 8.48  | Actor loss: -0.06 | Critic loss: 2.78 | Entropy loss: -0.0015  | Total Loss: 2.72 | Total Steps: 136\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2154/94000  | Episode Reward: 10  | Average Reward 8.48  | Actor loss: -0.05 | Critic loss: 0.11 | Entropy loss: -0.0012  | Total Loss: 0.06 | Total Steps: 9\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2155/94000  | Episode Reward: 8  | Average Reward 8.51  | Actor loss: -0.00 | Critic loss: 1.27 | Entropy loss: -0.0025  | Total Loss: 1.27 | Total Steps: 128\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2156/94000  | Episode Reward: 10  | Average Reward 8.51  | Actor loss: 0.06 | Critic loss: 0.49 | Entropy loss: -0.0006  | Total Loss: 0.55 | Total Steps: 40\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2157/94000  | Episode Reward: 10  | Average Reward 8.51  | Actor loss: 0.10 | Critic loss: 0.29 | Entropy loss: -0.0011  | Total Loss: 0.39 | Total Steps: 11\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2158/94000  | Episode Reward: 8  | Average Reward 8.48  | Actor loss: -0.06 | Critic loss: 2.10 | Entropy loss: -0.0019  | Total Loss: 2.05 | Total Steps: 65\n",
      "\n",
      "---blue prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2159/94000  | Episode Reward: 10  | Average Reward 8.51  | Actor loss: 0.06 | Critic loss: 3.30 | Entropy loss: -0.0035  | Total Loss: 3.36 | Total Steps: 34\n",
      "\n",
      "---blue cube---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2160/94000  | Episode Reward: 5  | Average Reward 8.46  | Actor loss: 0.09 | Critic loss: 3.88 | Entropy loss: -0.0052  | Total Loss: 3.96 | Total Steps: 50\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2161/94000  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: 0.00 | Critic loss: 0.29 | Entropy loss: -0.0000  | Total Loss: 0.29 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2162/94000  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: 0.00 | Critic loss: 0.25 | Entropy loss: -0.0000  | Total Loss: 0.25 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2163/94000  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: 0.00 | Critic loss: 2.45 | Entropy loss: -0.0000  | Total Loss: 2.45 | Total Steps: 31\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2164/94000  | Episode Reward: 10  | Average Reward 8.46  | Actor loss: 0.00 | Critic loss: 0.19 | Entropy loss: -0.0000  | Total Loss: 0.19 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2165/94000  | Episode Reward: 10  | Average Reward 8.81  | Actor loss: 0.00 | Critic loss: 1.14 | Entropy loss: -0.0000  | Total Loss: 1.14 | Total Steps: 31\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2166/94000  | Episode Reward: 10  | Average Reward 8.81  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2167/94000  | Episode Reward: 10  | Average Reward 8.81  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2168/94000  | Episode Reward: 10  | Average Reward 8.84  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2169/94000  | Episode Reward: 8  | Average Reward 8.84  | Actor loss: -0.02 | Critic loss: 6.67 | Entropy loss: -0.0001  | Total Loss: 6.65 | Total Steps: 30\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2170/94000  | Episode Reward: 8  | Average Reward 8.81  | Actor loss: -0.62 | Critic loss: 3.11 | Entropy loss: -0.0057  | Total Loss: 2.48 | Total Steps: 57\n",
      "\n",
      "---yellow cube---\n",
      "Decision Step reward: -1.0\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2171/94000  | Episode Reward: 9  | Average Reward 8.82  | Actor loss: 0.21 | Critic loss: 4.34 | Entropy loss: -0.0082  | Total Loss: 4.54 | Total Steps: 39\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2172/94000  | Episode Reward: 10  | Average Reward 8.82  | Actor loss: 0.00 | Critic loss: 1.36 | Entropy loss: -0.0000  | Total Loss: 1.36 | Total Steps: 31\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2173/94000  | Episode Reward: 10  | Average Reward 8.82  | Actor loss: -0.17 | Critic loss: 3.92 | Entropy loss: -0.0035  | Total Loss: 3.75 | Total Steps: 45\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2174/94000  | Episode Reward: 10  | Average Reward 8.84  | Actor loss: 0.27 | Critic loss: 0.90 | Entropy loss: -0.0048  | Total Loss: 1.16 | Total Steps: 37\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2175/94000  | Episode Reward: 10  | Average Reward 8.84  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0000  | Total Loss: 0.21 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2176/94000  | Episode Reward: 10  | Average Reward 8.84  | Actor loss: -0.07 | Critic loss: 1.96 | Entropy loss: -0.0005  | Total Loss: 1.88 | Total Steps: 39\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2177/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: 0.08 | Critic loss: 0.48 | Entropy loss: -0.0002  | Total Loss: 0.56 | Total Steps: 8\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2178/94000  | Episode Reward: 10  | Average Reward 8.88  | Actor loss: -0.32 | Critic loss: 2.81 | Entropy loss: -0.0056  | Total Loss: 2.49 | Total Steps: 36\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2179/94000  | Episode Reward: 8  | Average Reward 8.86  | Actor loss: 0.01 | Critic loss: 7.20 | Entropy loss: -0.0005  | Total Loss: 7.21 | Total Steps: 52\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2180/94000  | Episode Reward: 10  | Average Reward 8.86  | Actor loss: -0.70 | Critic loss: 4.99 | Entropy loss: -0.0070  | Total Loss: 4.29 | Total Steps: 48\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2181/94000  | Episode Reward: 10  | Average Reward 8.86  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0000  | Total Loss: 0.07 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2182/94000  | Episode Reward: 10  | Average Reward 8.86  | Actor loss: 0.10 | Critic loss: 0.72 | Entropy loss: -0.0012  | Total Loss: 0.83 | Total Steps: 12\n",
      "\n",
      "---yellow cylinder---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2183/94000  | Episode Reward: 2  | Average Reward 8.80  | Actor loss: -1.67 | Critic loss: 9.97 | Entropy loss: -0.0335  | Total Loss: 8.27 | Total Steps: 193\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2184/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: 0.00 | Critic loss: 0.51 | Entropy loss: -0.0004  | Total Loss: 0.52 | Total Steps: 34\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2185/94000  | Episode Reward: 10  | Average Reward 8.80  | Actor loss: 0.02 | Critic loss: 0.19 | Entropy loss: -0.0000  | Total Loss: 0.21 | Total Steps: 6\n",
      "\n",
      "---blue prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2186/94000  | Episode Reward: 8  | Average Reward 8.79  | Actor loss: -0.42 | Critic loss: 6.89 | Entropy loss: -0.0010  | Total Loss: 6.47 | Total Steps: 19\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2187/94000  | Episode Reward: 10  | Average Reward 8.81  | Actor loss: 0.01 | Critic loss: 3.83 | Entropy loss: -0.0000  | Total Loss: 3.84 | Total Steps: 6\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2188/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: -0.04 | Critic loss: 2.06 | Entropy loss: -0.0004  | Total Loss: 2.02 | Total Steps: 39\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2189/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0000  | Total Loss: 0.08 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2190/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: -0.61 | Critic loss: 5.69 | Entropy loss: -0.0069  | Total Loss: 5.08 | Total Steps: 98\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2191/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.94 | Critic loss: 1.14 | Entropy loss: -0.0017  | Total Loss: 2.08 | Total Steps: 9\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2192/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.03 | Critic loss: 0.05 | Entropy loss: -0.0009  | Total Loss: 0.08 | Total Steps: 9\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2193/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0000  | Total Loss: 0.14 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2194/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2195/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: 0.00 | Critic loss: 1.37 | Entropy loss: -0.0000  | Total Loss: 1.37 | Total Steps: 31\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2196/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: -0.36 | Critic loss: 4.53 | Entropy loss: -0.0025  | Total Loss: 4.17 | Total Steps: 62\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2197/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: 0.11 | Critic loss: 0.32 | Entropy loss: -0.0011  | Total Loss: 0.43 | Total Steps: 10\n",
      "\n",
      "---blue sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2198/94000  | Episode Reward: 8  | Average Reward 9.09  | Actor loss: -0.04 | Critic loss: 1.43 | Entropy loss: -0.0011  | Total Loss: 1.39 | Total Steps: 30\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2199/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: 0.13 | Critic loss: 0.33 | Entropy loss: -0.0027  | Total Loss: 0.45 | Total Steps: 12\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2200/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: -0.10 | Critic loss: 2.06 | Entropy loss: -0.0017  | Total Loss: 1.97 | Total Steps: 38\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2201/94000  | Episode Reward: 10  | Average Reward 9.09  | Actor loss: 0.09 | Critic loss: 0.09 | Entropy loss: -0.0006  | Total Loss: 0.17 | Total Steps: 8\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 10  | Average Reward 6.33  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0011  | Total Loss: 0.10 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 9  | Average Reward 6.32  | Actor loss: 0.11 | Critic loss: 4.40 | Entropy loss: -0.0713  | Total Loss: 4.44 | Total Steps: 12\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 3/100  | Episode Reward: 8  | Average Reward 6.50  | Actor loss: -0.00 | Critic loss: 0.02 | Entropy loss: -0.0069  | Total Loss: 0.02 | Total Steps: 41\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 8  | Average Reward 6.47  | Actor loss: 0.05 | Critic loss: 0.60 | Entropy loss: -0.0083  | Total Loss: 0.64 | Total Steps: 57\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 10  | Average Reward 6.53  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0023  | Total Loss: 0.11 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 10  | Average Reward 6.53  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0010  | Total Loss: 0.09 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 7/100  | Episode Reward: -12  | Average Reward 6.33  | Actor loss: -0.00 | Critic loss: 105.80 | Entropy loss: -0.0002  | Total Loss: 105.79 | Total Steps: 500\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 10  | Average Reward 6.58  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0002  | Total Loss: 0.08 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 10  | Average Reward 6.58  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0014  | Total Loss: 0.09 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 10  | Average Reward 6.60  | Actor loss: 0.03 | Critic loss: 1.25 | Entropy loss: -0.0547  | Total Loss: 1.22 | Total Steps: 12\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 5  | Average Reward 6.65  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0042  | Total Loss: 0.16 | Total Steps: 44\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 9  | Average Reward 6.64  | Actor loss: 0.83 | Critic loss: 9.95 | Entropy loss: -0.0448  | Total Loss: 10.73 | Total Steps: 33\n",
      "TEST: ---green cube---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 8  | Average Reward 6.62  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0297  | Total Loss: -0.02 | Total Steps: 48\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: -7  | Average Reward 6.45  | Actor loss: 0.34 | Critic loss: 2.63 | Entropy loss: -0.0916  | Total Loss: 2.88 | Total Steps: 201\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 10  | Average Reward 6.47  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0158  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 8  | Average Reward 6.45  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0013  | Total Loss: 0.08 | Total Steps: 38\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 10  | Average Reward 6.45  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0002  | Total Loss: 0.07 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 18/100  | Episode Reward: -10  | Average Reward 6.25  | Actor loss: -0.00 | Critic loss: 87.97 | Entropy loss: -0.0002  | Total Loss: 87.96 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: -9  | Average Reward 6.11  | Actor loss: 1.18 | Critic loss: 13.45 | Entropy loss: -0.0955  | Total Loss: 14.53 | Total Steps: 334\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: -21  | Average Reward 5.79  | Actor loss: 0.02 | Critic loss: 1.10 | Entropy loss: -0.0809  | Total Loss: 1.03 | Total Steps: 376\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 10  | Average Reward 5.82  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0188  | Total Loss: 0.05 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 22/100  | Episode Reward: 5  | Average Reward 5.77  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0035  | Total Loss: 0.01 | Total Steps: 47\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 10  | Average Reward 5.77  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0033  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 8  | Average Reward 5.77  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0029  | Total Loss: 0.06 | Total Steps: 29\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 10  | Average Reward 5.79  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0002  | Total Loss: 0.00 | Total Steps: 31\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 10  | Average Reward 5.84  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0003  | Total Loss: 0.06 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 10  | Average Reward 5.84  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0004  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 8  | Average Reward 6.60  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0002  | Total Loss: 0.08 | Total Steps: 38\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 10  | Average Reward 6.60  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0004  | Total Loss: 0.11 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 10  | Average Reward 6.60  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0042  | Total Loss: -0.00 | Total Steps: 34\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 31/100  | Episode Reward: -4  | Average Reward 6.49  | Actor loss: 3.85 | Critic loss: 23.03 | Entropy loss: -0.0896  | Total Loss: 26.79 | Total Steps: 278\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 32/100  | Episode Reward: 2  | Average Reward 6.43  | Actor loss: 0.00 | Critic loss: 1.27 | Entropy loss: -0.0773  | Total Loss: 1.20 | Total Steps: 195\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 33/100  | Episode Reward: 10  | Average Reward 6.43  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0249  | Total Loss: 0.08 | Total Steps: 7\n",
      "TEST: ---red capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 34/100  | Episode Reward: 10  | Average Reward 6.46  | Actor loss: 0.00 | Critic loss: 0.41 | Entropy loss: -0.0026  | Total Loss: 0.40 | Total Steps: 49\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 35/100  | Episode Reward: 10  | Average Reward 6.46  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0232  | Total Loss: 0.07 | Total Steps: 7\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 36/100  | Episode Reward: 8  | Average Reward 6.43  | Actor loss: 0.02 | Critic loss: 0.05 | Entropy loss: -0.0292  | Total Loss: 0.04 | Total Steps: 79\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 37/100  | Episode Reward: 1  | Average Reward 6.34  | Actor loss: 1.91 | Critic loss: 13.73 | Entropy loss: -0.0832  | Total Loss: 15.55 | Total Steps: 207\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 38/100  | Episode Reward: 10  | Average Reward 6.37  | Actor loss: 0.01 | Critic loss: 0.07 | Entropy loss: -0.0923  | Total Loss: -0.01 | Total Steps: 7\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 39/100  | Episode Reward: 10  | Average Reward 6.42  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0181  | Total Loss: -0.02 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 40/100  | Episode Reward: 5  | Average Reward 6.37  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0092  | Total Loss: -0.01 | Total Steps: 49\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 41/100  | Episode Reward: 10  | Average Reward 6.38  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0295  | Total Loss: 0.11 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 42/100  | Episode Reward: 5  | Average Reward 6.38  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0196  | Total Loss: -0.02 | Total Steps: 74\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 43/100  | Episode Reward: 10  | Average Reward 6.38  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0047  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 44/100  | Episode Reward: 8  | Average Reward 6.36  | Actor loss: 0.00 | Critic loss: 0.22 | Entropy loss: -0.0091  | Total Loss: 0.22 | Total Steps: 34\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 45/100  | Episode Reward: 2  | Average Reward 6.28  | Actor loss: 21.33 | Critic loss: 43.84 | Entropy loss: -0.0824  | Total Loss: 65.09 | Total Steps: 84\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 46/100  | Episode Reward: 8  | Average Reward 6.28  | Actor loss: 0.04 | Critic loss: 0.45 | Entropy loss: -0.0162  | Total Loss: 0.48 | Total Steps: 77\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 47/100  | Episode Reward: 8  | Average Reward 6.30  | Actor loss: 0.00 | Critic loss: 0.29 | Entropy loss: -0.0118  | Total Loss: 0.28 | Total Steps: 38\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 48/100  | Episode Reward: 10  | Average Reward 6.30  | Actor loss: 0.01 | Critic loss: 1.36 | Entropy loss: -0.0180  | Total Loss: 1.35 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 49/100  | Episode Reward: 10  | Average Reward 6.30  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0049  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 50/100  | Episode Reward: 10  | Average Reward 6.30  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0024  | Total Loss: 0.01 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 51/100  | Episode Reward: 8  | Average Reward 6.33  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0203  | Total Loss: 0.09 | Total Steps: 50\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 52/100  | Episode Reward: 8  | Average Reward 6.30  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0013  | Total Loss: 0.09 | Total Steps: 29\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 53/100  | Episode Reward: 10  | Average Reward 6.30  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0026  | Total Loss: -0.00 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 54/100  | Episode Reward: 10  | Average Reward 6.30  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0003  | Total Loss: 0.13 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 55/100  | Episode Reward: 10  | Average Reward 6.30  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0041  | Total Loss: 0.04 | Total Steps: 36\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 56/100  | Episode Reward: 10  | Average Reward 6.33  | Actor loss: 2.31 | Critic loss: 1.31 | Entropy loss: -0.0327  | Total Loss: 3.59 | Total Steps: 53\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 57/100  | Episode Reward: 10  | Average Reward 6.40  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0082  | Total Loss: -0.01 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 58/100  | Episode Reward: 0  | Average Reward 6.35  | Actor loss: 0.00 | Critic loss: 0.63 | Entropy loss: -0.0880  | Total Loss: 0.54 | Total Steps: 239\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 59/100  | Episode Reward: -10  | Average Reward 6.15  | Actor loss: -0.00 | Critic loss: 89.79 | Entropy loss: -0.0002  | Total Loss: 89.79 | Total Steps: 500\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 60/100  | Episode Reward: 10  | Average Reward 6.15  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0556  | Total Loss: 0.10 | Total Steps: 9\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing  | Episode: 61/100  | Episode Reward: 10  | Average Reward 6.55  | Actor loss: -0.00 | Critic loss: 0.05 | Entropy loss: -0.0186  | Total Loss: 0.03 | Total Steps: 9\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 62/100  | Episode Reward: 5  | Average Reward 6.50  | Actor loss: 0.01 | Critic loss: 2.39 | Entropy loss: -0.0398  | Total Loss: 2.37 | Total Steps: 49\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 63/100  | Episode Reward: 10  | Average Reward 6.70  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0029  | Total Loss: 0.00 | Total Steps: 35\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 64/100  | Episode Reward: 10  | Average Reward 6.70  | Actor loss: 0.01 | Critic loss: 0.69 | Entropy loss: -0.0131  | Total Loss: 0.68 | Total Steps: 38\n",
      "TEST: ---green cube---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 65/100  | Episode Reward: -10  | Average Reward 6.50  | Actor loss: -0.01 | Critic loss: 98.59 | Entropy loss: -0.0001  | Total Loss: 98.58 | Total Steps: 500\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 66/100  | Episode Reward: 10  | Average Reward 6.70  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0134  | Total Loss: 0.08 | Total Steps: 7\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 67/100  | Episode Reward: 2  | Average Reward 6.62  | Actor loss: 0.02 | Critic loss: 1.65 | Entropy loss: -0.0686  | Total Loss: 1.60 | Total Steps: 95\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 68/100  | Episode Reward: 8  | Average Reward 6.59  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0120  | Total Loss: -0.00 | Total Steps: 34\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 69/100  | Episode Reward: 10  | Average Reward 6.62  | Actor loss: 0.01 | Critic loss: 1.38 | Entropy loss: -0.0009  | Total Loss: 1.39 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 70/100  | Episode Reward: -5  | Average Reward 6.50  | Actor loss: 0.01 | Critic loss: 1.83 | Entropy loss: -0.0894  | Total Loss: 1.75 | Total Steps: 246\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 71/100  | Episode Reward: 10  | Average Reward 6.50  | Actor loss: 0.00 | Critic loss: 0.11 | Entropy loss: -0.0176  | Total Loss: 0.09 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 72/100  | Episode Reward: 8  | Average Reward 6.47  | Actor loss: 0.01 | Critic loss: 0.13 | Entropy loss: -0.0117  | Total Loss: 0.12 | Total Steps: 47\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 73/100  | Episode Reward: 5  | Average Reward 6.45  | Actor loss: 0.00 | Critic loss: 0.10 | Entropy loss: -0.0015  | Total Loss: 0.10 | Total Steps: 49\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 74/100  | Episode Reward: 5  | Average Reward 6.39  | Actor loss: 8.76 | Critic loss: 29.41 | Entropy loss: -0.0778  | Total Loss: 38.10 | Total Steps: 172\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 75/100  | Episode Reward: -10  | Average Reward 6.20  | Actor loss: -0.00 | Critic loss: 94.34 | Entropy loss: -0.0002  | Total Loss: 94.34 | Total Steps: 500\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 76/100  | Episode Reward: 10  | Average Reward 6.22  | Actor loss: 0.52 | Critic loss: 0.50 | Entropy loss: -0.0117  | Total Loss: 1.01 | Total Steps: 33\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 77/100  | Episode Reward: -7  | Average Reward 6.05  | Actor loss: 7.05 | Critic loss: 38.34 | Entropy loss: -0.0826  | Total Loss: 45.31 | Total Steps: 140\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 78/100  | Episode Reward: 10  | Average Reward 6.05  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0860  | Total Loss: -0.08 | Total Steps: 8\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 79/100  | Episode Reward: 10  | Average Reward 6.07  | Actor loss: 0.01 | Critic loss: 1.33 | Entropy loss: -0.0112  | Total Loss: 1.33 | Total Steps: 86\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 80/100  | Episode Reward: 10  | Average Reward 6.12  | Actor loss: 0.01 | Critic loss: 2.90 | Entropy loss: -0.0100  | Total Loss: 2.91 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 81/100  | Episode Reward: 10  | Average Reward 6.14  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0019  | Total Loss: 0.05 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 82/100  | Episode Reward: 10  | Average Reward 6.20  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0008  | Total Loss: 0.02 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Step: 400\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 83/100  | Episode Reward: 4  | Average Reward 6.16  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0038  | Total Loss: -0.00 | Total Steps: 439\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 84/100  | Episode Reward: -10  | Average Reward 6.09  | Actor loss: -0.00 | Critic loss: 91.78 | Entropy loss: -0.0001  | Total Loss: 91.77 | Total Steps: 500\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 85/100  | Episode Reward: 5  | Average Reward 6.07  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0048  | Total Loss: 0.03 | Total Steps: 48\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 86/100  | Episode Reward: -4  | Average Reward 5.92  | Actor loss: 15.38 | Critic loss: 43.90 | Entropy loss: -0.0901  | Total Loss: 59.19 | Total Steps: 148\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 87/100  | Episode Reward: 8  | Average Reward 5.90  | Actor loss: 0.00 | Critic loss: 0.52 | Entropy loss: -0.0029  | Total Loss: 0.52 | Total Steps: 34\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 88/100  | Episode Reward: 10  | Average Reward 5.92  | Actor loss: -0.00 | Critic loss: 0.00 | Entropy loss: -0.0796  | Total Loss: -0.08 | Total Steps: 7\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 89/100  | Episode Reward: 10  | Average Reward 5.97  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0027  | Total Loss: 0.08 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 90/100  | Episode Reward: 8  | Average Reward 5.97  | Actor loss: 0.00 | Critic loss: 0.34 | Entropy loss: -0.0008  | Total Loss: 0.34 | Total Steps: 34\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 91/100  | Episode Reward: 0  | Average Reward 5.88  | Actor loss: 0.61 | Critic loss: 10.28 | Entropy loss: -0.0812  | Total Loss: 10.81 | Total Steps: 143\n",
      "TEST: ---red capsule---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 92/100  | Episode Reward: 8  | Average Reward 5.85  | Actor loss: 0.00 | Critic loss: 0.23 | Entropy loss: -0.0205  | Total Loss: 0.21 | Total Steps: 57\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Step: 300\n",
      "TEST: Step: 400\n",
      "TEST: Max Step Reward: -10\n",
      "TEST: Step: 500\n",
      "Testing  | Episode: 93/100  | Episode Reward: -10  | Average Reward 5.67  | Actor loss: -0.00 | Critic loss: 101.29 | Entropy loss: -0.0001  | Total Loss: 101.29 | Total Steps: 500\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 94/100  | Episode Reward: 10  | Average Reward 5.70  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0037  | Total Loss: 0.15 | Total Steps: 50\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 95/100  | Episode Reward: 10  | Average Reward 5.70  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0013  | Total Loss: 0.12 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 96/100  | Episode Reward: 8  | Average Reward 5.71  | Actor loss: 0.03 | Critic loss: 4.84 | Entropy loss: -0.0632  | Total Loss: 4.80 | Total Steps: 34\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 97/100  | Episode Reward: 10  | Average Reward 5.75  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0029  | Total Loss: 0.08 | Total Steps: 31\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 200\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 98/100  | Episode Reward: -9  | Average Reward 5.64  | Actor loss: 0.54 | Critic loss: 11.96 | Entropy loss: -0.0834  | Total Loss: 12.42 | Total Steps: 212\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 99/100  | Episode Reward: 10  | Average Reward 5.67  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0029  | Total Loss: -0.00 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 100/100  | Episode Reward: 5  | Average Reward 5.62  | Actor loss: 0.00 | Critic loss: 0.06 | Entropy loss: -0.0078  | Total Loss: 0.05 | Total Steps: 47\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2202/94000  | Episode Reward: 5  | Average Reward 9.04  | Actor loss: -0.09 | Critic loss: 3.78 | Entropy loss: -0.0022  | Total Loss: 3.69 | Total Steps: 107\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2203/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.00 | Critic loss: 0.03 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2204/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: -0.00 | Critic loss: 0.01 | Entropy loss: -0.0000  | Total Loss: 0.01 | Total Steps: 6\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2205/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.03 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2206/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.00 | Critic loss: 1.03 | Entropy loss: -0.0000  | Total Loss: 1.03 | Total Steps: 31\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2207/94000  | Episode Reward: 8  | Average Reward 9.02  | Actor loss: -0.17 | Critic loss: 4.04 | Entropy loss: -0.0017  | Total Loss: 3.86 | Total Steps: 45\n",
      "\n",
      "---black cylinder---\n",
      "Step: 250\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2208/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.07 | Critic loss: 1.34 | Entropy loss: -0.0020  | Total Loss: 1.41 | Total Steps: 377\n",
      "\n",
      "---black cube---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 2209/94000  | Episode Reward: -10  | Average Reward 8.84  | Actor loss: -0.00 | Critic loss: 3.99 | Entropy loss: -0.0001  | Total Loss: 3.99 | Total Steps: 500\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2210/94000  | Episode Reward: 10  | Average Reward 8.84  | Actor loss: -1.00 | Critic loss: 3.58 | Entropy loss: -0.0052  | Total Loss: 2.58 | Total Steps: 62\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2211/94000  | Episode Reward: 10  | Average Reward 8.89  | Actor loss: 0.01 | Critic loss: 0.20 | Entropy loss: -0.0000  | Total Loss: 0.21 | Total Steps: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2212/94000  | Episode Reward: 10  | Average Reward 8.91  | Actor loss: 0.00 | Critic loss: 0.42 | Entropy loss: -0.0000  | Total Loss: 0.43 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2213/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: 0.00 | Critic loss: 3.71 | Entropy loss: -0.0002  | Total Loss: 3.71 | Total Steps: 45\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2214/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: -0.00 | Critic loss: 3.04 | Entropy loss: -0.0000  | Total Loss: 3.03 | Total Steps: 34\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2215/94000  | Episode Reward: 8  | Average Reward 8.99  | Actor loss: -0.26 | Critic loss: 8.51 | Entropy loss: -0.0017  | Total Loss: 8.25 | Total Steps: 54\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2216/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: -0.72 | Critic loss: 5.74 | Entropy loss: -0.0103  | Total Loss: 5.01 | Total Steps: 70\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2217/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.00 | Critic loss: 0.13 | Entropy loss: -0.0001  | Total Loss: 0.13 | Total Steps: 6\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2218/94000  | Episode Reward: 8  | Average Reward 8.96  | Actor loss: -0.33 | Critic loss: 4.28 | Entropy loss: -0.0013  | Total Loss: 3.94 | Total Steps: 31\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2219/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: -0.39 | Critic loss: 0.64 | Entropy loss: -0.0016  | Total Loss: 0.25 | Total Steps: 12\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2220/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: 0.14 | Critic loss: 1.88 | Entropy loss: -0.0008  | Total Loss: 2.02 | Total Steps: 10\n",
      "\n",
      "---green capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2221/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0000  | Total Loss: 0.15 | Total Steps: 6\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2222/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.00 | Critic loss: 0.28 | Entropy loss: -0.0000  | Total Loss: 0.28 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2223/94000  | Episode Reward: 10  | Average Reward 8.99  | Actor loss: 0.15 | Critic loss: 0.42 | Entropy loss: -0.0008  | Total Loss: 0.57 | Total Steps: 11\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2224/94000  | Episode Reward: 10  | Average Reward 9.02  | Actor loss: -0.33 | Critic loss: 2.93 | Entropy loss: -0.0038  | Total Loss: 2.60 | Total Steps: 22\n",
      "\n",
      "---green cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2225/94000  | Episode Reward: 8  | Average Reward 9.02  | Actor loss: -0.40 | Critic loss: 3.78 | Entropy loss: -0.0023  | Total Loss: 3.37 | Total Steps: 51\n",
      "\n",
      "---black prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2226/94000  | Episode Reward: 10  | Average Reward 9.07  | Actor loss: 0.00 | Critic loss: 0.16 | Entropy loss: -0.0000  | Total Loss: 0.16 | Total Steps: 6\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2227/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: -0.00 | Critic loss: 0.70 | Entropy loss: -0.0000  | Total Loss: 0.70 | Total Steps: 38\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2228/94000  | Episode Reward: 10  | Average Reward 9.10  | Actor loss: 0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 2229/94000  | Episode Reward: -10  | Average Reward 8.90  | Actor loss: -0.00 | Critic loss: 3.61 | Entropy loss: -0.0001  | Total Loss: 3.61 | Total Steps: 500\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2230/94000  | Episode Reward: 10  | Average Reward 8.93  | Actor loss: 0.01 | Critic loss: 0.65 | Entropy loss: -0.0004  | Total Loss: 0.65 | Total Steps: 8\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2231/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: -0.23 | Critic loss: 3.46 | Entropy loss: -0.0080  | Total Loss: 3.22 | Total Steps: 58\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2232/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.00 | Critic loss: 4.06 | Entropy loss: -0.0001  | Total Loss: 4.06 | Total Steps: 31\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2233/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.22 | Critic loss: 0.38 | Entropy loss: -0.0009  | Total Loss: 0.60 | Total Steps: 7\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2234/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: -1.11 | Critic loss: 5.12 | Entropy loss: -0.0033  | Total Loss: 4.01 | Total Steps: 32\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2235/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.00 | Critic loss: 0.08 | Entropy loss: -0.0000  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2236/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.02 | Critic loss: 1.99 | Entropy loss: -0.0002  | Total Loss: 2.01 | Total Steps: 31\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2237/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: -0.04 | Critic loss: 0.67 | Entropy loss: -0.0007  | Total Loss: 0.63 | Total Steps: 14\n",
      "\n",
      "---red sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2238/94000  | Episode Reward: 8  | Average Reward 8.95  | Actor loss: -0.87 | Critic loss: 2.27 | Entropy loss: -0.0033  | Total Loss: 1.40 | Total Steps: 22\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2239/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.14 | Critic loss: 0.51 | Entropy loss: -0.0018  | Total Loss: 0.65 | Total Steps: 12\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2240/94000  | Episode Reward: 8  | Average Reward 8.95  | Actor loss: -0.87 | Critic loss: 5.96 | Entropy loss: -0.0055  | Total Loss: 5.09 | Total Steps: 64\n",
      "\n",
      "---blue sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2241/94000  | Episode Reward: 10  | Average Reward 8.97  | Actor loss: 0.00 | Critic loss: 2.47 | Entropy loss: -0.0000  | Total Loss: 2.47 | Total Steps: 31\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2242/94000  | Episode Reward: 8  | Average Reward 8.95  | Actor loss: 0.06 | Critic loss: 0.32 | Entropy loss: -0.0010  | Total Loss: 0.37 | Total Steps: 38\n",
      "\n",
      "---green prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2243/94000  | Episode Reward: 10  | Average Reward 8.95  | Actor loss: 0.70 | Critic loss: 1.61 | Entropy loss: -0.0032  | Total Loss: 2.30 | Total Steps: 12\n",
      "\n",
      "---red cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2244/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: -0.00 | Critic loss: 0.04 | Entropy loss: -0.0000  | Total Loss: 0.04 | Total Steps: 6\n",
      "\n",
      "---green prism---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2245/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: -0.43 | Critic loss: 3.14 | Entropy loss: -0.0023  | Total Loss: 2.70 | Total Steps: 47\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2246/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: -0.48 | Critic loss: 4.37 | Entropy loss: -0.0113  | Total Loss: 3.87 | Total Steps: 75\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2247/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: -0.13 | Critic loss: 2.15 | Entropy loss: -0.0011  | Total Loss: 2.01 | Total Steps: 48\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2248/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0000  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2249/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0000  | Total Loss: 0.02 | Total Steps: 6\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2250/94000  | Episode Reward: 8  | Average Reward 8.94  | Actor loss: -0.05 | Critic loss: 5.69 | Entropy loss: -0.0020  | Total Loss: 5.63 | Total Steps: 77\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2251/94000  | Episode Reward: 8  | Average Reward 8.96  | Actor loss: -0.29 | Critic loss: 5.97 | Entropy loss: -0.0006  | Total Loss: 5.68 | Total Steps: 29\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2252/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: -0.10 | Critic loss: 4.35 | Entropy loss: -0.0019  | Total Loss: 4.25 | Total Steps: 93\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2253/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: -0.55 | Critic loss: 4.35 | Entropy loss: -0.0020  | Total Loss: 3.80 | Total Steps: 45\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2254/94000  | Episode Reward: 8  | Average Reward 8.98  | Actor loss: -0.14 | Critic loss: 3.96 | Entropy loss: -0.0003  | Total Loss: 3.82 | Total Steps: 30\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2255/94000  | Episode Reward: 10  | Average Reward 9.01  | Actor loss: 0.01 | Critic loss: 0.34 | Entropy loss: -0.0000  | Total Loss: 0.35 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2256/94000  | Episode Reward: 8  | Average Reward 8.98  | Actor loss: -0.00 | Critic loss: 2.31 | Entropy loss: -0.0005  | Total Loss: 2.31 | Total Steps: 51\n",
      "\n",
      "---green sphere---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2257/94000  | Episode Reward: 8  | Average Reward 8.96  | Actor loss: -0.26 | Critic loss: 2.83 | Entropy loss: -0.0044  | Total Loss: 2.57 | Total Steps: 58\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2258/94000  | Episode Reward: 10  | Average Reward 8.98  | Actor loss: 0.06 | Critic loss: 1.26 | Entropy loss: -0.0012  | Total Loss: 1.31 | Total Steps: 11\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2259/94000  | Episode Reward: 10  | Average Reward 8.98  | Actor loss: 0.00 | Critic loss: 1.85 | Entropy loss: -0.0001  | Total Loss: 1.86 | Total Steps: 31\n",
      "\n",
      "---green cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2260/94000  | Episode Reward: 10  | Average Reward 9.04  | Actor loss: 0.01 | Critic loss: 1.60 | Entropy loss: -0.0000  | Total Loss: 1.61 | Total Steps: 31\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2261/94000  | Episode Reward: 8  | Average Reward 9.01  | Actor loss: 0.00 | Critic loss: 0.36 | Entropy loss: -0.0001  | Total Loss: 0.36 | Total Steps: 38\n",
      "\n",
      "---blue capsule---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2262/94000  | Episode Reward: 8  | Average Reward 8.98  | Actor loss: -0.03 | Critic loss: 2.15 | Entropy loss: -0.0006  | Total Loss: 2.12 | Total Steps: 54\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2263/94000  | Episode Reward: 10  | Average Reward 8.98  | Actor loss: -0.04 | Critic loss: 1.05 | Entropy loss: -0.0013  | Total Loss: 1.01 | Total Steps: 58\n",
      "\n",
      "---black cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2264/94000  | Episode Reward: 8  | Average Reward 8.96  | Actor loss: 0.32 | Critic loss: 0.86 | Entropy loss: -0.0021  | Total Loss: 1.17 | Total Steps: 37\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2265/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: -0.15 | Critic loss: 2.48 | Entropy loss: -0.0029  | Total Loss: 2.33 | Total Steps: 24\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2266/94000  | Episode Reward: 10  | Average Reward 8.96  | Actor loss: 0.00 | Critic loss: 0.09 | Entropy loss: -0.0000  | Total Loss: 0.09 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 2267/94000  | Episode Reward: -10  | Average Reward 8.76  | Actor loss: -0.03 | Critic loss: 6.11 | Entropy loss: -0.0029  | Total Loss: 6.08 | Total Steps: 500\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2268/94000  | Episode Reward: 10  | Average Reward 8.76  | Actor loss: 0.50 | Critic loss: 1.60 | Entropy loss: -0.0040  | Total Loss: 2.10 | Total Steps: 23\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2269/94000  | Episode Reward: 10  | Average Reward 8.79  | Actor loss: 0.00 | Critic loss: 0.63 | Entropy loss: -0.0000  | Total Loss: 0.64 | Total Steps: 6\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2270/94000  | Episode Reward: 10  | Average Reward 8.81  | Actor loss: -0.02 | Critic loss: 3.47 | Entropy loss: -0.0001  | Total Loss: 3.45 | Total Steps: 34\n",
      "\n",
      "---black cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2271/94000  | Episode Reward: 10  | Average Reward 8.82  | Actor loss: 0.00 | Critic loss: 3.22 | Entropy loss: -0.0000  | Total Loss: 3.22 | Total Steps: 31\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2272/94000  | Episode Reward: 10  | Average Reward 8.82  | Actor loss: 0.03 | Critic loss: 0.27 | Entropy loss: -0.0001  | Total Loss: 0.30 | Total Steps: 6\n",
      "\n",
      "---black cube---\n",
      "Step: 250\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 2273/94000  | Episode Reward: -10  | Average Reward 8.62  | Actor loss: -0.00 | Critic loss: 2.78 | Entropy loss: -0.0002  | Total Loss: 2.77 | Total Steps: 500\n",
      "\n",
      "---yellow cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2274/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: -0.13 | Critic loss: 0.36 | Entropy loss: -0.0013  | Total Loss: 0.23 | Total Steps: 14\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2275/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0000  | Total Loss: 0.05 | Total Steps: 6\n",
      "\n",
      "---green sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2276/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.01 | Critic loss: 0.41 | Entropy loss: -0.0004  | Total Loss: 0.42 | Total Steps: 39\n",
      "\n",
      "---yellow sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2277/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.25 | Critic loss: 0.72 | Entropy loss: -0.0006  | Total Loss: 0.97 | Total Steps: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2278/94000  | Episode Reward: 10  | Average Reward 8.62  | Actor loss: 0.16 | Critic loss: 0.11 | Entropy loss: -0.0006  | Total Loss: 0.28 | Total Steps: 6\n",
      "\n",
      "---yellow cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2279/94000  | Episode Reward: 10  | Average Reward 8.64  | Actor loss: -0.52 | Critic loss: 5.86 | Entropy loss: -0.0072  | Total Loss: 5.33 | Total Steps: 69\n",
      "\n",
      "---red cylinder---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2280/94000  | Episode Reward: 5  | Average Reward 8.60  | Actor loss: -1.06 | Critic loss: 9.14 | Entropy loss: -0.0047  | Total Loss: 8.08 | Total Steps: 55\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2281/94000  | Episode Reward: 10  | Average Reward 8.60  | Actor loss: -0.00 | Critic loss: 0.22 | Entropy loss: -0.0008  | Total Loss: 0.21 | Total Steps: 9\n",
      "\n",
      "---yellow cylinder---\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Step: 250\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Decision Step reward: -1.0\n",
      "Max Step Reward: -10\n",
      "Step: 500\n",
      "Training  | Episode: 2282/94000  | Episode Reward: -42  | Average Reward 8.07  | Actor loss: -2.77 | Critic loss: 11.29 | Entropy loss: -0.0670  | Total Loss: 8.46 | Total Steps: 500\n",
      "\n",
      "---yellow capsule---\n",
      "Decision Step reward: -1.0\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2283/94000  | Episode Reward: 9  | Average Reward 8.14  | Actor loss: -1.35 | Critic loss: 4.08 | Entropy loss: -0.0575  | Total Loss: 2.68 | Total Steps: 210\n",
      "\n",
      "---green prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2284/94000  | Episode Reward: 8  | Average Reward 8.12  | Actor loss: -0.77 | Critic loss: 9.73 | Entropy loss: -0.0160  | Total Loss: 8.94 | Total Steps: 73\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2285/94000  | Episode Reward: 10  | Average Reward 8.12  | Actor loss: 0.29 | Critic loss: 1.18 | Entropy loss: -0.0029  | Total Loss: 1.47 | Total Steps: 40\n",
      "\n",
      "---red prism---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2286/94000  | Episode Reward: 5  | Average Reward 8.10  | Actor loss: -0.72 | Critic loss: 7.20 | Entropy loss: -0.0025  | Total Loss: 6.48 | Total Steps: 45\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2287/94000  | Episode Reward: 10  | Average Reward 8.10  | Actor loss: -0.94 | Critic loss: 3.64 | Entropy loss: -0.0468  | Total Loss: 2.65 | Total Steps: 169\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2288/94000  | Episode Reward: 10  | Average Reward 8.10  | Actor loss: 0.00 | Critic loss: 0.07 | Entropy loss: -0.0002  | Total Loss: 0.08 | Total Steps: 6\n",
      "\n",
      "---red sphere---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2289/94000  | Episode Reward: 10  | Average Reward 8.10  | Actor loss: -0.08 | Critic loss: 4.29 | Entropy loss: -0.0005  | Total Loss: 4.21 | Total Steps: 42\n",
      "\n",
      "---red prism---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2290/94000  | Episode Reward: 10  | Average Reward 8.10  | Actor loss: 0.01 | Critic loss: 0.60 | Entropy loss: -0.0000  | Total Loss: 0.60 | Total Steps: 6\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2291/94000  | Episode Reward: 10  | Average Reward 8.10  | Actor loss: 0.07 | Critic loss: 0.14 | Entropy loss: -0.0004  | Total Loss: 0.21 | Total Steps: 8\n",
      "\n",
      "---black prism---\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2292/94000  | Episode Reward: 8  | Average Reward 8.07  | Actor loss: 0.00 | Critic loss: 3.85 | Entropy loss: -0.0012  | Total Loss: 3.85 | Total Steps: 49\n",
      "\n",
      "---red cylinder---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2293/94000  | Episode Reward: 10  | Average Reward 8.07  | Actor loss: 0.25 | Critic loss: 1.17 | Entropy loss: -0.0020  | Total Loss: 1.41 | Total Steps: 40\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2294/94000  | Episode Reward: 10  | Average Reward 8.07  | Actor loss: 0.00 | Critic loss: 1.91 | Entropy loss: -0.0001  | Total Loss: 1.91 | Total Steps: 29\n",
      "\n",
      "---black cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2295/94000  | Episode Reward: 10  | Average Reward 8.07  | Actor loss: 0.18 | Critic loss: 0.12 | Entropy loss: -0.0020  | Total Loss: 0.30 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2296/94000  | Episode Reward: 10  | Average Reward 8.07  | Actor loss: 0.01 | Critic loss: 1.92 | Entropy loss: -0.0000  | Total Loss: 1.93 | Total Steps: 6\n",
      "\n",
      "---blue cube---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2297/94000  | Episode Reward: 10  | Average Reward 8.07  | Actor loss: 0.01 | Critic loss: 1.70 | Entropy loss: -0.0002  | Total Loss: 1.70 | Total Steps: 31\n",
      "\n",
      "---yellow capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2298/94000  | Episode Reward: 10  | Average Reward 8.10  | Actor loss: 0.11 | Critic loss: 5.31 | Entropy loss: -0.0029  | Total Loss: 5.42 | Total Steps: 32\n",
      "\n",
      "---black capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2299/94000  | Episode Reward: 10  | Average Reward 8.10  | Actor loss: 0.04 | Critic loss: 2.14 | Entropy loss: -0.0007  | Total Loss: 2.18 | Total Steps: 37\n",
      "\n",
      "---blue capsule---\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2300/94000  | Episode Reward: 10  | Average Reward 8.10  | Actor loss: 0.00 | Critic loss: 2.12 | Entropy loss: -0.0000  | Total Loss: 2.12 | Total Steps: 31\n",
      "\n",
      "---black cube---\n",
      "Decision Step reward: -2.5\n",
      "Decision Step reward: -2.5\n",
      "Agent in terminal steps\n",
      "Terminal Step reward: 10.0\n",
      "Training  | Episode: 2301/94000  | Episode Reward: 5  | Average Reward 8.04  | Actor loss: -0.15 | Critic loss: 2.27 | Entropy loss: -0.0008  | Total Loss: 2.12 | Total Steps: 46\n",
      "TEST: ---green cube---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 1/100  | Episode Reward: 8  | Average Reward 5.59  | Actor loss: 0.00 | Critic loss: 0.17 | Entropy loss: -0.0032  | Total Loss: 0.16 | Total Steps: 30\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 2/100  | Episode Reward: 10  | Average Reward 5.60  | Actor loss: 0.00 | Critic loss: 1.27 | Entropy loss: -0.0795  | Total Loss: 1.20 | Total Steps: 16\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 3/100  | Episode Reward: -4  | Average Reward 5.49  | Actor loss: 0.00 | Critic loss: 0.60 | Entropy loss: -0.0910  | Total Loss: 0.52 | Total Steps: 198\n",
      "TEST: ---red capsule---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 4/100  | Episode Reward: 8  | Average Reward 5.49  | Actor loss: 0.01 | Critic loss: 1.37 | Entropy loss: -0.0384  | Total Loss: 1.34 | Total Steps: 36\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 5/100  | Episode Reward: 10  | Average Reward 5.49  | Actor loss: 0.00 | Critic loss: 0.26 | Entropy loss: -0.0069  | Total Loss: 0.26 | Total Steps: 6\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 6/100  | Episode Reward: 10  | Average Reward 5.49  | Actor loss: 0.01 | Critic loss: 1.09 | Entropy loss: -0.0047  | Total Loss: 1.09 | Total Steps: 40\n",
      "TEST: ---black sphere---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 7/100  | Episode Reward: 8  | Average Reward 5.68  | Actor loss: 0.00 | Critic loss: 1.90 | Entropy loss: -0.0017  | Total Loss: 1.90 | Total Steps: 29\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 8/100  | Episode Reward: 5  | Average Reward 5.63  | Actor loss: 0.10 | Critic loss: 0.03 | Entropy loss: -0.0050  | Total Loss: 0.13 | Total Steps: 136\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 9/100  | Episode Reward: 10  | Average Reward 5.63  | Actor loss: 0.00 | Critic loss: 0.58 | Entropy loss: -0.0003  | Total Loss: 0.58 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Step: 100\n",
      "TEST: Step: 200\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 10/100  | Episode Reward: 5  | Average Reward 5.58  | Actor loss: 0.00 | Critic loss: 0.26 | Entropy loss: -0.0033  | Total Loss: 0.25 | Total Steps: 286\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 11/100  | Episode Reward: 10  | Average Reward 5.63  | Actor loss: 0.18 | Critic loss: 2.81 | Entropy loss: -0.0206  | Total Loss: 2.96 | Total Steps: 16\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 12/100  | Episode Reward: 10  | Average Reward 5.64  | Actor loss: 0.02 | Critic loss: 1.33 | Entropy loss: -0.0043  | Total Loss: 1.35 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 13/100  | Episode Reward: 10  | Average Reward 5.67  | Actor loss: 0.00 | Critic loss: 0.02 | Entropy loss: -0.0449  | Total Loss: -0.03 | Total Steps: 8\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 14/100  | Episode Reward: 5  | Average Reward 5.79  | Actor loss: 0.00 | Critic loss: 0.92 | Entropy loss: -0.0116  | Total Loss: 0.91 | Total Steps: 45\n",
      "TEST: ---yellow prism---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 15/100  | Episode Reward: 10  | Average Reward 5.79  | Actor loss: 0.70 | Critic loss: 11.91 | Entropy loss: -0.0711  | Total Loss: 12.54 | Total Steps: 25\n",
      "TEST: ---red capsule---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 16/100  | Episode Reward: 10  | Average Reward 5.82  | Actor loss: 0.21 | Critic loss: 2.10 | Entropy loss: -0.0083  | Total Loss: 2.30 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 17/100  | Episode Reward: 10  | Average Reward 5.82  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0025  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 18/100  | Episode Reward: 10  | Average Reward 6.01  | Actor loss: 0.00 | Critic loss: 0.21 | Entropy loss: -0.0405  | Total Loss: 0.17 | Total Steps: 9\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 19/100  | Episode Reward: 10  | Average Reward 6.21  | Actor loss: 0.00 | Critic loss: 0.12 | Entropy loss: -0.0015  | Total Loss: 0.12 | Total Steps: 31\n",
      "TEST: ---black sphere---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 20/100  | Episode Reward: 10  | Average Reward 6.51  | Actor loss: 0.01 | Critic loss: 2.53 | Entropy loss: -0.0004  | Total Loss: 2.53 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 21/100  | Episode Reward: 0  | Average Reward 6.42  | Actor loss: 0.01 | Critic loss: 0.05 | Entropy loss: -0.0108  | Total Loss: 0.05 | Total Steps: 42\n",
      "TEST: ---yellow prism---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Step: 100\n",
      "TEST: Decision Step reward: -1.0\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 22/100  | Episode Reward: 6  | Average Reward 6.42  | Actor loss: 19.34 | Critic loss: 26.73 | Entropy loss: -0.0911  | Total Loss: 45.98 | Total Steps: 129\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 23/100  | Episode Reward: 2  | Average Reward 6.34  | Actor loss: 0.01 | Critic loss: 0.31 | Entropy loss: -0.0177  | Total Loss: 0.30 | Total Steps: 49\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 24/100  | Episode Reward: 8  | Average Reward 6.34  | Actor loss: 0.00 | Critic loss: 0.05 | Entropy loss: -0.0076  | Total Loss: 0.04 | Total Steps: 34\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 25/100  | Episode Reward: 10  | Average Reward 6.34  | Actor loss: 0.02 | Critic loss: 1.37 | Entropy loss: -0.0019  | Total Loss: 1.38 | Total Steps: 6\n",
      "TEST: ---green cube---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 26/100  | Episode Reward: 10  | Average Reward 6.34  | Actor loss: 0.00 | Critic loss: 0.01 | Entropy loss: -0.0129  | Total Loss: -0.01 | Total Steps: 55\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 27/100  | Episode Reward: 10  | Average Reward 6.34  | Actor loss: 0.00 | Critic loss: 0.15 | Entropy loss: -0.0006  | Total Loss: 0.15 | Total Steps: 31\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Decision Step reward: -2.5\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 28/100  | Episode Reward: 8  | Average Reward 6.34  | Actor loss: 0.00 | Critic loss: 0.14 | Entropy loss: -0.0004  | Total Loss: 0.14 | Total Steps: 38\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 29/100  | Episode Reward: 10  | Average Reward 6.34  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0012  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---blue cylinder---\n",
      "TEST: Agent in terminal steps\n",
      "TEST: Terminal Step reward: 10.0\n",
      "Testing  | Episode: 30/100  | Episode Reward: 10  | Average Reward 6.34  | Actor loss: 0.00 | Critic loss: 0.00 | Entropy loss: -0.0010  | Total Loss: 0.00 | Total Steps: 6\n",
      "TEST: ---yellow prism---\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "import argparse\n",
    "import time\n",
    "import json\n",
    "# import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "entropy_term = 0\n",
    "# add arguments in command --train/test\n",
    "# parser = argparse.ArgumentParser(description='Train or test neural net motor controller.')\n",
    "# parser.add_argument('--train', dest='train', action='store_true', default=False)\n",
    "# parser.add_argument('--test', dest='test', action='store_true', default=True)\n",
    "# args = parser.parse_args()\n",
    "train = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device) \n",
    "\n",
    "S0_ALG_NAME = 'S2'\n",
    "S0_ENV_ID = '21'\n",
    "S0_episode = 29000\n",
    "\n",
    "ALG_NAME = 'S2'\n",
    "ENV_ID = '24'\n",
    "TRAIN_EPISODES = 94000  # number of overall episodes for training  # number of overall episodes for testing\n",
    "MAX_STEPS = 500  # maximum time step in one episode\n",
    "LAM = 0.95  # reward discount in TD error\n",
    "lr = 2.5e-5  #0.00005 \n",
    "speed = 3\n",
    "num_steps = 250 # the step for updating the network\n",
    "test_episode = 0\n",
    "if __name__ == '__main__':\n",
    "    agent = Agent(num_words, embedding_dim, vision_output_dim, language_output_dim, mixing_dim, lstm_hidden_dim,num_actions)\n",
    "    agent.load(S0_episode,S0_ALG_NAME,S0_ENV_ID)\n",
    "    agent.to(device)\n",
    "    optimizer = optim.RMSprop(agent.parameters(), lr=lr)\n",
    "    best_score = float('-inf')\n",
    "    hashmap = {\n",
    "        0: 'capsule',\n",
    "        1: 'cube',\n",
    "        2: 'cylinder',\n",
    "        3: 'prism',\n",
    "        4: 'sphere',\n",
    "        5: 'red',\n",
    "        6: 'green',\n",
    "        7: 'blue',\n",
    "        8: 'yellow',\n",
    "        9: 'black'}\n",
    "    if train:\n",
    "        entropy_term = 0\n",
    "        test_episode_reward = []\n",
    "        test_average_reward = []\n",
    "        test_steps = []\n",
    "        test_actor_loss = []\n",
    "        test_critic_loss = []\n",
    "        test_entropy_loss = []\n",
    "        test_total_loss = []\n",
    "        tracked_agent = -1\n",
    "        test_episode = 0\n",
    "        all_episode_reward = []\n",
    "        all_average_reward = []\n",
    "        all_steps = []\n",
    "        all_actor_loss = []\n",
    "        all_critic_loss = []\n",
    "        all_entropy_loss = []\n",
    "        all_total_loss = []\n",
    "        env = env_train\n",
    "        for episode in range(TRAIN_EPISODES):\n",
    "            t0 = time.time()\n",
    "            episode_reward = 0\n",
    "            # env.reset()\n",
    "            behavior_name=list(env.behavior_specs)[0]\n",
    "            spec=env.behavior_specs[behavior_name]\n",
    "            # state = env.reset().astype(np.float32)\n",
    "            STEPS = 0\n",
    "\n",
    "            decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "            # state -- vt, lt, lstm\n",
    "            vt = torch.tensor(decision_steps.obs[0]).reshape(1,3,128,128).to(device)\n",
    "            index1 = int(decision_steps.obs[1][0][0])\n",
    "            index2 = int(decision_steps.obs[1][0][1])+5\n",
    "            print()\n",
    "            print(f'---{hashmap[index2]} {hashmap[index1]}---')\n",
    "            # 0-capsule,1-cube,2-cylinder,3-prism,4-sphere \n",
    "            lt = torch.zeros(35).to(device)\n",
    "            lt[index1],lt[index2] = 1,1\n",
    "            lstm_hidden_state = (torch.zeros(1, lstm_hidden_dim).to(device), torch.zeros(1, lstm_hidden_dim).to(device))\n",
    "            done = False\n",
    "            while True:\n",
    "\n",
    "                # Need to use when calculating the loss\n",
    "                log_probs = []\n",
    "                # values = []\n",
    "                values = torch.empty(0).to(device)\n",
    "                rewards = []\n",
    "\n",
    "                for steps in range(num_steps):\n",
    "                    lstm_hidden_state = tuple(tensor.detach() for tensor in lstm_hidden_state)\n",
    "                    STEPS += 1\n",
    "                    policy_dist, value, lstm_hidden_state = agent(vt,lt,lstm_hidden_state)\n",
    "                    # value = value.detach()\n",
    "                    dist = F.softmax(policy_dist.detach(),dim=1).cpu().numpy()\n",
    "                    \n",
    "\n",
    "                    action_dist = Categorical(F.softmax(policy_dist.detach(),dim=1))\n",
    "                    # action_dist = Categorical(F.softmax(policy_dist,dim=1))\n",
    "                    action = action_dist.sample() # sample an action from action_dist\n",
    "                    action_onehot = F.one_hot(torch.tensor(action),num_actions).cpu()\n",
    "                    \n",
    "                    log_prob = torch.log(F.softmax(policy_dist,dim=1)[0][action])\n",
    "                    # log_prob = torch.log(F.softmax(policy_dist,dim=1)[0][action])\n",
    "                    # entropy = -np.sum(np.mean(dist)* np.log(dist))\n",
    "                    entropy = F.cross_entropy(policy_dist.detach(), action)\n",
    "\n",
    "                    discrete_actions = np.array(action_onehot).reshape(1,4)*speed\n",
    "                    action_tuple = ActionTuple()\n",
    "                    action_tuple.add_discrete(discrete_actions)\n",
    "                    env.set_actions(behavior_name,action_tuple)\n",
    "                    env.step()\n",
    "                    decision_steps, terminal_steps = env.get_steps(behavior_name)\n",
    "\n",
    "                    if tracked_agent == -1 and len(decision_steps) >= 1:\n",
    "                        tracked_agent = decision_steps.agent_id[0]\n",
    "                        # print(tracked_agent)\n",
    "\n",
    "                    if tracked_agent in terminal_steps: # roll over or hit the target\n",
    "                        print('Agent in terminal steps')\n",
    "                        done = True\n",
    "                        reward = terminal_steps[tracked_agent].reward\n",
    "                        if reward > 0:\n",
    "                            pass\n",
    "                        else: reward = -1 # roll over or other unseen conditions\n",
    "\n",
    "                        print(f'Terminal Step reward: {reward}')\n",
    "\n",
    "                    elif tracked_agent in decision_steps: # the agent which requires action\n",
    "                        reward = decision_steps[tracked_agent].reward\n",
    "                        # print(f'Decision Step reward: {reward}')\n",
    "                        if reward<0:\n",
    "                            print(f'Decision Step reward: {reward}')\n",
    "                    if STEPS >= MAX_STEPS:\n",
    "                        reward = -10\n",
    "                        print(f'Max Step Reward: {reward}')\n",
    "                        env.reset()\n",
    "                        done = True\n",
    "                    if STEPS % num_steps == 0:\n",
    "                        print (f'Step: {STEPS}')\n",
    "\n",
    "                    episode_reward = episode_reward + reward\n",
    "\n",
    "                    rewards.append(reward)\n",
    "                    # values.append(value)\n",
    "                    values = torch.cat((values, value), dim=0)\n",
    "                    log_probs.append(log_prob)\n",
    "                    entropy_term = entropy_term + entropy\n",
    "                    vt_new = torch.tensor(decision_steps.obs[0]).reshape(1,3,128,128).to(device)\n",
    "                    vt = vt_new\n",
    "\n",
    "                    if done or steps == num_steps-1:\n",
    "                        # _, Qval,_ = agent(vt_new,lt,lstm_hidden_state)\n",
    "                        # Qval = Qval.detach()\n",
    "                        break\n",
    "                \n",
    "                \n",
    "                discounted_rewards = np.zeros_like(values.cpu().detach().numpy())\n",
    "                cumulative = 0\n",
    "                for t in reversed(range(len(rewards))):\n",
    "                    cumulative = rewards[t] + LAM * cumulative # Monte Carlo\n",
    "                    discounted_rewards[t] = cumulative\n",
    "                # print(f'rewards:{rewards}, discounted_rewards:{discounted_rewards}')\n",
    "                # Advantage Actor Critic\n",
    "\n",
    "                # Qvals[-1] = rewards[t] + LAM * Qval      or       Qvals[-1] = rewards[t]                   \n",
    "                # for t in range(len(rewards)-1):\n",
    "                #         Qvals[t] = rewards[t] + LAM * values[t+1]\n",
    "                \n",
    "                # r_(t+1) = R(s_t|a_t)--> reward[t]        a_t, V_t = agent(s_t)\n",
    "                # A_t = r_(t+1) + LAM * V_(t+1) - V_t \n",
    "                #     = Q_t - V_t\n",
    "                \n",
    "                # Monte Carlo Advantage = reward + LAM * cumulative_reward\n",
    "                # Actor_loss = -log(pai(s_t|a_t))*A_t\n",
    "                # Critic_loss = A_t.pow(2) *0.5\n",
    "                # Entropy_loss = -F.entropy(pai(St),index) * 0.001\n",
    "\n",
    "                # entropy = -np.sum(np.mean(dist) * np.log(dist))\n",
    "                \n",
    "                #update actor critic\n",
    "                \n",
    "                # values = torch.FloatTensor(values).requires_grad_(True).to(device)\n",
    "                discounted_rewards = torch.FloatTensor(discounted_rewards.astype(np.float32)).to(device)\n",
    "                log_probs = torch.stack(log_probs)\n",
    "                advantage = discounted_rewards - values\n",
    "                actor_loss = (-log_probs * advantage).mean()\n",
    "                critic_loss = 0.5 * torch.square(advantage).mean()\n",
    "                entropy_term /= num_steps\n",
    "                entropy_loss = -0.1 * entropy_term\n",
    "                ac_loss = actor_loss + critic_loss + entropy_loss\n",
    "                # ac_loss = values.mean()\n",
    "                optimizer.zero_grad()\n",
    "                ac_loss.backward()\n",
    "                optimizer.step()\n",
    "                # for name, param in agent.named_parameters():\n",
    "                #     if param.grad is not None:\n",
    "                #         print(name, param.grad)\n",
    "                #     else:\n",
    "                #         print(name, \"gradients not computed\")\n",
    "                # for name, param in agent.named_parameters():\n",
    "                #     if name == 'value_estimator.weight':\n",
    "                #         print(name, param)\n",
    "                \n",
    "                \n",
    "                if done: break\n",
    "\n",
    "\n",
    "            all_episode_reward.append(float(episode_reward))\n",
    "            all_steps.append(STEPS)\n",
    "            all_actor_loss.append(float(actor_loss))\n",
    "            all_critic_loss.append(float(critic_loss))\n",
    "            all_entropy_loss.append(float(entropy_loss))\n",
    "            all_total_loss.append(float(ac_loss))\n",
    "            if episode >= 100:\n",
    "                avg_score = np.mean(all_episode_reward[-100:])\n",
    "                all_average_reward.append(avg_score)\n",
    "                if avg_score > best_score:\n",
    "                    best_score = avg_score\n",
    "                    agent.save(episode, ALG_NAME, ENV_ID)\n",
    "                    print(f'-----The best score for averaging previous 100 episode reward is {best_score}. Model has been saved-----')\n",
    "                print('Training  | Episode: {}/{}  | Episode Reward: {:.0f}  | Average Reward {:.2f}  | Actor loss: {:.2f} | Critic loss: {:.2f} | Entropy loss: {:.4f}  | Total Loss: {:.2f} | Total Steps: {}' \\\n",
    "                    .format(episode + 1, TRAIN_EPISODES, episode_reward, avg_score, actor_loss, critic_loss,entropy_loss,  ac_loss, STEPS))\n",
    "            else:  print('Training  | Episode: {}/{}  | Episode Reward: {:.0f}  | Actor loss: {:.2f} | Critic loss: {:.2f} | Entropy loss: {:.4f}  | Total Loss: {:.2f} | Total Steps: {}' \\\n",
    "                    .format(episode + 1, TRAIN_EPISODES, episode_reward, actor_loss, critic_loss, entropy_loss,  ac_loss, STEPS))\n",
    "            if episode%500 == 0:\n",
    "                    agent.save(episode, ALG_NAME, ENV_ID)\n",
    "                    print(\"Model has been saved\")\n",
    "            if episode%100 == 0:\n",
    "                test_episode,test_episode_reward,test_average_reward,test_steps,test_actor_loss,test_critic_loss,test_entropy_loss,test_total_loss = test(agent,test_episode,test_episode_reward,test_average_reward,test_steps,test_actor_loss,test_critic_loss,test_entropy_loss,test_total_loss)\n",
    "\n",
    "        print(all_average_reward)\n",
    "        agent.save(episode ,ALG_NAME, ENV_ID)\n",
    "        print(\"Model has been saved\")\n",
    "\n",
    "        data = {\n",
    "                    'all_average_reward': all_average_reward,\n",
    "                    'all_episode_reward': all_episode_reward,\n",
    "                    'all_actor_loss': all_actor_loss,\n",
    "                    'all_critic_loss': all_critic_loss,\n",
    "                    'all_entropy_loss': all_entropy_loss,\n",
    "                    'all_total_loss': all_total_loss,\n",
    "                    'all_steps': all_steps,\n",
    "                } \n",
    "        file_path = f'result/{ALG_NAME}_{ENV_ID}_train.txt'\n",
    "        with open(file_path, 'w') as file:\n",
    "            json.dump(data, file)\n",
    "        \n",
    "        test_data = {\n",
    "                    'all_average_reward': test_average_reward,\n",
    "                    'all_episode_reward': test_episode_reward,\n",
    "                    'all_actor_loss': test_actor_loss,\n",
    "                    'all_critic_loss': test_critic_loss,\n",
    "                    'all_entropy_loss': test_entropy_loss,\n",
    "                    'all_total_loss': test_total_loss,\n",
    "                    'all_steps': test_steps,\n",
    "                } \n",
    "        file_path = f'result/{ALG_NAME}_{ENV_ID}_test.txt'\n",
    "        with open(file_path, 'w') as file:\n",
    "            json.dump(test_data, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T01:05:45.393557Z",
     "start_time": "2023-07-29T01:05:44.254496Z"
    }
   },
   "outputs": [],
   "source": [
    "        data = {\n",
    "                    'all_average_reward': all_average_reward,\n",
    "                    'all_episode_reward': all_episode_reward,\n",
    "                    'all_actor_loss': all_actor_loss,\n",
    "                    'all_critic_loss': all_critic_loss,\n",
    "                    'all_entropy_loss': all_entropy_loss,\n",
    "                    'all_total_loss': all_total_loss,\n",
    "                    'all_steps': all_steps,\n",
    "                } \n",
    "        file_path = f'result/{ALG_NAME}_{ENV_ID}_train.txt'\n",
    "        with open(file_path, 'w') as file:\n",
    "            json.dump(data, file)\n",
    "        \n",
    "        test_data = {\n",
    "                    'all_average_reward': test_average_reward,\n",
    "                    'all_episode_reward': test_episode_reward,\n",
    "                    'all_actor_loss': test_actor_loss,\n",
    "                    'all_critic_loss': test_critic_loss,\n",
    "                    'all_entropy_loss': test_entropy_loss,\n",
    "                    'all_total_loss': test_total_loss,\n",
    "                    'all_steps': test_steps,\n",
    "                } \n",
    "        file_path = f'result/{ALG_NAME}_{ENV_ID}_test.txt'\n",
    "        with open(file_path, 'w') as file:\n",
    "            json.dump(test_data, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
